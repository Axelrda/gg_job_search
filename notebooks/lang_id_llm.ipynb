{"cells":[{"cell_type":"markdown","metadata":{"id":"6cdNWq2sbbn-"},"source":["## Load libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5927,"status":"ok","timestamp":1684447605260,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"},"user_tz":-120},"id":"QI2v6Qd0FsvT"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/axelus/anaconda3/envs/ggjobsearch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","2024-01-13 11:17:06.016490: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-01-13 11:17:06.016647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-01-13 11:17:06.057960: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-01-13 11:17:06.142518: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-01-13 11:17:07.744276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import pandas as pd\n","import unicodedata\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n","\n","from tqdm import tqdm\n","\n","from jobsearch.cleaning import drop_columns, perform_data_casting\n","from jobsearch.utils import fetch_table_data\n","\n","from jobsearch.params import DB_PATH, LANG_CLASSIF_MODEL"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["papluca/xlm-roberta-base-language-detection\n"]}],"source":["print(LANG_CLASSIF_MODEL)"]},{"cell_type":"markdown","metadata":{},"source":["## Load data"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2726,"status":"ok","timestamp":1684448951814,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"},"user_tz":-120},"id":"N5YrI-5ZEAHq"},"outputs":[],"source":["data = fetch_table_data(DB_PATH)"]},{"cell_type":"markdown","metadata":{},"source":["## Clean data"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["df = data.copy()\n","df = drop_columns(df)\n","df = perform_data_casting(df)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["df.description.sample(1000).to_csv('../db/1000_descriptions.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"9j555LhHZjK-"},"source":["## Encoding data"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":641,"status":"ok","timestamp":1684448988137,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"},"user_tz":-120},"id":"tBEat7SEuM0a"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["descriptions = df.description.to_list()\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"papluca/xlm-roberta-base-language-detection\n","\")\n","\n","inputs = tokenizer(descriptions,\n","                   truncation=True,\n","                   padding=True,\n","                   max_length=512, #512 tokens would be enough for the model to classify correctly\n","                   return_tensors=\"pt\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def tokenizing_data(LANG_CLASSIF_MODEL):\n","    descriptions = data.description.to_list()\n","\n","    tokenizer = AutoTokenizer.from_pretrained(LANG_CLASSIF_MODEL)\n","\n","    inputs = tokenizer(descriptions,\n","                    truncation=True,\n","                    padding=True,\n","                    max_length=512,\n","                    return_tensors=\"pt\")"]},{"cell_type":"markdown","metadata":{"id":"tmp0tMy2L3yQ"},"source":["## Encogings to torch dataset"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1684448988140,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"},"user_tz":-120},"id":"6zI0-LVav4U8"},"outputs":[],"source":["class PyTorchEncodedDataset(torch.utils.data.Dataset):\n","\n","    \"\"\"\n","    A custom PyTorch dataset that takes a dictionary of encodings as input and returns a dictionary of PyTorch tensors\n","    when indexed.\n","    \"\"\"\n","\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask']}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)\n","\n","torch_descriptions = PyTorchEncodedDataset(inputs)"]},{"cell_type":"markdown","metadata":{"id":"DV-zS6zPcW9v"},"source":["## Dataloader"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":353,"status":"ok","timestamp":1684448988483,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"},"user_tz":-120},"id":"Ddh1WhmecYRe"},"outputs":[],"source":["# create a data loader with batch size 32\n","batch_size = 50\n","dataloader = DataLoader(torch_descriptions, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"of_VGfmqMtHo"},"source":["## Load model to device"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3819,"status":"ok","timestamp":1684448992293,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"},"user_tz":-120},"id":"gACDIgNEwZwn","outputId":"91ac84c1-77f2-4ad1-9da6-9dfd9d62a734"},"outputs":[{"data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): XLMRobertaModel(\n","    (embeddings): XLMRobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): XLMRobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): XLMRobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=20, bias=True)\n","  )\n",")"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# set up device\n","device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n","\n","# set up model and move it to device\n","lg_classifier = AutoModelForSequenceClassification.from_pretrained(LANG_CLASSIF_MODEL)\n","lg_classifier.to(device)"]},{"cell_type":"markdown","metadata":{"id":"2G3SD6bfMyPp"},"source":["## Inference"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4397,"status":"ok","timestamp":1684448996660,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"},"user_tz":-120},"id":"jFLjUXL8muGB","outputId":"59191aa2-236f-42f8-f6db-0bd4628c76b7"},"outputs":[{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/4 [00:00<?, ?it/s]<ipython-input-19-d9847ad612b6>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask']}\n","100%|██████████| 4/4 [00:04<00:00,  1.13s/it]\n"]}],"source":["logit_list = []\n","\n","with torch.no_grad():\n","\n","  # iterate over dataloader\n","  for batch in tqdm(dataloader):\n","    # Move batch to device\n","    batch = {k: v.to(device) for k, v in batch.items()}\n","\n","    # get logits\n","    logits = lg_classifier(**batch).logits\n","\n","    # append list\n","    logit_list.append(logits)"]},{"cell_type":"markdown","metadata":{"id":"Okqr1JNOLEQN"},"source":["## Post-processing"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1684448996661,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"},"user_tz":-120},"id":"Ky4WYLtS0qa-","outputId":"040b9be1-2e63-4706-a171-cc2afca42d49"},"outputs":[{"data":{"text/plain":["fr    139\n","en     30\n","it      1\n","Name: lang_labels, dtype: int64"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# get best predicted ids (language)\n","id_list = []\n","for batch in logit_list:\n","  for line in batch:\n","    id_list.append(line.argmax().item())\n","\n","# assign ids to pd.Series\n","id_col = pd.Series(id_list)\n","\n","# map ids to corresponding labels for easier readability\n","lang_labels = id_col.map(lg_classifier.config.id2label)\n","\n","# rename\n","lang_labels.rename('lang_labels', inplace=True)\n","\n","lang_labels.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"5ugjMXRuch0B"},"source":["## Export"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1684448996662,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"},"user_tz":-120},"id":"q1gACVDdciPd"},"outputs":[],"source":["# export\n","lang_labels.to_csv('/content/drive/MyDrive/github/gg_job_search/data/lang_labels', mode='a', index=False, header=False)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNndtzgyGSHce0yVzNK5J2M","machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
