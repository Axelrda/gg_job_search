{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## IMPORT NECESSARY LIBRARIES\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# Scraping google jobs w/ serpapi\n",
    "import serpapi\n",
    "\n",
    "# generate UULE code from adress\n",
    "import uule_grabber\n",
    "\n",
    "# connect to SQLite database\n",
    "import sqlite3\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from jobsearch.database import export_dataframe_to_postgresql\n",
    "from jobsearch.utils import convert_dict_columns_to_json\n",
    "from jobsearch.params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQLite and create a new database (or open it if it already exists)\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "try:\n",
    "    # get canonical name for location of interest ==> FRANCE\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT \"Canonical Name\"\n",
    "        FROM google_geotargets\n",
    "        WHERE \"Target Type\" = ? AND \"Country Code\" = ?;\n",
    "    \"\"\", (GOOGLE_GEOTARGET_TARGET_TYPE, GOOGLE_GEOTARGET_COUNTRY_CODE))\n",
    "\n",
    "    canonical_name = cursor.fetchall()[0][0]\n",
    "\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w+CAIQICIGRnJhbmNl'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert canonical_name to uule code\n",
    "uule_code = uule_grabber.uule(canonical_name)\n",
    "uule_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with all scraped jobs during session\n",
    "new_jobs = pd.DataFrame()\n",
    "n_range = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting SerpAPI data for page: 0 - 10 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 10 - 20 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 20 - 30 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 30 - 40 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 40 - 50 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 50 - 60 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 60 - 70 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 70 - 80 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 80 - 90 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 90 - 100 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 100 - 110 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 110 - 120 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 120 - 130 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 130 - 140 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 140 - 150 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 150 - 160 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 160 - 170 of 'machine learning engineer' results\n",
      "Getting SerpAPI data for page: 0 - 10 of 'data scientist' results\n",
      "Getting SerpAPI data for page: 10 - 20 of 'data scientist' results\n",
      "Getting SerpAPI data for page: 20 - 30 of 'data scientist' results\n",
      "Getting SerpAPI data for page: 30 - 40 of 'data scientist' results\n",
      "Getting SerpAPI data for page: 40 - 50 of 'data scientist' results\n",
      "Getting SerpAPI data for page: 50 - 60 of 'data scientist' results\n",
      "Getting SerpAPI data for page: 60 - 70 of 'data scientist' results\n",
      "Getting SerpAPI data for page: 70 - 80 of 'data scientist' results\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m\n\u001b[1;32m      8\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m'\u001b[39m: SERPAPI_KEY,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesktop\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchips\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_posted:past week\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m#'date_range:2023-05-18'   #'date_posted:today'\u001b[39;00m\n\u001b[1;32m     21\u001b[0m }\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# query serapi\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m search \u001b[38;5;241m=\u001b[39m \u001b[43mserpapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# get results as dict\u001b[39;00m\n\u001b[1;32m     26\u001b[0m res \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mas_dict()\n",
      "File \u001b[0;32m~/anaconda3/envs/ggjobsearch/lib/python3.11/site-packages/serpapi/core.py:66\u001b[0m, in \u001b[0;36mClient.search\u001b[0;34m(self, params, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m     64\u001b[0m     params\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m---> 66\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/search\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SerpResults\u001b[38;5;241m.\u001b[39mfrom_http_response(r, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ggjobsearch/lib/python3.11/site-packages/serpapi/http.py:37\u001b[0m, in \u001b[0;36mHTTPClient.request\u001b[0;34m(self, method, path, params, assert_200, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mUSER_AGENT}\n\u001b[0;32m---> 37\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mConnectionError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPConnectionError(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/ggjobsearch/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/ggjobsearch/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/ggjobsearch/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/envs/ggjobsearch/lib/python3.11/site-packages/urllib3/connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ggjobsearch/lib/python3.11/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    462\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ggjobsearch/lib/python3.11/site-packages/urllib3/connectionpool.py:462\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 462\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ggjobsearch/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/ggjobsearch/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ggjobsearch/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ggjobsearch/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ggjobsearch/lib/python3.11/ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/ggjobsearch/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for query in SERPAPI_SEARCH_QUERIES:\n",
    "\n",
    "    for num  in range(n_range):\n",
    "\n",
    "        start_page = num * 10\n",
    "\n",
    "    # define parameters\n",
    "        params = {\n",
    "            'api_key': SERPAPI_KEY,\n",
    "            'device':'desktop',\n",
    "            'uule': uule_code,                         # encoded location\n",
    "            'q': query,                          # search query\n",
    "            'google_domain': 'google.fr',\n",
    "            'hl': 'fr',                                 # language of the search\n",
    "            'gl': 'fr',                                 # country of the search\n",
    "            'engine': 'google_jobs',                    # SerpApi search engine\n",
    "            'start': start_page,  # pagination\n",
    "            #'as_qdr':\"d\"\n",
    "            #\"tbs\":\"cdr:1,cd_min:12-25-2023,cd_max:01-01-2024\"\n",
    "            'chips': f'date_posted:today'  #'date_range:2023-05-18'   #'date_posted:today'\n",
    "        }\n",
    "\n",
    "        # query serapi\n",
    "        search = serpapi.search(params=params)\n",
    "        # get results as dict\n",
    "        res = search.as_dict()\n",
    "\n",
    "        # check if last search page, exceptions handling\n",
    "        try:\n",
    "            if res['error'] == \"Google hasn't returned any results for this query.\":\n",
    "                    break\n",
    "        except KeyError:\n",
    "                print(f\"Getting SerpAPI data for page: {start_page} - {start_page+10} of '{query}' results\")\n",
    "        else:\n",
    "                continue\n",
    "\n",
    "        # discard search metadata, keep job results\n",
    "        jobs = res['jobs_results']\n",
    "\n",
    "        # convert to dataframe\n",
    "        jobs_df = pd.DataFrame(jobs)\n",
    "        # convert json columns to dataframe\n",
    "        normalized_extensions = pd.json_normalize(jobs_df['detected_extensions'])\n",
    "\n",
    "        ten_jobs_df = pd.concat([jobs_df, normalized_extensions],axis=1).drop('detected_extensions', axis=1)\n",
    "        ten_jobs_df['date_time'] = datetime.datetime.now()\n",
    "        ten_jobs_df['search_query'] = query\n",
    "\n",
    "        # concat dataframe of 10 pulled results with new_jobs\n",
    "        new_jobs = pd.concat([new_jobs, ten_jobs_df])\n",
    "\n",
    "new_jobs = new_jobs.drop_duplicates(subset='description')\n",
    "\n",
    "new_jobs = new_jobs.reindex(columns=['title', 'company_name', 'location', 'via', 'description',\n",
    "    'job_highlights', 'related_links', 'thumbnail', 'extensions', 'job_id',\n",
    "    'posted_at', 'schedule_type', 'date_time', 'search_query'])\n",
    "\n",
    "new_jobs = new_jobs.reset_index(drop=True)\n",
    "\n",
    "print(\"Scraping jobs finished ‚úÖ\")\n",
    "\n",
    "print(f\"{new_jobs.shape[0]} jobs were scraped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jobs = convert_dict_columns_to_json(new_jobs, [\"related_links\", \"job_highlights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CLOUD postgres database ...\n",
      "‚úÖ Dataframe exported to database\n",
      "Using LOCAL postgres database ...\n",
      "‚úÖ Dataframe exported to database\n"
     ]
    }
   ],
   "source": [
    "export_dataframe_to_postgresql(jobs, export_to_cloud=True)\n",
    "export_dataframe_to_postgresql(jobs, export_to_cloud=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>job_highlights</th>\n",
       "      <th>related_links</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>extensions</th>\n",
       "      <th>job_id</th>\n",
       "      <th>posted_at</th>\n",
       "      <th>schedule_type</th>\n",
       "      <th>date_time</th>\n",
       "      <th>search_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning Engineer Intern (4-6 months)</td>\n",
       "      <td>360Learning</td>\n",
       "      <td>Paris</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>In 2021, 360Learning assembled its first team ...</td>\n",
       "      <td>[{\"items\": [\"In 2021, 360Learning assembled it...</td>\n",
       "      <td>[{\"link\": \"https://360learning.com/\", \"text\": ...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>[il y a 23 heures, Stage]</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJNYWNoaW5lIExlYXJuaW5nIEVuZ2...</td>\n",
       "      <td>il y a 23 heures</td>\n",
       "      <td>Stage</td>\n",
       "      <td>2024-02-13 08:59:38.374182</td>\n",
       "      <td>machine learning engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Pictarine</td>\n",
       "      <td>Lab√®ge</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Mission and challenges üéØ\\n\\nL‚Äôun des enjeux de...</td>\n",
       "      <td>[{\"items\": [\"Mission and challenges \\ud83c\\udf...</td>\n",
       "      <td>[{\"link\": \"https://www.google.fr/search?sca_es...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>[il y a 23 heures, √Ä plein temps]</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJNYWNoaW5lIExlYXJuaW5nIEVuZ2...</td>\n",
       "      <td>il y a 23 heures</td>\n",
       "      <td>√Ä plein temps</td>\n",
       "      <td>2024-02-13 08:59:38.374182</td>\n",
       "      <td>machine learning engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine learning engineer | retail/ia</td>\n",
       "      <td>Urban Linker</td>\n",
       "      <td>Paris</td>\n",
       "      <td>via Urban Linker</td>\n",
       "      <td>Tes missions seront :\\n‚Ä¢ Assurer le bon foncti...</td>\n",
       "      <td>[{\"items\": [\"Tes missions seront :\\n\\u2022 Ass...</td>\n",
       "      <td>[{\"link\": \"https://www.google.fr/search?sca_es...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[50¬†k¬†‚Ç¨ √† 60¬†k¬†‚Ç¨ par an, Prestataire]</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJNYWNoaW5lIGxlYXJuaW5nIGVuZ2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prestataire</td>\n",
       "      <td>2024-02-13 08:59:38.374182</td>\n",
       "      <td>machine learning engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remote Machine Learning Engineer</td>\n",
       "      <td>Clarity AI</td>\n",
       "      <td>France</td>\n",
       "      <td>via Emplois Trabajo.org</td>\n",
       "      <td>Clarity AI is a global tech company founded in...</td>\n",
       "      <td>[{\"items\": [\"Clarity AI is a global tech compa...</td>\n",
       "      <td>[{\"link\": \"http://clarity.ai/\", \"text\": \"clari...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>[il y a 2 jours, √Ä plein temps]</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJSZW1vdGUgTWFjaGluZSBMZWFybm...</td>\n",
       "      <td>il y a 2 jours</td>\n",
       "      <td>√Ä plein temps</td>\n",
       "      <td>2024-02-13 08:59:38.374182</td>\n",
       "      <td>machine learning engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist / Machine Learning Engineer</td>\n",
       "      <td>Ekinox</td>\n",
       "      <td>Paris</td>\n",
       "      <td>via Welcome To The Jungle</td>\n",
       "      <td>Le poste: Data Scientist/Machine Learning Engi...</td>\n",
       "      <td>[{\"items\": [\"Le poste: Data Scientist/Machine ...</td>\n",
       "      <td>[{\"link\": \"https://www.google.fr/search?sca_es...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>[il y a 29 jours, √Ä plein temps]</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCAvIE1hY2...</td>\n",
       "      <td>il y a 29 jours</td>\n",
       "      <td>√Ä plein temps</td>\n",
       "      <td>2024-02-13 08:59:38.374182</td>\n",
       "      <td>machine learning engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist R&amp;D H/F</td>\n",
       "      <td>Manpower</td>\n",
       "      <td>Tours</td>\n",
       "      <td>via HelloWork</td>\n",
       "      <td>D√©tail du poste\\n\\nLe cabinet de recrutement M...</td>\n",
       "      <td>[{\"items\": [\"D\\u00e9tail du poste\\n\\nLe cabine...</td>\n",
       "      <td>[{\"link\": \"https://www.google.fr/search?sca_es...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>[il y a 4 jours, √Ä plein temps et Travail temp...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCBSXHUwMD...</td>\n",
       "      <td>il y a 4 jours</td>\n",
       "      <td>√Ä plein temps et Travail temporaire</td>\n",
       "      <td>2024-02-13 09:03:54.250849</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist Trainee H/F</td>\n",
       "      <td>FR03 VALEO VISION</td>\n",
       "      <td>France</td>\n",
       "      <td>via Workday</td>\n",
       "      <td>Valeo je technologick√° spoleƒçnost vyv√≠jej√≠c√≠ p...</td>\n",
       "      <td>[{\"items\": [\"Valeo je technologick\\u00e1 spole...</td>\n",
       "      <td>[{\"link\": \"https://www.google.fr/search?sca_es...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[il y a 4 jours, √Ä plein temps et Travail temp...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCBUcmFpbm...</td>\n",
       "      <td>il y a 4 jours</td>\n",
       "      <td>√Ä plein temps et Travail temporaire</td>\n",
       "      <td>2024-02-13 09:03:54.250849</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lyon - Data Scientist Confirm√©(e) - H/F</td>\n",
       "      <td>ALTEN</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>via Smart Recruiters Jobs</td>\n",
       "      <td>Description de l'entreprise\\n\\nRejoindre LINCO...</td>\n",
       "      <td>[{\"items\": [\"Description de l'entreprise\\n\\nRe...</td>\n",
       "      <td>[{\"link\": \"https://www.alten.fr/\", \"text\": \"al...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[√Ä plein temps]</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJMeW9uIC0gRGF0YSBTY2llbnRpc3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>√Ä plein temps</td>\n",
       "      <td>2024-02-13 09:03:54.250849</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Informatiker/in, Data Scientist</td>\n",
       "      <td>HUK-COBURG Versicherungsgruppe</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>via BeBee</td>\n",
       "      <td>Machine Learning, K√ºnstliche Intelligenz, Data...</td>\n",
       "      <td>[{\"items\": [\"Machine Learning, K\\u00fcnstliche...</td>\n",
       "      <td>[{\"link\": \"http://www.huk.de/\", \"text\": \"huk.d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[il y a 2 jours, √Ä plein temps]</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJJbmZvcm1hdGlrZXIvaW4sIERhdG...</td>\n",
       "      <td>il y a 2 jours</td>\n",
       "      <td>√Ä plein temps</td>\n",
       "      <td>2024-02-13 09:03:54.250849</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stage - Data Scientist (F/H)</td>\n",
       "      <td>Michelin</td>\n",
       "      <td>Clermont-Ferrand</td>\n",
       "      <td>via JobTeaser</td>\n",
       "      <td>Contexte :\\n\\nDans un contexte industriel, il ...</td>\n",
       "      <td>[{\"items\": [\"Contexte :\\n\\nDans un contexte in...</td>\n",
       "      <td>[{\"link\": \"http://www.test.com/\", \"text\": \"tes...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>[Stage]</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJTdGFnZSAtIERhdGEgU2NpZW50aX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stage</td>\n",
       "      <td>2024-02-13 09:03:54.250849</td>\n",
       "      <td>data scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title  \\\n",
       "0   Machine Learning Engineer Intern (4-6 months)   \n",
       "1                       Machine Learning Engineer   \n",
       "2           Machine learning engineer | retail/ia   \n",
       "3                Remote Machine Learning Engineer   \n",
       "4      Data Scientist / Machine Learning Engineer   \n",
       "..                                            ...   \n",
       "5                          Data Scientist R&D H/F   \n",
       "6                      Data Scientist Trainee H/F   \n",
       "7         Lyon - Data Scientist Confirm√©(e) - H/F   \n",
       "8                 Informatiker/in, Data Scientist   \n",
       "9                    Stage - Data Scientist (F/H)   \n",
       "\n",
       "                      company_name               location  \\\n",
       "0                      360Learning               Paris      \n",
       "1                        Pictarine              Lab√®ge      \n",
       "2                     Urban Linker               Paris      \n",
       "3                       Clarity AI              France      \n",
       "4                           Ekinox               Paris      \n",
       "..                             ...                    ...   \n",
       "5                         Manpower               Tours      \n",
       "6                FR03 VALEO VISION              France      \n",
       "7                            ALTEN                Lyon      \n",
       "8   HUK-COBURG Versicherungsgruppe                Lyon      \n",
       "9                         Michelin    Clermont-Ferrand      \n",
       "\n",
       "                          via  \\\n",
       "0                via LinkedIn   \n",
       "1                via LinkedIn   \n",
       "2            via Urban Linker   \n",
       "3     via Emplois Trabajo.org   \n",
       "4   via Welcome To The Jungle   \n",
       "..                        ...   \n",
       "5               via HelloWork   \n",
       "6                 via Workday   \n",
       "7   via Smart Recruiters Jobs   \n",
       "8                   via BeBee   \n",
       "9               via JobTeaser   \n",
       "\n",
       "                                          description  \\\n",
       "0   In 2021, 360Learning assembled its first team ...   \n",
       "1   Mission and challenges üéØ\\n\\nL‚Äôun des enjeux de...   \n",
       "2   Tes missions seront :\\n‚Ä¢ Assurer le bon foncti...   \n",
       "3   Clarity AI is a global tech company founded in...   \n",
       "4   Le poste: Data Scientist/Machine Learning Engi...   \n",
       "..                                                ...   \n",
       "5   D√©tail du poste\\n\\nLe cabinet de recrutement M...   \n",
       "6   Valeo je technologick√° spoleƒçnost vyv√≠jej√≠c√≠ p...   \n",
       "7   Description de l'entreprise\\n\\nRejoindre LINCO...   \n",
       "8   Machine Learning, K√ºnstliche Intelligenz, Data...   \n",
       "9   Contexte :\\n\\nDans un contexte industriel, il ...   \n",
       "\n",
       "                                       job_highlights  \\\n",
       "0   [{\"items\": [\"In 2021, 360Learning assembled it...   \n",
       "1   [{\"items\": [\"Mission and challenges \\ud83c\\udf...   \n",
       "2   [{\"items\": [\"Tes missions seront :\\n\\u2022 Ass...   \n",
       "3   [{\"items\": [\"Clarity AI is a global tech compa...   \n",
       "4   [{\"items\": [\"Le poste: Data Scientist/Machine ...   \n",
       "..                                                ...   \n",
       "5   [{\"items\": [\"D\\u00e9tail du poste\\n\\nLe cabine...   \n",
       "6   [{\"items\": [\"Valeo je technologick\\u00e1 spole...   \n",
       "7   [{\"items\": [\"Description de l'entreprise\\n\\nRe...   \n",
       "8   [{\"items\": [\"Machine Learning, K\\u00fcnstliche...   \n",
       "9   [{\"items\": [\"Contexte :\\n\\nDans un contexte in...   \n",
       "\n",
       "                                        related_links  \\\n",
       "0   [{\"link\": \"https://360learning.com/\", \"text\": ...   \n",
       "1   [{\"link\": \"https://www.google.fr/search?sca_es...   \n",
       "2   [{\"link\": \"https://www.google.fr/search?sca_es...   \n",
       "3   [{\"link\": \"http://clarity.ai/\", \"text\": \"clari...   \n",
       "4   [{\"link\": \"https://www.google.fr/search?sca_es...   \n",
       "..                                                ...   \n",
       "5   [{\"link\": \"https://www.google.fr/search?sca_es...   \n",
       "6   [{\"link\": \"https://www.google.fr/search?sca_es...   \n",
       "7   [{\"link\": \"https://www.alten.fr/\", \"text\": \"al...   \n",
       "8   [{\"link\": \"http://www.huk.de/\", \"text\": \"huk.d...   \n",
       "9   [{\"link\": \"http://www.test.com/\", \"text\": \"tes...   \n",
       "\n",
       "                                            thumbnail  \\\n",
       "0   https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
       "1   https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
       "2                                                 NaN   \n",
       "3   https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
       "4   https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
       "..                                                ...   \n",
       "5   https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9   https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
       "\n",
       "                                           extensions  \\\n",
       "0                           [il y a 23 heures, Stage]   \n",
       "1                   [il y a 23 heures, √Ä plein temps]   \n",
       "2               [50¬†k¬†‚Ç¨ √† 60¬†k¬†‚Ç¨ par an, Prestataire]   \n",
       "3                     [il y a 2 jours, √Ä plein temps]   \n",
       "4                    [il y a 29 jours, √Ä plein temps]   \n",
       "..                                                ...   \n",
       "5   [il y a 4 jours, √Ä plein temps et Travail temp...   \n",
       "6   [il y a 4 jours, √Ä plein temps et Travail temp...   \n",
       "7                                     [√Ä plein temps]   \n",
       "8                     [il y a 2 jours, √Ä plein temps]   \n",
       "9                                             [Stage]   \n",
       "\n",
       "                                               job_id         posted_at  \\\n",
       "0   eyJqb2JfdGl0bGUiOiJNYWNoaW5lIExlYXJuaW5nIEVuZ2...  il y a 23 heures   \n",
       "1   eyJqb2JfdGl0bGUiOiJNYWNoaW5lIExlYXJuaW5nIEVuZ2...  il y a 23 heures   \n",
       "2   eyJqb2JfdGl0bGUiOiJNYWNoaW5lIGxlYXJuaW5nIGVuZ2...               NaN   \n",
       "3   eyJqb2JfdGl0bGUiOiJSZW1vdGUgTWFjaGluZSBMZWFybm...    il y a 2 jours   \n",
       "4   eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCAvIE1hY2...   il y a 29 jours   \n",
       "..                                                ...               ...   \n",
       "5   eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCBSXHUwMD...    il y a 4 jours   \n",
       "6   eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCBUcmFpbm...    il y a 4 jours   \n",
       "7   eyJqb2JfdGl0bGUiOiJMeW9uIC0gRGF0YSBTY2llbnRpc3...               NaN   \n",
       "8   eyJqb2JfdGl0bGUiOiJJbmZvcm1hdGlrZXIvaW4sIERhdG...    il y a 2 jours   \n",
       "9   eyJqb2JfdGl0bGUiOiJTdGFnZSAtIERhdGEgU2NpZW50aX...               NaN   \n",
       "\n",
       "                          schedule_type                  date_time  \\\n",
       "0                                 Stage 2024-02-13 08:59:38.374182   \n",
       "1                         √Ä plein temps 2024-02-13 08:59:38.374182   \n",
       "2                           Prestataire 2024-02-13 08:59:38.374182   \n",
       "3                         √Ä plein temps 2024-02-13 08:59:38.374182   \n",
       "4                         √Ä plein temps 2024-02-13 08:59:38.374182   \n",
       "..                                  ...                        ...   \n",
       "5   √Ä plein temps et Travail temporaire 2024-02-13 09:03:54.250849   \n",
       "6   √Ä plein temps et Travail temporaire 2024-02-13 09:03:54.250849   \n",
       "7                         √Ä plein temps 2024-02-13 09:03:54.250849   \n",
       "8                         √Ä plein temps 2024-02-13 09:03:54.250849   \n",
       "9                                 Stage 2024-02-13 09:03:54.250849   \n",
       "\n",
       "                 search_query  \n",
       "0   machine learning engineer  \n",
       "1   machine learning engineer  \n",
       "2   machine learning engineer  \n",
       "3   machine learning engineer  \n",
       "4   machine learning engineer  \n",
       "..                        ...  \n",
       "5              data scientist  \n",
       "6              data scientist  \n",
       "7              data scientist  \n",
       "8              data scientist  \n",
       "9              data scientist  \n",
       "\n",
       "[246 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_jobs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gg_job_search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
