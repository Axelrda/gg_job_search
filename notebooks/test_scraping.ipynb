{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT NECESSARY LIBRARIES\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# Scraping google jobs w/ serpapi\n",
    "import serpapi\n",
    "\n",
    "# generate UULE code from adress\n",
    "import uule_grabber\n",
    "\n",
    "# connect to SQLite database\n",
    "import sqlite3\n",
    "\n",
    "# necessary for path to files\n",
    "#from config import DB_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/axelus/data_science_projects/gg_job_search/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jobsearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjobsearch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m API_KEY\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jobsearch'"
     ]
    }
   ],
   "source": [
    "from jobsearch.params import API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_QUERIES = [\"machine learning engineer\", \"data scientist\", \"data analyst\", \"data engineer\"]\n",
    "COUNTRY_CODE = 'FR'\n",
    "TARGET_TYPE = 'Country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_canonical_name():\n",
    "\n",
    "    # Connect to SQLite and create a new database (or open it if it already exists)\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # get canonical name for location of interest ==> FRANCE\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT \"Canonical Name\"\n",
    "            FROM google_geotargets\n",
    "            WHERE \"Target Type\" = ? AND \"Country Code\" = ?;\n",
    "        \"\"\", (TARGET_TYPE, COUNTRY_CODE))\n",
    "\n",
    "        canonical_name = cursor.fetchall()[0][0]\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    return canonical_name\n",
    "\n",
    "def collect_data_w_serpapi(uule_code):\n",
    "    # Defining our search query + necessary parameters for GoogleSearch object\n",
    "\n",
    "    # initialize jobs_all outside of the loop\n",
    "    jobs_all = pd.DataFrame()\n",
    "\n",
    "    # initialize all_jobs_queries outside of function\n",
    "    all_jobs_queries = pd.DataFrame()\n",
    "\n",
    "    #for date in datelist:\n",
    "    for query in SEARCH_QUERIES:\n",
    "\n",
    "        # serpapi will iterate up to n number of iterations\n",
    "        for num  in range(50):\n",
    "\n",
    "            start = num * 10\n",
    "\n",
    "        # define parameters\n",
    "            params = {\n",
    "                'api_key': API_KEY,\n",
    "                'device':'desktop',\n",
    "                'uule': uule_code,                         # encoded location\n",
    "                'q': query,                          # search query\n",
    "                'google_domain': 'google.fr',\n",
    "                'hl': 'fr',                                 # language of the search\n",
    "                'gl': 'fr',                                 # country of the search\n",
    "                'engine': 'google_jobs',                    # SerpApi search engine\n",
    "                'start': start,                             # pagination\n",
    "                'chips': 'date_posted:2023-07-12'  #'date_range:2023-05-18'   #'date_posted:today'\n",
    "            }\n",
    "\n",
    "            # get results\n",
    "            search = GoogleSearch(params)\n",
    "            results = search.get_dict()  # JSON file to python dict\n",
    "\n",
    "            # check if last search page, exceptions handling\n",
    "            try:\n",
    "                if results['error'] == \"Google hasn't returned any results for this query.\":\n",
    "                        break\n",
    "            except KeyError:\n",
    "                    print(f\"Getting SerpAPI data for page: {start} of '{query}' results\")\n",
    "            else:\n",
    "                    continue\n",
    "\n",
    "            # create dataframe of 10 pulled results\n",
    "            jobs = results['jobs_results']\n",
    "            jobs = pd.DataFrame(jobs)\n",
    "            jobs = pd.concat([pd.DataFrame(jobs),\n",
    "                            pd.json_normalize(jobs['detected_extensions'])], #convert detected extension key in json files into pandas df\n",
    "                            axis=1).drop('detected_extensions', axis=1) # drop json object\n",
    "            jobs['date_time'] = datetime.datetime.now() # add extraction date column for job results\n",
    "\n",
    "            # concat dataframe of 10 pulled results with jobs_all\n",
    "            if start == 0:\n",
    "                    jobs_all = jobs\n",
    "            else:\n",
    "                    jobs_all = pd.concat([jobs_all, jobs])\n",
    "\n",
    "            # assign ongoing query to pulled results dataframe\n",
    "            jobs_all['search_query'] = query\n",
    "\n",
    "            # concat dataframe of all pulled results with all_jobs_queries\n",
    "            all_jobs_queries = pd.concat([all_jobs_queries, jobs_all])\n",
    "\n",
    "    # get rid of duplicates before export\n",
    "    all_jobs_queries.drop_duplicates(subset='description', inplace=True)\n",
    "\n",
    "    # reindex columns to match the order of existing data\n",
    "    all_jobs_queries = all_jobs_queries.reindex(columns=['title', 'company_name', 'location', 'via', 'description',\n",
    "       'job_highlights', 'related_links', 'thumbnail', 'extensions', 'job_id',\n",
    "       'posted_at', 'schedule_type', 'date_time', 'search_query'])\n",
    "\n",
    "    all_jobs_queries.to_csv('all_jobs.csv', index=False)\n",
    "\n",
    "    # convert value to str format (sql database doesn't accept list type)\n",
    "    for column in all_jobs_queries.columns:\n",
    "        all_jobs_queries[column] = all_jobs_queries[column].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "    # export data to database\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        all_jobs_queries.to_sql('unprocessed_data', conn, if_exists='append', index=False)\n",
    "\n",
    "    print(\"Shape of df:\", all_jobs_queries.shape)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     canonical_name = get_canonical_name()\n",
    "\n",
    "#     # convert canonical_name to uule code\n",
    "#     uule_code = uule_grabber.uule(canonical_name)\n",
    "\n",
    "#     collect_data_w_serpapi(uule_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gg_job_search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
