{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c6lSPXQ26ju"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import sqlite3\n",
        "\n",
        "# libraries used to remove duplicates using tf-idf and cosine similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "from jobsearch.preprocess import preprocess\n",
        "\n",
        "# necessary for path to files\n",
        "from jobsearch.params import DB_PATH\n",
        "\n",
        "pd.options.display.max_rows = 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OhFyuaQ3QlP"
      },
      "source": [
        "## COO representation of text corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LCbeEPO3LMT"
      },
      "outputs": [],
      "source": [
        "def convert_to_tfidf(corpus):\n",
        "    \"\"\"\n",
        "    This function vectorizes a text corpus using Term Frequency-Inverse Document Frequency (TF-IDF) methodology\n",
        "    and returns the resultant TF-IDF matrix.\n",
        "\n",
        "    Args:\n",
        "        corpus (iterable of str): The text corpus to vectorize. It can be a list or array-like structure containing text data.\n",
        "\n",
        "    Returns:\n",
        "        scipy.sparse.csr.csr_matrix: The TF-IDF matrix representation of the provided text corpus.\n",
        "    \"\"\"\n",
        "    # Initialize a TF-IDF vectorizer\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "    # Convert the corpus into a NumPy array of strings\n",
        "    corpus_np = np.array(corpus, dtype=str)\n",
        "\n",
        "    # Transform the corpus to a TF-IDF matrix\n",
        "    tfidf_matrix_np = tfidf_vectorizer.fit_transform(corpus_np)\n",
        "\n",
        "    return tfidf_matrix_np\n",
        "\n",
        "def compute_cosine_similarity(tfidf_matrix_np):\n",
        "    \"\"\"\n",
        "    Computes the cosine similarity between pairs of documents using their TF-IDF representations.\n",
        "\n",
        "    Args:\n",
        "        tfidf_matrix_np (scipy.sparse.csr.csr_matrix): The TF-IDF matrix representation of a text corpus.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A 2D numpy array containing cosine similarity values between each pair of documents.\n",
        "    \"\"\"\n",
        "    # Compute cosine similarity between pairs of documents\n",
        "    cosine_matrix = (tfidf_matrix_np) * (tfidf_matrix_np.T)\n",
        "\n",
        "    # Convert cosine similarity to numpy array\n",
        "    cosine_matrix = cosine_matrix.toarray()\n",
        "\n",
        "    # Set diagonal of cosine similarity to 0, as we don't need to compare a document with itself\n",
        "    np.fill_diagonal(cosine_matrix, 0)\n",
        "\n",
        "    return cosine_matrix\n",
        "\n",
        "def convert_cosine_similarity_to_coo(cosine_matrix):\n",
        "    \"\"\"\n",
        "    Converts a cosine similarity matrix to a coordinate (COO) matrix representation for efficient operations.\n",
        "\n",
        "    Args:\n",
        "        cosine_sim (np.ndarray): A 2D numpy array containing cosine similarity values between pairs of documents.\n",
        "\n",
        "    Returns:\n",
        "        scipy.sparse.coo.coo_matrix: The COO matrix representation of the provided cosine similarity matrix.\n",
        "    \"\"\"\n",
        "    # Convert cosine similarity to a coordinate (COO) matrix\n",
        "    cosine_coo = coo_matrix(cosine_matrix)\n",
        "\n",
        "    return cosine_coo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tat9ZGZL3TSD"
      },
      "source": [
        "## Get duplicates indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs3xpIFd3LC_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def filter_over_threshold(cosine_matrix, threshold=0.8):\n",
        "    \"\"\"\n",
        "    Filter records based on cosine similarity.\n",
        "\n",
        "    Args:\n",
        "        cosine_matrix (np.ndarray): 2D numpy array containing cosine similarity values.\n",
        "        threshold (float, optional): Minimum cosine similarity value to consider a record as similar. Defaults to 0.8.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary where keys are the index of the record and values are the indices of records above the threshold.\n",
        "    \"\"\"\n",
        "    over_threshold_dict = {}\n",
        "\n",
        "    for i in range(cosine_matrix.shape[0]):\n",
        "        # Extract relevant similarity scores\n",
        "        cos_val = cosine_matrix[i]\n",
        "\n",
        "        # Get record indices with scores above the threshold\n",
        "        over_threshold_indices = np.where(cos_val > threshold)[0]\n",
        "        over_threshold_dict[i] = over_threshold_indices\n",
        "\n",
        "    return over_threshold_dict\n",
        "\n",
        "def filter_by_bounds(job_data, over_threshold_dict):\n",
        "    \"\"\"\n",
        "    Filter down the compared records based on salary bounds using the indices filtered by cosine similarity.\n",
        "\n",
        "    Args:\n",
        "        job_data (pd.DataFrame): DataFrame containing job descriptions and extracted salary information.\n",
        "        over_threshold_dict (dict): Dictionary from `filter_over_threshold` containing indices of records above the threshold.\n",
        "\n",
        "    Returns:\n",
        "        set: Indices of duplicated records.\n",
        "    \"\"\"\n",
        "    duplicated_dict = {}\n",
        "\n",
        "    for i, similar_indices in over_threshold_dict.items():\n",
        "        # Filter by salary: identical lower & upper bound to original record\n",
        "        og_record = job_data.iloc[i]\n",
        "        same_bounds = job_data.iloc[similar_indices].loc[(job_data.lower_bound == og_record.lower_bound) &\n",
        "                                                         (job_data.upper_bound == og_record.upper_bound)]\n",
        "\n",
        "        # Add indices to dict\n",
        "        duplicated_dict[i] = list(same_bounds.index.values)\n",
        "\n",
        "    # Get duplicated record's indices\n",
        "    duplicated_indices = set()\n",
        "    # keep unique indices only\n",
        "    for value in duplicated_dict.values():\n",
        "        duplicated_indices = duplicated_indices.union(value)\n",
        "\n",
        "    return duplicated_indices"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
