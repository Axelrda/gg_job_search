{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["cf1679e1","00e3d02c","81e5836e"],"authorship_tag":"ABX9TyN84EdeBXYLHNGXmFFYv68u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"canvas":{"comments":[],"componentType":"CodeCell","copiedOriginId":null,"diskcache":false,"headerColor":"none","id":"c48c73be-79c0-4a27-9180-c81296120997","isComponent":false,"name":"","parents":[]},"id":"cf1679e1"},"source":["## INSIGHTS GATHERED FROM EXPLORATION\n"]},{"cell_type":"markdown","metadata":{"canvas":{"comments":[],"componentType":"CodeCell","copiedOriginId":null,"diskcache":false,"headerColor":"none","id":"35cb596f-91fa-41f4-a157-463a8d814e0e","isComponent":false,"name":"","parents":[]},"id":"85242f91"},"source":["#### Job titles\n","\n","Based on this sample of job titles, we could create : \n","    \n","    * Contract_type (full-time, part-time ...) \n","    * Contract_status (CDI, CDD, work-study, internship ...)\n","    * Duration of Contract (Duration/Undetermined)\n","    * Experience ( Senior, Junior ...)\n","    * Data Specialization (Supply chain, Marketing, Clinical ...)\n","    * Multiple titles (Analyst/Scientist, Scientist/ML Engineer, Manager/Analyst ...)\n","    * Specific expertise asked for (Python, Power BI ...)\n","    \n","    "]},{"cell_type":"markdown","metadata":{"canvas":{"comments":[],"componentType":"CodeCell","copiedOriginId":null,"diskcache":false,"headerColor":"none","id":"2ca538cb-1fbc-4a61-9e38-699165d3d17f","isComponent":false,"name":"","parents":[]},"id":"4e05598b"},"source":["#### Company name\n","\n","When ***Unspecified***, companies name can be found in description column.\n","\n","Possible new columns :\n","\n","    * Group/Holding (Y/N/NC)\n","    * Interim company (Y/N/NC)\n","\n","Based on the number of job posting per company we could potentially infer about : **size of company ? / Amount of data to work on** / \n","\n","Adding a time variable and much more data, the number of similar / identical job postings for the same company could maybe give insights on the **company's turnover rate / company's growth / magnitude of need-urgency to hire** ...  \n","\n","It seems like extracting additional informations without more context will be difficult. Having access to each company's structure information we could create :\n","\n","    * Size of company\n","    * Industry\n","    * Public / Private\n","    \n","We'll see if can extract more related informations in the following columns. Otherwise, we could try to scrap **Glassdoor databases** (or similar) to get those informations.remains to be seen ..."]},{"cell_type":"markdown","metadata":{"canvas":{"comments":[],"componentType":"CodeCell","copiedOriginId":null,"diskcache":false,"headerColor":"none","id":"6868c971-6ec6-4226-a78d-2c1d082494df","isComponent":false,"name":"","parents":[]},"id":"ee0cabad"},"source":["#### Location\n","\n","We could create a map of th repartition of job posting based on location provided.\n","\n","Some companies don't provide precise location *(ex : location = FRANCE)* and the information is not available in description column either. Further investigations will be needed for these companies, perhaps in conjunction with other databases *(GLASSDOOR / SIRENE databases for instance)*."]},{"cell_type":"markdown","metadata":{"canvas":{"comments":[],"componentType":"CodeCell","copiedOriginId":null,"diskcache":false,"headerColor":"none","id":"cffe4e39-6b95-434c-837d-2088f930f55b","isComponent":false,"name":"","parents":[]},"id":"391bf1f6"},"source":["#### Description :\n","\n","\n","We could create :\n","\n","    * Lenght of description (dunno what informations it could provide yet)\n","    * Toold required (Excel, Google Tag Manager ...)\n","    * Coding languages required (R, Python, SQL ...)\n","    * Skills required (reporting, data visualization)\n","    * Required experience\n","    * Duration of contract\n","    * Avantages (ticket resto)\n"]},{"cell_type":"markdown","metadata":{"canvas":{"comments":[],"componentType":"CodeCell","copiedOriginId":null,"diskcache":false,"headerColor":"none","id":"1172d996-06c7-4bc9-861f-9d9e9d8c8e9c","isComponent":false,"name":"","parents":[]},"id":"00e3d02c"},"source":["## Visualizing aggregated job descriptions w/ WordCloud"]},{"cell_type":"markdown","metadata":{"canvas":{"comments":[],"componentType":"CodeCell","copiedOriginId":null,"diskcache":false,"headerColor":"none","id":"0d0a67b0-c07c-4f17-af2a-1ce4ba1487e9","isComponent":false,"name":"","parents":[]},"id":"466f87f2-444b-4423-87d3-42086b8e557c"},"source":["WordCloud provide a quick and visually appealing way to identify the most common terms and phrases used in job descriptions.\n","\n","Below i divided my dataframe by search query to get query-related wordclouds. Grouping data by job titles might have be more precise but as there are over 1300 unique job titles, the quick & easy wordcloud solution would have become less interesting. So i used search_query as a proxy."]},{"cell_type":"code","execution_count":null,"metadata":{"canvas":{"comments":[],"componentType":"CodeCell","copiedOriginId":null,"diskcache":false,"headerColor":"none","id":"7fb63ac1-5051-494c-9b07-46a94ca2cc4a","isComponent":false,"name":"","parents":[]},"tags":[],"id":"d50cbc73"},"outputs":[],"source":["# groupby data by search query and aggregate descriptions\n","agg_descriptions_by_query = data.groupby('search_query')['description_normalized'].sum().reset_index()\n","\n","\n","for job in agg_descriptions_by_query.search_query.values:\n","\n","    # get aggregated description for each query\n","    agg_text = agg_descriptions_by_query.loc[agg_descriptions_by_query.search_query == job, 'description_normalized'].values[0]\n","\n","    # Create a word cloud object and generate the word cloud\n","    wordcloud = WordCloud(width=800, height=800, background_color=\"white\").generate(agg_text)\n","    print(\"\\n***\",job,\"***\\n\")\n","\n","    # Display the word cloud\n","    plt.figure(figsize=(8, 8), facecolor=None)\n","    plt.imshow(wordcloud)\n","    plt.axis(\"off\")\n","    plt.tight_layout(pad=0)\n","    plt.show()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"canvas":{"comments":[],"componentType":"CodeCell","copiedOriginId":null,"diskcache":false,"headerColor":"none","id":"d9f06708-4e76-4d66-9e0b-2db385d28300","isComponent":false,"name":"","parents":[]},"tags":[],"id":"7f526509"},"outputs":[],"source":["additionnal_stop_words = [\"client\", \"solution\", \"service\", \"donnée\", \"plus\", \"busines\", \"entreprise\", \"développement\", \"produit, \"team\"]"]},{"cell_type":"markdown","metadata":{"canvas":{"comments":[],"componentType":"CodeCell","copiedOriginId":null,"diskcache":false,"headerColor":"none","id":"539e7bac-cd6d-42b7-a663-7e1176ca0f45","isComponent":false,"name":"","parents":[]},"id":"81e5836e"},"source":["## Performing N-grams tokenization on normalized job descripions"]},{"cell_type":"markdown","metadata":{"canvas":{"comments":[],"componentType":"CodeCell","copiedOriginId":null,"diskcache":false,"headerColor":"none","id":"1824c996-3836-434e-baee-3804b3ceadf5","isComponent":false,"name":"","parents":[]},"id":"6d9481ba-6f40-4254-8504-abb894e98084"},"source":["By using N-grams tokenization, we can create tokens that represent not just individual words, but also sequences of words that appear together frequently. This is important because the context in which words are used can greatly affect their meaning.\n","\n","These tokens might capture more complex and nuanced information about the job description and may provide more accurate insights into the skills, qualifications, and requirements of the job. "]},{"cell_type":"code","execution_count":null,"metadata":{"canvas":{"comments":[],"componentType":"CodeCell","copiedOriginId":null,"diskcache":false,"headerColor":"none","id":"420a604e-288a-4dfa-a7f5-18d7ff6b8938","isComponent":false,"name":"","parents":[]},"id":"513098b8"},"outputs":[],"source":["trigrams = []\n","bigrams = []\n","monograms = []\n","\n","def get_most_common_ngrams(data, n, k):\n","    \"\"\"\n","    This function takes a list of strings, an integer n (for the n-gram size), \n","    and an integer k (for the number of most common n-grams to return). \n","    It returns a list of the k most common n-grams in the input data.\n","    \"\"\"\n","    ngrams_list = []  # Create an empty list to store the n-grams\n","    \n","    for text in data:\n","        \n","        # Tokenize the text into words\n","        words = nltk.word_tokenize(text)\n","        # Generate the n-grams and add them to the list\n","        ngrams_list.extend(list(ngrams(words, n)))\n","        \n","    # Count the occurrences of each n-gram using FreqDist\n","    freq_dist = FreqDist(ngrams_list)\n","    \n","    # Get the k most common n-grams and return them\n","    return freq_dist.most_common(k)\n","\n","trigrams = get_most_common_ngrams(data.description_normalized, 3, 1000)\n","bigrams = get_most_common_ngrams(data.description_normalized, 2, 1000)\n","monograms = get_most_common_ngrams(data.description_normalized, 1, 1000)\n","\n","    \n","# Print the most common trigrams and bigrams\n","print(\"The 5 most common trigrams are:\\n\")\n","for trigram, count in trigrams[:5]:\n","    print(' '.join(trigram), count)\n","\n","print(\"\\nThe 5 most common bigrams are:\\n\")\n","for bigram, count in bigrams[:5]:\n","    print(' '.join(bigram), count)\n","    \n","print(\"\\nThe 5 most common monograms are:\\n\")\n","for monogram, count in monograms[:5]:\n","    print(' '.join(monogram), count)"]}]}