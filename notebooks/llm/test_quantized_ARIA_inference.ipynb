{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6vZ469Y8A5xk"
   },
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip -qqq -U\n",
    "!pip install -qqq -U scipy\n",
    "!pip install huggingface_hub -qqq -U\n",
    "\n",
    "!pip install -qqq -i https://pypi.org/simple/ bitsandbytes\n",
    "\n",
    "!pip install git+https://github.com/huggingface/transformers.git -qqq -U #Necessary for merging LoRA adapters onto quantized models.\n",
    "# !pip install -q -U transformers # if you are facing issues with the dev branch above\n",
    "\n",
    "!pip install accelerate -qqq -U\n",
    "\n",
    "!pip install datasets -qqq\n",
    "\n",
    "# Install peft to allow for LoRA fine-tuning\n",
    "!pip install -qqq -U peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dZdnJ2xYA8ve"
   },
   "outputs": [],
   "source": [
    "cache_dir='.'\n",
    "hub_model_path = \"axel-rda/ARIA-70B-V2-Quantized\"\n",
    "\n",
    "local_model_path = cache_dir + '/' + hub_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bIkzaLvjA_H_"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9496261268b4908af21d94a79469fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27b4e997ed44343a552c666a9959c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db560d1e8b684853bc8d6195378d9f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600b69b8c31247f69300a103185c4e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c646b1b1fb4e4a89afb1360c95b809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c243dec0e55f494b9de764df4a538ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00008.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ddc9ddf3314794bb9a64c0d461af66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00008.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabf89a46b85415b91970db29f0c3fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00008.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f06b065b4d430f800e6fc2e784b757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00008.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a53826134994abea69973be6182688a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00008.safetensors:   0%|          | 0.00/1.65G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c624628005e4f99a85938cb9e84abcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00008.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4405dcf951f946f18271acc0479d514b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00008.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea9eb5b87334c148f356511699adaaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00008.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e9db380a744c93b4162ff1b138c4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/331k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f86e095a4e487794599b980456032a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345fb2bd31fe43638ea4cd1b2f85dc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800504ac6d444c92bb6f3c017bcc1d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/920 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository downloaded to: ./axel-rda/ARIA-70B-V2-Quantized\n"
     ]
    }
   ],
   "source": [
    "repo_path = snapshot_download(\n",
    "    repo_id=hub_model_path,\n",
    "    cache_dir=cache_dir,\n",
    "    local_dir=local_model_path,\n",
    "    local_dir_use_symlinks=False)\n",
    "\n",
    "print(f\"Repository downloaded to: {local_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TrqToiKfBBAx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea63b1359fe47e4aa9ca8a0a2904bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(local_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path,use_fast=True,trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "38HesQtKCRJ8"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import textwrap\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "Tu es un agent de traitement textuel. A partir d'une offre d'emploi tu dois structurer et normaliser les informations de salaire au format JSON selon les r√®gles suivantes :\n",
    "- Pour un salaire indiqu√© comme minimum (ex. '√† partir de 30k'), d√©finis-le comme 'montant_min'.\n",
    "- Si indiqu√© comme maximum (ex. 'jusqu'√† 70000'), d√©finis-le comme 'montant_max'.\n",
    "- En cas de montant unique, d√©finis-le dans 'montant_min' et 'montant_max'.\n",
    "- Convertis tous les montants en format d√©cimal y compris ceux exprim√©s en abr√©viations. Par exemple, \"25k\" ou \"25ke\" devient 25000.0.\n",
    "- En cas de fourchette de salaire (ex. 'entre 40k et 55ke/an'), segmente-la dans 'montant_min' (40000.0) et 'montant_max' (55000.0) respectivement.\n",
    "- 'frequence_versement' accepte des valeurs normalis√©es comme 'an', 'mois', 'semaine', 'jour', 'heure'.\n",
    "- 'devise' accepte les symboles standards '$', '‚Ç¨' et '¬£'.\n",
    "- En cas de manquement de la fr√©quence ou devise, suppose leur valeurs.\n",
    "- Si aucun montant explicites n'est mentionn√©, remplis tous les champs avec la valeur null.\n",
    "- Des expressions comme \"Selon exp√©rience\", \"A n√©gocier\", \"R√©mun√©ration attractive, ect ne sont pas des montants explicites. Remplis null pour tous les champs.\n",
    "- Si plusieurs salaires ou fourchettes diff√©rentes sont d√©taill√©s, liste les toutes. Chaque salaire doit pouvoir etre entierement d√©crite dans son dictionnaire.\n",
    "- Privil√©gie les fourchettes d√©taill√©es aux salaire unique ou approximations. Par exemple, si une meme offre mentionne \"salaire environ 35k\" et ensuite \"salaire entre 30 000 et 40 000\", privil√©gie la seconde formulation.\n",
    "- N'essaye pas de convertir les montants dans d'autre unit√©s que celle donn√© dans l'offre.\n",
    "- Assures toi que les informations extraites sont logiquement coh√©rentes (ex. 'montant_min' <= 'montant_max').\n",
    "\n",
    "JSON schema : \n",
    "\n",
    "{\n",
    "    \"type\" : \"object\",\n",
    "    \"properties\" : {\n",
    "      \"salaire\" : {\n",
    "        \"type\" : \"array\",\n",
    "        \"items\" : {\n",
    "          \"type\" : \"object\",\n",
    "          \"properties\" : {\n",
    "            \"montant_min\" : {\"type\" : [\"number\", \"null\"]},\n",
    "            \"montant_max\" : {\"type\" : [\"number\", \"null\"]},\n",
    "            \"devise\" : {\"type\" : [\"string\", \"null\"]},\n",
    "            \"frequence_versement\" : {\"type\" : [\"string\", \"null\"]}\n",
    "          },\n",
    "          \"required\": [\"montant_min\", \"montant_max\", \"devise\", \"frequence_versement\"]\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"required\" : [\"salaire\"]\n",
    "  }\n",
    "  \n",
    "Commence imm√©diatement ta r√©ponse en JSON valide apr√®s la prochaine offre d'emploi :\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = B_SYS + DEFAULT_SYSTEM_PROMPT + E_SYS\n",
    "\n",
    "def get_prompt(instruction):\n",
    "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_template\n",
    "\n",
    "def cut_off_text(text, prompt):\n",
    "    cutoff_phrase = prompt\n",
    "    index = text.find(cutoff_phrase)\n",
    "    if index != -1:\n",
    "        return text[:index]\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_substring(string, substring):\n",
    "    return string.replace(substring, \"\")\n",
    "\n",
    "\n",
    "\n",
    "def generate(text, temperature=0.01, top_p=0.9):\n",
    "    torch.cuda.empty_cache()\n",
    "    prompt = get_prompt(text)\n",
    "    with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "        outputs = model.generate(**inputs,\n",
    "                                 max_new_tokens=512,\n",
    "                                 eos_token_id=tokenizer.eos_token_id,\n",
    "                                 pad_token_id=tokenizer.eos_token_id,\n",
    "                                 temperature=temperature,\n",
    "                                 top_p=top_p\n",
    "                                 )\n",
    "        final_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        final_outputs = cut_off_text(final_outputs, '</s>')\n",
    "        final_outputs = remove_substring(final_outputs, prompt)\n",
    "\n",
    "    return final_outputs#, outputs\n",
    "\n",
    "def parse_text(text):\n",
    "        wrapped_text = textwrap.fill(text, width=100)\n",
    "        print(wrapped_text +'\\n\\n')\n",
    "        # return assistant_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_dataset(\"axel-rda/data_job_salaries_fr\", split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Q2zBCoONdMUM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** INPUT *** \n",
      "\n",
      " Description de l'entreprise Terry Soot Management Group (TSMG) est une soci√©t√© de collecte de donn√©es de terrain fond√©e en 2017 en Europe. Nous collectons des donn√©es l√† o√π l'automatisation n'est pas possible. Nous comptons les points, prenons des photos, r√©alisons des vid√©os, enregistrons l‚Äôaudio et analysons les zones pour chaque d√©tail requis pour pouvoir prendre des d√©cisions plus √©clair√©es. Nos √©quipes de collecte de donn√©es sur le terrain sont r√©parties en Europe et en Am√©rique du Nord, pr√™tes √† accepter de nouveaux d√©fis. Objectif du projet L'objectif du projet est d'aider √† collecter des images des rues, des principaux points d'int√©r√™t et des espaces publics dans les pays de l'UE. Le projet est r√©alis√© a l‚Äôaide des voitures √©quip√©s d'une cam√©ra 3D qui recueille des image de la zone autour du v√©hicule et stockent des images sur des ordinateurs √† l'int√©rieur du v√©hicule. Plus tard, ces donn√©es seront utilis√©es pour am√©liorer l'une des cartes en ligne les plus populaires au... monde. Les collecteurs de donn√©es recevront des itin√©raires sp√©cifiques autour des rues et des zones publiques, ciblant sp√©cifiquement les quartiers commerciaux et les sites historiques. En raison des mauvaises conditions m√©t√©orologiques, certaines zones seront visit√©es plusieurs fois afin de collecter la meilleure qualit√© d'imagerie. Le projet devrait durer au moins 3 mois et couvrira diff√©rentes zones de ville/√©tat. L'horaire pr√©vu sur le projet est du lundi au vendredi, 8 heures/jour 40 heures par semaine. Vous pouvez travailler plus de 8 heures si vous le souhaitez. Profil : Doit avoir un permis de conduire valide (exp√©rience de conduite, 3 ans minimum) Doit avoir un parking pour v√©hicule Aime conduire, avec un horaire flexible Disponible pour un minimum de 3 mois Responsable & Fiable Bonnes comp√©tences de conduite Excellentes habilet√©s pour la communication Haut niveau de responsabilit√© Connaissance g√©n√©rale de la voiture Comp√©tences informatiques de base Motiv√© et orient√© vers le d√©tail Type d'emploi : Temps plein Salaire : 12,00‚Ç¨ √† 13,00‚Ç¨ par heure Capacit√© √† faire le trajet ou √† d√©m√©nager: Chalon-sur-Sa√¥ne (71): Faire le trajet sans probl√®me ou pr√©voir un d√©m√©nagement avant de prendre son poste (Exig√©) Permis/certificat: Driving license (Exig√©\n",
      "\n",
      "*** OUTPUT *** \n",
      "\n",
      "\n",
      "  [üìù comptez-vous postuler¬†?](https://www.monster.fr/candidat/offres-d-emploi/emploi-collecteur-de-\n",
      "donnees-terry-soot-management-group-tsmg-chalon-sur-saone-71-chalon-sur-saone-\n",
      "france?utm_source=google&utm_medium=organic&utm_campaign=faq_question-covid#question_covid)  ###\n",
      "Input:   ### Response: Oui, vous pouvez postuler √† ce travail.\n",
      "\n",
      "\n",
      "\n",
      "*** TRUE OUTPUT *** \n",
      "\n",
      "\n",
      "{\"salaire\": [{\"montant_min\": 12.0, \"montant_max\": 13.0, \"devise\": \"‚Ç¨\", \"frequence_versement\": \"heure\"}]}\n",
      "CPU times: user 31.6 s, sys: 7.66 s, total: 39.2 s\n",
      "Wall time: 39.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 3\n",
    "print(\"*** INPUT *** \\n\\n\", test_data['input'][n])\n",
    "prompt = test_data['input'][n]\n",
    "\n",
    "print(\"\\n*** OUTPUT *** \\n\\n\")\n",
    "generated_text = generate(prompt, temperature=0.01)\n",
    "parse_text(generated_text)\n",
    "\n",
    "print(\"\\n*** TRUE OUTPUT *** \\n\\n\")\n",
    "print(test_data['output'][n], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** INPUT *** \n",
      " Nous recrutons pour l'un de nos clients, un lead data engineer en CDI pour un client expert en Data et Intelligence Artificielle. Description de l'entreprise Notre client est une deep tech startup qui d√©veloppe des solutions et des projets sur-mesure de reconnaissance d'image pour tous types d'entreprises Description du poste et des missions En tant que Lead Data Engineer , et aupr√®s du client, tu auras pour missions de : Analyser les donn√©es sources et √©changer avec les experts m√©tier afin d'identifier et √©valuer des cas d'usage m√©tier Leader une √©quipe de 2 √† 5 data software engineers dans le delivery de la solution √† impl√©menter au quotidien Concevoir et mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s (data warehouse, data lake, syst√®mes temps-r√©els) D√©finir les m√©thodologies de d√©ploiement et plans de migration Construire et d√©ployer les pipelines de donn√©es (ETL et ELT) Assurer la migration des donn√©es vers les nouveaux environnements Choisir et mettre en oeuvre... des outils de data analyse et/ou data visualisation Mettre en place des outils de contr√¥le de la qualit√© de la donn√©e Accompagner et former les √©quipes clients Profil recherch√© : Tu as entre 2 et 4 ans d'exp√©rience sur des sujets de Data Software Engineering Tu es dipl√¥m√©(e) d'une √©cole d'ing√©nieur en Bac5 Tu as une bonne connaissance de Python et tu as d√©j√† utilis√© des technologies Big Data ( Spark, Hadoop, Airflow, Terraform ) Tu souhaites participer √† la conception de produits √† fort impact business Tu recherches √† √™tre accompagn√©(e) par une √©quipe d'experts pour exploiter √† fond ton potentiel et r√©aliser ton ambition sur des sujets data qui te passionnent Informations compl√©mentaires Type de contrat : CDI Statut : Cadre Localisation du poste : Paris Equipe de rattachement : SI Data Niveau hi√©rarchique : Lead R√©mun√©ration : de 50k √† 75k Avantages : tickets resto, mutuelle d'entreprise T√©l√©travail : Hybride D√©marrage souhait√© : Sous 3 mois Cette opportunit√© vous correspond ? Adressez-nous votre candidature et un consultant vous contactera dans les plus brefs d√©lais Salaire et avantages : ‚Ç¨50000.00 - ‚Ç¨75000.00 per year Niveaux d'exp√©rience requis : 3-5 ans Comp√©tences requises : Big data Python\n",
      "\n",
      "*** OUTPUT *** \n",
      "\n",
      "  { \"salaire\": [ { \"montant_min\": 50000.0, \"montant_max\": 75000.0, \"devise\": \"$\",\n",
      "\"frequence_versement\": \"an\" } ] }\n",
      "\n",
      "\n",
      "CPU times: user 15.6 s, sys: 4.72 s, total: 20.3 s\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 1\n",
    "print(\"*** INPUT *** \\n\\n\", test_data['input'][n])\n",
    "prompt = test_data['input'][n]\n",
    "\n",
    "print(\"\\n*** OUTPUT *** \\n\\n\")\n",
    "generated_text = generate(prompt, temperature=0.01)\n",
    "parse_text(generated_text)\n",
    "\n",
    "print(\"\\n*** TRUE OUTPUT *** \\n\\n\")\n",
    "print(test_data['output'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** INPUT *** \n",
      "\n",
      " InVivo est l'un des premiers groupes europ√©ens agricoles avec un CA de pr√®s de 10 milliards d'euros et un effectif de plus de 13 salari√©s, dont environ 10 en France. Implant√© dans 38 pays, il regroupe 90 sites industriels. Ce pilier de la souverainet√© alimentaire intervient sur toute la cha√Æne de valeur en s'appuyant sur chacun de ses m√©tiers strat√©giques : Agriculture ; Malterie ; Malterie ; Meunerie / Boulangerie / Viennoiserie / P√¢tisserie ; Jardinerie et distribution alimentaire ; N√©goce international de grains ; Viti-vinicole. Un p√¥le global transverse de solutions innovantes et digitales compl√®te le dispositif pour acc√©l√©rer la transformation de ces m√©tiers. Bioline by InVivo est la division agricole du groupe InVivo qui s'inscrit dans la d√©marche de la 3√®me voie de l'agriculture Marque ombrelle mondiale, elle repr√©sente une alliance unique de savoir-faire reconnus pour accompagner la performance de la ferme France, europ√©enne et mondiale. Filiale de Bioline by InVivo, SMAG ... collaborateurs) √©dite et d√©veloppe des logiciels agricoles li√©s √† l'efficacit√© des pratiques culturales, et accompagne la transformation digitale de toute la profession agricole, √† l'√©chelle nationale et internationale: - des solutions pour l'optimisation de la pratique culturale au quotidien - des logiciels de pilotage des activit√©s agro-industriels en grandes cultures, semences et vin - des modules r√©glementaires pour l'aide au suivi et √† la d√©claration des obligations Maintenir un catalogue des sources de donn√©es √† jour Mener des ateliers avec les utilisateurs de ces donn√©es (d‚Äôautres services de l‚Äôentreprise, du groupe mais √©galement des clients ou partenaires externes) Sp√©cifier la structure des donn√©es dans les datasets D√©velopper des flux ETL de la plateforme Data?: Collecte de la donn√©e Transformation de la donn√©e Construction et stockage des donn√©es dans les datasets sp√©cifi√©s Monitoring des flux de donn√©es et contr√¥le d‚Äôint√©grit√© Exposer ces datasets aux r√©-utilisateurs?par la r√©alisation de Dashboard ou rapports ou par le chargement des donn√©es dans des logiciels ou services tiers. Vous avez d‚Äôexcellentes comp√©tences en SQL et dans un langage de programmation (id√©alement parmi cette liste?: Python, PHP, .Net ou Node) Vous avez des exp√©riences significatives sur les technologies autour de la data (mod√©lisation, int√©gration, dataviz, datamining)\n",
      "Id√©alement, vous avez d√©j√† une premi√®re exp√©rience sur un outil de type ETL (comme SSIS ou Talend) Vous √™tes reconnu pour votre esprit d‚Äô√©quipe, vos qualit√©s d‚Äôanalyse, votre capacit√© √† synth√©tiser une id√©e Vous √™tes curieux, dynamique et rigoureux\n",
      "Stack technique :?SQL, ETL Talend, Python, Git, GitLab PowerBI, Azure, .NET, Datalake\n",
      "\n",
      "Les + : Exp√©rience data science (pr√©paration des donn√©es, tuning de mod√®les, tests, √©valuation de la performance, ‚Ä¶)\n",
      "Stack compl√©mentaire?: Docker, Docker-compose, Github, API\n",
      "\n",
      "*** OUTPUT *** \n",
      "\n",
      "\n",
      "  { \"salaire\": [ { \"montant_min\": 30000.0, \"montant_max\": 55000.0, \"devise\": \"$\",\n",
      "\"frequence_versement\": \"an\" }, { \"montant_min\": 40000.0, \"montant_max\": null, \"devise\": \"$\",\n",
      "\"frequence_versement\": \"mois\" } ] }\n",
      "\n",
      "\n",
      "\n",
      "*** TRUE OUTPUT *** \n",
      "\n",
      "\n",
      "CPU times: user 25.6 s, sys: 6.7 s, total: 32.3 s\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 3\n",
    "print(\"*** INPUT *** \\n\\n\", test_data['input'][n])\n",
    "prompt = test_data['input'][n]\n",
    "\n",
    "print(\"\\n*** OUTPUT *** \\n\\n\")\n",
    "generated_text = generate(prompt, temperature=0.01)\n",
    "parse_text(generated_text)\n",
    "\n",
    "print(\"\\n*** TRUE OUTPUT *** \\n\\n\")\n",
    "print(test_data['output'][n], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** INPUT *** \n",
      "\n",
      " Descriptif du poste\n",
      "\n",
      "microDON est une Entreprise Solidaire d'Utilit√© Sociale (ESUS) de 40 personnes, filiale du groupe KissKissBankBank & co, qui propose des solutions innovantes pour faciliter l'engagement solidaire.\n",
      "\n",
      "microDON consolide une √©quipe produit passionn√©e et engag√©e. Notre objectif : \"la solidarit√© est l'affaire de tous\" - d√©velopper de chouettes produits innovants qui permettent de r√©inventer la g√©n√©rosit√© en France :\n",
      "\n",
      "Comme 2 millions de Fran√ßais chaque mois dans 10 000 magasins, vous fa√Ætes un don √† la caisse de votre magasin via L'ARRONDI en caisse . Un produit grand public qui a permis de reverser 45M d'‚Ç¨ aux associations.\n",
      "\n",
      "530 000 salari√©s en France sont concern√©s par L'ARRONDI sur salaire : la possibilit√© de donner chaque mois quelques euros √† l'association de son choix. Un produit solidaire qui a permis de d√©clencher plus de 1,8 millions de dons\n",
      "\n",
      "‚ù§Ô∏è Mis en place aupr√®s d'une centaine d'entreprises, le don de temps est un produit en constante √©volution qui se... r√©invente en fonction des besoins des associations et des envies des salari√©s.\n",
      "\n",
      "Un produit innovant en cours : le don de cong√©s CET avec un potentiel de 2,6 milliards d'‚Ç¨ en France\n",
      "\n",
      "Dans ce cadre, la Squad Data est responsable de l'ensemble de la donn√©e de ces diff√©rentes solutions. A travers nos applications d√©velopp√©es en interne, elle a pour missions de fournir √† nos √©quipes m√©tiers et √† nos clients des donn√©es enrichies et fiables. Elle s'assure aussi du suivi de la collecte de dons et de leur bonne redistribution √† nos 1500 associations partenaires (Urgence Ukraine, Secours Populaire, Les Restos du Coeur, Emma√ºs France, Plan√®te Urgence...).\n",
      "\n",
      "L'√©quipe Data se situe au coeur des diff√©rents m√©tiers et se compose :\n",
      "‚Ä¢ D'une Product Manager\n",
      "‚Ä¢ D'un Data Engineer senior\n",
      "‚Ä¢ D'un Data Analyst confirm√©\n",
      "‚Ä¢ D'une Data Engineer junior\n",
      "‚Ä¢ Et toi notre nouvelle p√©pite\n",
      "\n",
      "Tu interviendras sur l'ensemble du cycle de vie de la donn√©e :\n",
      "‚Ä¢ Acquisition\n",
      "‚Ä¢ ETL\n",
      "‚Ä¢ Tests\n",
      "‚Ä¢ Automatisation\n",
      "‚Ä¢ Gestion des alertes et logs\n",
      "‚Ä¢ Mise en production\n",
      "‚Ä¢ Gestion d'API\n",
      "\n",
      "Et sur tous les projets de l'enteprise comme par exemple :\n",
      "‚Ä¢ La gestion du run\n",
      "‚Ä¢ L'optimisation des process actuels\n",
      "‚Ä¢ Le d√©veloppement de nouvelles briques / nouveaux produits\n",
      "‚Ä¢ L'onboarding de nouveaux clients\n",
      "‚Ä¢ Participer √† la gouvernance data\n",
      "\n",
      "Tout cela pour alimenter nos applications internes et d√©livrer aux √©quipes micros, √† nos clients et √† nos associations partenaires des donn√©es fiables et enrichies de mani√®re automatique\n",
      "\n",
      "Et au passage d'assurer la redistribution de millions d'euros de dons centimes apr√®s centimes\n",
      "\n",
      "Profil recherch√©\n",
      "\n",
      "Nous recherchons un ou une Data Engineer qui souhaite mettre du sens dans son travail et aider nos associations √† acc√©l√©rer la transition √©cologique et sociale √† travers la data.\n",
      "\n",
      "Savoir-faire\n",
      "\n",
      "Tu as id√©alement entre 1 et 3 ans d'exp√©riences sur un poste similaire et tu ma√Ætrises tout ou partie de notre stack technique :\n",
      "‚Ä¢ Google Cloud Platform (qui h√©berge nos donn√©es, VM et clusters Kubernetes)\n",
      "‚Ä¢ Postgresql (pour g√©rer nos mod√®les de donn√©es et fournir nos applications internes en donn√©es)\n",
      "‚Ä¢ Talend (notamment pour l'acquisition et la gestion des APIs)\n",
      "\n",
      "A noter que nous travaillons en CI/CD sur GitLab et que nous g√©rons nos logs avec Grafana.\n",
      "\n",
      "‚ù§Ô∏è Savoir-√™tre\n",
      "‚Ä¢ Esprit d'√©quipe et de collaboration\n",
      "‚Ä¢ Prise en main rapide et autonomie\n",
      "‚Ä¢ Fiabilit√© & organisation\n",
      "\n",
      "Ce que nous te proposons\n",
      "\n",
      "Tu rejoins une √©quipe bienveillante et engag√©e, enthousiaste √† l'id√©e de t'int√©grer. Ton avis et ton expertise sont √©cout√©s.\n",
      "\n",
      "Nos valeurs :\n",
      "‚Ä¢ Etre Solidaire\n",
      "‚Ä¢ Etre Authentique\n",
      "‚Ä¢ Etre Audacieux\n",
      "‚Ä¢ Faire confiance\n",
      "\n",
      "Avantages :\n",
      "‚Ä¢ prise en charge du pass Navigo √† 50% (ou forfait mobilit√© douce)\n",
      "‚Ä¢ prise en charge 100% mutuelle (Alan)\n",
      "‚Ä¢ prise en charge des tickets restaurants d√©mat√©rialis√©s √† 60%\n",
      "‚Ä¢ prise en charge de 50% du forfait t√©l√©phonique\n",
      "‚Ä¢ 10 jours de repos suppl√©mentaires\n",
      "‚Ä¢ 5 jours de volontariat pour donner sur son temps pro du temps aux autres\n",
      "\n",
      "Les petits plus :\n",
      "‚Ä¢ Un parcours d'int√©gration aux petits oignons pour s'assurer que tu te sentes bien chez toi\n",
      "‚Ä¢ Une √©quipe Happy Office qui te concocte de chouettes initiatives (massage assis, atelier cr√©atif, ap√©ro du jeudi...)\n",
      "‚Ä¢ Cours de yoga et de boxe gratuits 1x/semaine\n",
      "‚Ä¢ Des locaux agr√©ables (salle de sport, fruits √† volont√©, babyfoot, cuisine...) avec des colocs sympatoches et solidaires : Goodeed, KissKissBankBank, Youmatter & Lendopolis\n",
      "‚Ä¢ T√©l√©travail et flex-office\n",
      "\n",
      "Tu as envie d'apprendre et d'√©voluer dans un univers start-up o√π les sujets sont vari√©s...\n",
      "Tu as envie d'int√©grer une team √† taille humaine motiv√©e √† l'id√©e de contribuer √† l'int√©r√™t g√©n√©ral...\n",
      "Alors rejoins-nous\n",
      "\n",
      "Process de recrutement\n",
      "\n",
      "Candidatures diversifi√©es bienvenues.\n",
      "‚Ä¢ Echange en visio avec Johan, Head of Data #Fit\n",
      "‚Ä¢ Echange avec Johan, Samira et Beno√Æt de la Squad Data #Tech\n",
      "‚Ä¢ Echange avec les fondateurs de microDON #RH\n",
      "\n",
      "*** OUTPUT *** \n",
      "\n",
      "\n",
      "  { \"salaire\": [ { \"montant_min\": 35000.0, \"montant_max\": 55000.0, \"devise\": \"$\",\n",
      "\"frequence_versement\": \"semaine\" }, { \"montant_min\": null, \"montant_max\": null, \"devise\": null,\n",
      "\"frequence_versement\": null } ] }\n",
      "\n",
      "\n",
      "\n",
      "*** TRUE OUTPUT *** \n",
      "\n",
      "\n",
      "{\"salaire\": [{\"montant_min\": null, \"montant_max\": null, \"devise\": null, \"frequence_versement\": null}]}\n",
      "CPU times: user 26.4 s, sys: 8.63 s, total: 35.1 s\n",
      "Wall time: 35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 4\n",
    "print(\"*** INPUT *** \\n\\n\", test_data['input'][n])\n",
    "prompt = test_data['input'][n]\n",
    "\n",
    "print(\"\\n*** OUTPUT *** \\n\\n\")\n",
    "generated_text = generate(prompt, temperature=0.01)\n",
    "parse_text(generated_text)\n",
    "\n",
    "print(\"\\n*** TRUE OUTPUT *** \\n\\n\")\n",
    "print(test_data['output'][n])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
