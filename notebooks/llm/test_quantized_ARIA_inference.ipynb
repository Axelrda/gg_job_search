{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6vZ469Y8A5xk"
   },
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip -qqq -U\n",
    "!pip install -qqq -U scipy\n",
    "!pip install huggingface_hub -qqq -U\n",
    "\n",
    "!pip install -qqq -i https://pypi.org/simple/ bitsandbytes\n",
    "\n",
    "!pip install git+https://github.com/huggingface/transformers.git -qqq -U #Necessary for merging LoRA adapters onto quantized models.\n",
    "# !pip install -q -U transformers # if you are facing issues with the dev branch above\n",
    "\n",
    "!pip install accelerate -qqq -U\n",
    "\n",
    "!pip install datasets -qqq\n",
    "\n",
    "# Install peft to allow for LoRA fine-tuning\n",
    "!pip install -qqq -U peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dZdnJ2xYA8ve"
   },
   "outputs": [],
   "source": [
    "cache_dir='.'\n",
    "hub_model_path = \"axel-rda/ARIA-70B-V2-Quantized\"\n",
    "\n",
    "local_model_path = cache_dir + '/' + hub_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bIkzaLvjA_H_"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9496261268b4908af21d94a79469fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27b4e997ed44343a552c666a9959c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db560d1e8b684853bc8d6195378d9f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600b69b8c31247f69300a103185c4e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c646b1b1fb4e4a89afb1360c95b809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c243dec0e55f494b9de764df4a538ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00008.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ddc9ddf3314794bb9a64c0d461af66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00008.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabf89a46b85415b91970db29f0c3fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00008.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f06b065b4d430f800e6fc2e784b757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00008.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a53826134994abea69973be6182688a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00008.safetensors:   0%|          | 0.00/1.65G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c624628005e4f99a85938cb9e84abcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00008.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4405dcf951f946f18271acc0479d514b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00008.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea9eb5b87334c148f356511699adaaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00008.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e9db380a744c93b4162ff1b138c4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/331k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f86e095a4e487794599b980456032a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345fb2bd31fe43638ea4cd1b2f85dc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800504ac6d444c92bb6f3c017bcc1d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/920 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository downloaded to: ./axel-rda/ARIA-70B-V2-Quantized\n"
     ]
    }
   ],
   "source": [
    "repo_path = snapshot_download(\n",
    "    repo_id=hub_model_path,\n",
    "    cache_dir=cache_dir,\n",
    "    local_dir=local_model_path,\n",
    "    local_dir_use_symlinks=False)\n",
    "\n",
    "print(f\"Repository downloaded to: {local_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TrqToiKfBBAx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea63b1359fe47e4aa9ca8a0a2904bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(local_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path,use_fast=True,trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "38HesQtKCRJ8"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import textwrap\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "Tu es un agent de traitement textuel. A partir d'une offre d'emploi tu dois structurer et normaliser les informations de salaire au format JSON selon les règles suivantes :\n",
    "- Pour un salaire indiqué comme minimum (ex. 'à partir de 30k'), définis-le comme 'montant_min'.\n",
    "- Si indiqué comme maximum (ex. 'jusqu'à 70000'), définis-le comme 'montant_max'.\n",
    "- En cas de montant unique, définis-le dans 'montant_min' et 'montant_max'.\n",
    "- Convertis tous les montants en format décimal y compris ceux exprimés en abréviations. Par exemple, \"25k\" ou \"25ke\" devient 25000.0.\n",
    "- En cas de fourchette de salaire (ex. 'entre 40k et 55ke/an'), segmente-la dans 'montant_min' (40000.0) et 'montant_max' (55000.0) respectivement.\n",
    "- 'frequence_versement' accepte des valeurs normalisées comme 'an', 'mois', 'semaine', 'jour', 'heure'.\n",
    "- 'devise' accepte les symboles standards '$', '€' et '£'.\n",
    "- En cas de manquement de la fréquence ou devise, suppose leur valeurs.\n",
    "- Si aucun montant explicites n'est mentionné, remplis tous les champs avec la valeur null.\n",
    "- Des expressions comme \"Selon expérience\", \"A négocier\", \"Rémunération attractive, ect ne sont pas des montants explicites. Remplis null pour tous les champs.\n",
    "- Si plusieurs salaires ou fourchettes différentes sont détaillés, liste les toutes. Chaque salaire doit pouvoir etre entierement décrite dans son dictionnaire.\n",
    "- Privilégie les fourchettes détaillées aux salaire unique ou approximations. Par exemple, si une meme offre mentionne \"salaire environ 35k\" et ensuite \"salaire entre 30 000 et 40 000\", privilégie la seconde formulation.\n",
    "- N'essaye pas de convertir les montants dans d'autre unités que celle donné dans l'offre.\n",
    "- Assures toi que les informations extraites sont logiquement cohérentes (ex. 'montant_min' <= 'montant_max').\n",
    "\n",
    "JSON schema : \n",
    "\n",
    "{\n",
    "    \"type\" : \"object\",\n",
    "    \"properties\" : {\n",
    "      \"salaire\" : {\n",
    "        \"type\" : \"array\",\n",
    "        \"items\" : {\n",
    "          \"type\" : \"object\",\n",
    "          \"properties\" : {\n",
    "            \"montant_min\" : {\"type\" : [\"number\", \"null\"]},\n",
    "            \"montant_max\" : {\"type\" : [\"number\", \"null\"]},\n",
    "            \"devise\" : {\"type\" : [\"string\", \"null\"]},\n",
    "            \"frequence_versement\" : {\"type\" : [\"string\", \"null\"]}\n",
    "          },\n",
    "          \"required\": [\"montant_min\", \"montant_max\", \"devise\", \"frequence_versement\"]\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"required\" : [\"salaire\"]\n",
    "  }\n",
    "  \n",
    "Commence immédiatement ta réponse en JSON valide après la prochaine offre d'emploi :\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = B_SYS + DEFAULT_SYSTEM_PROMPT + E_SYS\n",
    "\n",
    "def get_prompt(instruction):\n",
    "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_template\n",
    "\n",
    "def cut_off_text(text, prompt):\n",
    "    cutoff_phrase = prompt\n",
    "    index = text.find(cutoff_phrase)\n",
    "    if index != -1:\n",
    "        return text[:index]\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_substring(string, substring):\n",
    "    return string.replace(substring, \"\")\n",
    "\n",
    "\n",
    "\n",
    "def generate(text, temperature=0.01, top_p=0.9):\n",
    "    torch.cuda.empty_cache()\n",
    "    prompt = get_prompt(text)\n",
    "    with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "        outputs = model.generate(**inputs,\n",
    "                                 max_new_tokens=512,\n",
    "                                 eos_token_id=tokenizer.eos_token_id,\n",
    "                                 pad_token_id=tokenizer.eos_token_id,\n",
    "                                 temperature=temperature,\n",
    "                                 top_p=top_p\n",
    "                                 )\n",
    "        final_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        final_outputs = cut_off_text(final_outputs, '</s>')\n",
    "        final_outputs = remove_substring(final_outputs, prompt)\n",
    "\n",
    "    return final_outputs#, outputs\n",
    "\n",
    "def parse_text(text):\n",
    "        wrapped_text = textwrap.fill(text, width=100)\n",
    "        print(wrapped_text +'\\n\\n')\n",
    "        # return assistant_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_dataset(\"axel-rda/data_job_salaries_fr\", split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Q2zBCoONdMUM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** INPUT *** \n",
      "\n",
      " Description de l'entreprise Terry Soot Management Group (TSMG) est une société de collecte de données de terrain fondée en 2017 en Europe. Nous collectons des données là où l'automatisation n'est pas possible. Nous comptons les points, prenons des photos, réalisons des vidéos, enregistrons l’audio et analysons les zones pour chaque détail requis pour pouvoir prendre des décisions plus éclairées. Nos équipes de collecte de données sur le terrain sont réparties en Europe et en Amérique du Nord, prêtes à accepter de nouveaux défis. Objectif du projet L'objectif du projet est d'aider à collecter des images des rues, des principaux points d'intérêt et des espaces publics dans les pays de l'UE. Le projet est réalisé a l’aide des voitures équipés d'une caméra 3D qui recueille des image de la zone autour du véhicule et stockent des images sur des ordinateurs à l'intérieur du véhicule. Plus tard, ces données seront utilisées pour améliorer l'une des cartes en ligne les plus populaires au... monde. Les collecteurs de données recevront des itinéraires spécifiques autour des rues et des zones publiques, ciblant spécifiquement les quartiers commerciaux et les sites historiques. En raison des mauvaises conditions météorologiques, certaines zones seront visitées plusieurs fois afin de collecter la meilleure qualité d'imagerie. Le projet devrait durer au moins 3 mois et couvrira différentes zones de ville/état. L'horaire prévu sur le projet est du lundi au vendredi, 8 heures/jour 40 heures par semaine. Vous pouvez travailler plus de 8 heures si vous le souhaitez. Profil : Doit avoir un permis de conduire valide (expérience de conduite, 3 ans minimum) Doit avoir un parking pour véhicule Aime conduire, avec un horaire flexible Disponible pour un minimum de 3 mois Responsable & Fiable Bonnes compétences de conduite Excellentes habiletés pour la communication Haut niveau de responsabilité Connaissance générale de la voiture Compétences informatiques de base Motivé et orienté vers le détail Type d'emploi : Temps plein Salaire : 12,00€ à 13,00€ par heure Capacité à faire le trajet ou à déménager: Chalon-sur-Saône (71): Faire le trajet sans problème ou prévoir un déménagement avant de prendre son poste (Exigé) Permis/certificat: Driving license (Exigé\n",
      "\n",
      "*** OUTPUT *** \n",
      "\n",
      "\n",
      "  [📝 comptez-vous postuler ?](https://www.monster.fr/candidat/offres-d-emploi/emploi-collecteur-de-\n",
      "donnees-terry-soot-management-group-tsmg-chalon-sur-saone-71-chalon-sur-saone-\n",
      "france?utm_source=google&utm_medium=organic&utm_campaign=faq_question-covid#question_covid)  ###\n",
      "Input:   ### Response: Oui, vous pouvez postuler à ce travail.\n",
      "\n",
      "\n",
      "\n",
      "*** TRUE OUTPUT *** \n",
      "\n",
      "\n",
      "{\"salaire\": [{\"montant_min\": 12.0, \"montant_max\": 13.0, \"devise\": \"€\", \"frequence_versement\": \"heure\"}]}\n",
      "CPU times: user 31.6 s, sys: 7.66 s, total: 39.2 s\n",
      "Wall time: 39.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 3\n",
    "print(\"*** INPUT *** \\n\\n\", test_data['input'][n])\n",
    "prompt = test_data['input'][n]\n",
    "\n",
    "print(\"\\n*** OUTPUT *** \\n\\n\")\n",
    "generated_text = generate(prompt, temperature=0.01)\n",
    "parse_text(generated_text)\n",
    "\n",
    "print(\"\\n*** TRUE OUTPUT *** \\n\\n\")\n",
    "print(test_data['output'][n], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** INPUT *** \n",
      " Nous recrutons pour l'un de nos clients, un lead data engineer en CDI pour un client expert en Data et Intelligence Artificielle. Description de l'entreprise Notre client est une deep tech startup qui développe des solutions et des projets sur-mesure de reconnaissance d'image pour tous types d'entreprises Description du poste et des missions En tant que Lead Data Engineer , et auprès du client, tu auras pour missions de : Analyser les données sources et échanger avec les experts métier afin d'identifier et évaluer des cas d'usage métier Leader une équipe de 2 à 5 data software engineers dans le delivery de la solution à implémenter au quotidien Concevoir et mettre en place des systèmes de données résilients et sécurisés (data warehouse, data lake, systèmes temps-réels) Définir les méthodologies de déploiement et plans de migration Construire et déployer les pipelines de données (ETL et ELT) Assurer la migration des données vers les nouveaux environnements Choisir et mettre en oeuvre... des outils de data analyse et/ou data visualisation Mettre en place des outils de contrôle de la qualité de la donnée Accompagner et former les équipes clients Profil recherché : Tu as entre 2 et 4 ans d'expérience sur des sujets de Data Software Engineering Tu es diplômé(e) d'une école d'ingénieur en Bac5 Tu as une bonne connaissance de Python et tu as déjà utilisé des technologies Big Data ( Spark, Hadoop, Airflow, Terraform ) Tu souhaites participer à la conception de produits à fort impact business Tu recherches à être accompagné(e) par une équipe d'experts pour exploiter à fond ton potentiel et réaliser ton ambition sur des sujets data qui te passionnent Informations complémentaires Type de contrat : CDI Statut : Cadre Localisation du poste : Paris Equipe de rattachement : SI Data Niveau hiérarchique : Lead Rémunération : de 50k à 75k Avantages : tickets resto, mutuelle d'entreprise Télétravail : Hybride Démarrage souhaité : Sous 3 mois Cette opportunité vous correspond ? Adressez-nous votre candidature et un consultant vous contactera dans les plus brefs délais Salaire et avantages : €50000.00 - €75000.00 per year Niveaux d'expérience requis : 3-5 ans Compétences requises : Big data Python\n",
      "\n",
      "*** OUTPUT *** \n",
      "\n",
      "  { \"salaire\": [ { \"montant_min\": 50000.0, \"montant_max\": 75000.0, \"devise\": \"$\",\n",
      "\"frequence_versement\": \"an\" } ] }\n",
      "\n",
      "\n",
      "CPU times: user 15.6 s, sys: 4.72 s, total: 20.3 s\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 1\n",
    "print(\"*** INPUT *** \\n\\n\", test_data['input'][n])\n",
    "prompt = test_data['input'][n]\n",
    "\n",
    "print(\"\\n*** OUTPUT *** \\n\\n\")\n",
    "generated_text = generate(prompt, temperature=0.01)\n",
    "parse_text(generated_text)\n",
    "\n",
    "print(\"\\n*** TRUE OUTPUT *** \\n\\n\")\n",
    "print(test_data['output'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** INPUT *** \n",
      "\n",
      " InVivo est l'un des premiers groupes européens agricoles avec un CA de près de 10 milliards d'euros et un effectif de plus de 13 salariés, dont environ 10 en France. Implanté dans 38 pays, il regroupe 90 sites industriels. Ce pilier de la souveraineté alimentaire intervient sur toute la chaîne de valeur en s'appuyant sur chacun de ses métiers stratégiques : Agriculture ; Malterie ; Malterie ; Meunerie / Boulangerie / Viennoiserie / Pâtisserie ; Jardinerie et distribution alimentaire ; Négoce international de grains ; Viti-vinicole. Un pôle global transverse de solutions innovantes et digitales complète le dispositif pour accélérer la transformation de ces métiers. Bioline by InVivo est la division agricole du groupe InVivo qui s'inscrit dans la démarche de la 3ème voie de l'agriculture Marque ombrelle mondiale, elle représente une alliance unique de savoir-faire reconnus pour accompagner la performance de la ferme France, européenne et mondiale. Filiale de Bioline by InVivo, SMAG ... collaborateurs) édite et développe des logiciels agricoles liés à l'efficacité des pratiques culturales, et accompagne la transformation digitale de toute la profession agricole, à l'échelle nationale et internationale: - des solutions pour l'optimisation de la pratique culturale au quotidien - des logiciels de pilotage des activités agro-industriels en grandes cultures, semences et vin - des modules réglementaires pour l'aide au suivi et à la déclaration des obligations Maintenir un catalogue des sources de données à jour Mener des ateliers avec les utilisateurs de ces données (d’autres services de l’entreprise, du groupe mais également des clients ou partenaires externes) Spécifier la structure des données dans les datasets Développer des flux ETL de la plateforme Data?: Collecte de la donnée Transformation de la donnée Construction et stockage des données dans les datasets spécifiés Monitoring des flux de données et contrôle d’intégrité Exposer ces datasets aux ré-utilisateurs?par la réalisation de Dashboard ou rapports ou par le chargement des données dans des logiciels ou services tiers. Vous avez d’excellentes compétences en SQL et dans un langage de programmation (idéalement parmi cette liste?: Python, PHP, .Net ou Node) Vous avez des expériences significatives sur les technologies autour de la data (modélisation, intégration, dataviz, datamining)\n",
      "Idéalement, vous avez déjà une première expérience sur un outil de type ETL (comme SSIS ou Talend) Vous êtes reconnu pour votre esprit d’équipe, vos qualités d’analyse, votre capacité à synthétiser une idée Vous êtes curieux, dynamique et rigoureux\n",
      "Stack technique :?SQL, ETL Talend, Python, Git, GitLab PowerBI, Azure, .NET, Datalake\n",
      "\n",
      "Les + : Expérience data science (préparation des données, tuning de modèles, tests, évaluation de la performance, …)\n",
      "Stack complémentaire?: Docker, Docker-compose, Github, API\n",
      "\n",
      "*** OUTPUT *** \n",
      "\n",
      "\n",
      "  { \"salaire\": [ { \"montant_min\": 30000.0, \"montant_max\": 55000.0, \"devise\": \"$\",\n",
      "\"frequence_versement\": \"an\" }, { \"montant_min\": 40000.0, \"montant_max\": null, \"devise\": \"$\",\n",
      "\"frequence_versement\": \"mois\" } ] }\n",
      "\n",
      "\n",
      "\n",
      "*** TRUE OUTPUT *** \n",
      "\n",
      "\n",
      "CPU times: user 25.6 s, sys: 6.7 s, total: 32.3 s\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 3\n",
    "print(\"*** INPUT *** \\n\\n\", test_data['input'][n])\n",
    "prompt = test_data['input'][n]\n",
    "\n",
    "print(\"\\n*** OUTPUT *** \\n\\n\")\n",
    "generated_text = generate(prompt, temperature=0.01)\n",
    "parse_text(generated_text)\n",
    "\n",
    "print(\"\\n*** TRUE OUTPUT *** \\n\\n\")\n",
    "print(test_data['output'][n], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** INPUT *** \n",
      "\n",
      " Descriptif du poste\n",
      "\n",
      "microDON est une Entreprise Solidaire d'Utilité Sociale (ESUS) de 40 personnes, filiale du groupe KissKissBankBank & co, qui propose des solutions innovantes pour faciliter l'engagement solidaire.\n",
      "\n",
      "microDON consolide une équipe produit passionnée et engagée. Notre objectif : \"la solidarité est l'affaire de tous\" - développer de chouettes produits innovants qui permettent de réinventer la générosité en France :\n",
      "\n",
      "Comme 2 millions de Français chaque mois dans 10 000 magasins, vous faîtes un don à la caisse de votre magasin via L'ARRONDI en caisse . Un produit grand public qui a permis de reverser 45M d'€ aux associations.\n",
      "\n",
      "530 000 salariés en France sont concernés par L'ARRONDI sur salaire : la possibilité de donner chaque mois quelques euros à l'association de son choix. Un produit solidaire qui a permis de déclencher plus de 1,8 millions de dons\n",
      "\n",
      "❤️ Mis en place auprès d'une centaine d'entreprises, le don de temps est un produit en constante évolution qui se... réinvente en fonction des besoins des associations et des envies des salariés.\n",
      "\n",
      "Un produit innovant en cours : le don de congés CET avec un potentiel de 2,6 milliards d'€ en France\n",
      "\n",
      "Dans ce cadre, la Squad Data est responsable de l'ensemble de la donnée de ces différentes solutions. A travers nos applications développées en interne, elle a pour missions de fournir à nos équipes métiers et à nos clients des données enrichies et fiables. Elle s'assure aussi du suivi de la collecte de dons et de leur bonne redistribution à nos 1500 associations partenaires (Urgence Ukraine, Secours Populaire, Les Restos du Coeur, Emmaüs France, Planète Urgence...).\n",
      "\n",
      "L'équipe Data se situe au coeur des différents métiers et se compose :\n",
      "• D'une Product Manager\n",
      "• D'un Data Engineer senior\n",
      "• D'un Data Analyst confirmé\n",
      "• D'une Data Engineer junior\n",
      "• Et toi notre nouvelle pépite\n",
      "\n",
      "Tu interviendras sur l'ensemble du cycle de vie de la donnée :\n",
      "• Acquisition\n",
      "• ETL\n",
      "• Tests\n",
      "• Automatisation\n",
      "• Gestion des alertes et logs\n",
      "• Mise en production\n",
      "• Gestion d'API\n",
      "\n",
      "Et sur tous les projets de l'enteprise comme par exemple :\n",
      "• La gestion du run\n",
      "• L'optimisation des process actuels\n",
      "• Le développement de nouvelles briques / nouveaux produits\n",
      "• L'onboarding de nouveaux clients\n",
      "• Participer à la gouvernance data\n",
      "\n",
      "Tout cela pour alimenter nos applications internes et délivrer aux équipes micros, à nos clients et à nos associations partenaires des données fiables et enrichies de manière automatique\n",
      "\n",
      "Et au passage d'assurer la redistribution de millions d'euros de dons centimes après centimes\n",
      "\n",
      "Profil recherché\n",
      "\n",
      "Nous recherchons un ou une Data Engineer qui souhaite mettre du sens dans son travail et aider nos associations à accélérer la transition écologique et sociale à travers la data.\n",
      "\n",
      "Savoir-faire\n",
      "\n",
      "Tu as idéalement entre 1 et 3 ans d'expériences sur un poste similaire et tu maîtrises tout ou partie de notre stack technique :\n",
      "• Google Cloud Platform (qui héberge nos données, VM et clusters Kubernetes)\n",
      "• Postgresql (pour gérer nos modèles de données et fournir nos applications internes en données)\n",
      "• Talend (notamment pour l'acquisition et la gestion des APIs)\n",
      "\n",
      "A noter que nous travaillons en CI/CD sur GitLab et que nous gérons nos logs avec Grafana.\n",
      "\n",
      "❤️ Savoir-être\n",
      "• Esprit d'équipe et de collaboration\n",
      "• Prise en main rapide et autonomie\n",
      "• Fiabilité & organisation\n",
      "\n",
      "Ce que nous te proposons\n",
      "\n",
      "Tu rejoins une équipe bienveillante et engagée, enthousiaste à l'idée de t'intégrer. Ton avis et ton expertise sont écoutés.\n",
      "\n",
      "Nos valeurs :\n",
      "• Etre Solidaire\n",
      "• Etre Authentique\n",
      "• Etre Audacieux\n",
      "• Faire confiance\n",
      "\n",
      "Avantages :\n",
      "• prise en charge du pass Navigo à 50% (ou forfait mobilité douce)\n",
      "• prise en charge 100% mutuelle (Alan)\n",
      "• prise en charge des tickets restaurants dématérialisés à 60%\n",
      "• prise en charge de 50% du forfait téléphonique\n",
      "• 10 jours de repos supplémentaires\n",
      "• 5 jours de volontariat pour donner sur son temps pro du temps aux autres\n",
      "\n",
      "Les petits plus :\n",
      "• Un parcours d'intégration aux petits oignons pour s'assurer que tu te sentes bien chez toi\n",
      "• Une équipe Happy Office qui te concocte de chouettes initiatives (massage assis, atelier créatif, apéro du jeudi...)\n",
      "• Cours de yoga et de boxe gratuits 1x/semaine\n",
      "• Des locaux agréables (salle de sport, fruits à volonté, babyfoot, cuisine...) avec des colocs sympatoches et solidaires : Goodeed, KissKissBankBank, Youmatter & Lendopolis\n",
      "• Télétravail et flex-office\n",
      "\n",
      "Tu as envie d'apprendre et d'évoluer dans un univers start-up où les sujets sont variés...\n",
      "Tu as envie d'intégrer une team à taille humaine motivée à l'idée de contribuer à l'intérêt général...\n",
      "Alors rejoins-nous\n",
      "\n",
      "Process de recrutement\n",
      "\n",
      "Candidatures diversifiées bienvenues.\n",
      "• Echange en visio avec Johan, Head of Data #Fit\n",
      "• Echange avec Johan, Samira et Benoît de la Squad Data #Tech\n",
      "• Echange avec les fondateurs de microDON #RH\n",
      "\n",
      "*** OUTPUT *** \n",
      "\n",
      "\n",
      "  { \"salaire\": [ { \"montant_min\": 35000.0, \"montant_max\": 55000.0, \"devise\": \"$\",\n",
      "\"frequence_versement\": \"semaine\" }, { \"montant_min\": null, \"montant_max\": null, \"devise\": null,\n",
      "\"frequence_versement\": null } ] }\n",
      "\n",
      "\n",
      "\n",
      "*** TRUE OUTPUT *** \n",
      "\n",
      "\n",
      "{\"salaire\": [{\"montant_min\": null, \"montant_max\": null, \"devise\": null, \"frequence_versement\": null}]}\n",
      "CPU times: user 26.4 s, sys: 8.63 s, total: 35.1 s\n",
      "Wall time: 35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 4\n",
    "print(\"*** INPUT *** \\n\\n\", test_data['input'][n])\n",
    "prompt = test_data['input'][n]\n",
    "\n",
    "print(\"\\n*** OUTPUT *** \\n\\n\")\n",
    "generated_text = generate(prompt, temperature=0.01)\n",
    "parse_text(generated_text)\n",
    "\n",
    "print(\"\\n*** TRUE OUTPUT *** \\n\\n\")\n",
    "print(test_data['output'][n])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
