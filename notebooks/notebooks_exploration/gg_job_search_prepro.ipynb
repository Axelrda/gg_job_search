{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b0e086",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "3ba96d83-40fb-44da-afdf-a8b407c9453c",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "source": [
    "# Preparation of job postings for analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e6147d",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "50200be7-91b2-4942-80b5-4254f4430d9f",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "In this notebook, we'll be preparing data for analysis in a project focused on predicting salaries from job postings. We'll be working with a dataset of scraped job postings from Google Job search results. \n",
    "\n",
    "The goal of this notebook is to clean and transform the data so that it is ready for modeling and further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abe775b",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "cb3d5e4f-59d2-4369-8126-042f7044a6af",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9487d252",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "2a68fb3e-6a83-4da6-b9c7-4041a91b3a91",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# libraries used for tokenization\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, MWETokenizer\n",
    "\n",
    "# Libraries used to remove similar job description based on cosine similarity \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# libraries used for text normalization\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk import FreqDist\n",
    "\n",
    "# lemmatization w/ spacy\n",
    "import spacy\n",
    "from spacy.symbols import ORTH, LEMMA\n",
    "from spacy import displacy\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# use to get USdollar / euro exchange rate from exchange rate API\n",
    "import requests\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "# import my customs functions\n",
    "from preprocessing import preprocess as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd10655",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "f812b570-77bc-4fec-8d39-f57ea0ffcb31",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced546c5",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "d147cfb5-c20c-4316-b77e-7f72f2839663",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>job_highlights</th>\n",
       "      <th>related_links</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>extensions</th>\n",
       "      <th>job_id</th>\n",
       "      <th>posted_at</th>\n",
       "      <th>schedule_type</th>\n",
       "      <th>date_time</th>\n",
       "      <th>search_query</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist Lead H/F</td>\n",
       "      <td>Fifty-Five</td>\n",
       "      <td>Paris</td>\n",
       "      <td>via HelloWork</td>\n",
       "      <td>Fifty-Five recherche …\\n\\nDescription\\nData Sc...</td>\n",
       "      <td>[{'items': [\"Fifty-Five recherche …\\n\\nDescrip...</td>\n",
       "      <td>[{'link': 'https://www.google.fr/search?gl=fr&amp;...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>['il y a 16 heures', 'À plein temps']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCBMZWFkIE...</td>\n",
       "      <td>il y a 16 heures</td>\n",
       "      <td>À plein temps</td>\n",
       "      <td>2023-02-17 11:50:44.355114</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DATA SCIENTIST (IT) / Freelance</td>\n",
       "      <td>Société Free-Work</td>\n",
       "      <td>Gennevilliers</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Contexte : Dans le cadre de plusieurs projets ...</td>\n",
       "      <td>[{'items': ['Contexte : Dans le cadre de plusi...</td>\n",
       "      <td>[{'link': 'https://www.google.fr/search?gl=fr&amp;...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>['il y a 17 heures', 'À plein temps']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEQVRBIFNDSUVOVElTVCAoSVQpIC...</td>\n",
       "      <td>il y a 17 heures</td>\n",
       "      <td>À plein temps</td>\n",
       "      <td>2023-02-17 11:50:44.355114</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Data analyst / Data scientist H/F</td>\n",
       "      <td>GrandVision France</td>\n",
       "      <td>Châtenay-Malabry</td>\n",
       "      <td>via Figaro Emploi</td>\n",
       "      <td>Quelles sont les missions ?\\n\\nVous\\navez beso...</td>\n",
       "      <td>[{'items': [\"Quelles sont les missions ?\\n\\nVo...</td>\n",
       "      <td>[{'link': 'https://www.google.fr/search?gl=fr&amp;...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>['il y a 11 heures', 'À plein temps']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIGFuYWx5c3QgLyBEYXRhIH...</td>\n",
       "      <td>il y a 11 heures</td>\n",
       "      <td>À plein temps</td>\n",
       "      <td>2023-02-17 11:50:44.355114</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Scientist H/F</td>\n",
       "      <td>Consept Informatique</td>\n",
       "      <td>Nantes</td>\n",
       "      <td>via HelloWork</td>\n",
       "      <td>Consept Informatique recherche …\\n\\nIntégré(e)...</td>\n",
       "      <td>[{'items': [\"Consept Informatique recherche …\\...</td>\n",
       "      <td>[{'link': 'https://www.google.fr/search?gl=fr&amp;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['il y a 11 heures', '35\\xa0k\\xa0€ à 40\\xa0k\\x...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCBIL0YiLC...</td>\n",
       "      <td>il y a 11 heures</td>\n",
       "      <td>À plein temps</td>\n",
       "      <td>2023-02-17 11:50:44.355114</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist - Industrial Field</td>\n",
       "      <td>Fieldbox</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>As part of the Data Science team, you work clo...</td>\n",
       "      <td>[{'items': ['As part of the Data Science team,...</td>\n",
       "      <td>[{'link': 'https://www.google.fr/search?gl=fr&amp;...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>['il y a 19 heures', 'À plein temps']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCAtIEluZH...</td>\n",
       "      <td>il y a 19 heures</td>\n",
       "      <td>À plein temps</td>\n",
       "      <td>2023-02-17 11:50:44.355114</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              title          company_name  \\\n",
       "0           0            Data Scientist Lead H/F            Fifty-Five   \n",
       "1           1    DATA SCIENTIST (IT) / Freelance     Société Free-Work   \n",
       "2           2  Data analyst / Data scientist H/F    GrandVision France   \n",
       "3           3                 Data Scientist H/F  Consept Informatique   \n",
       "4           4  Data Scientist - Industrial Field              Fieldbox   \n",
       "\n",
       "           location                via  \\\n",
       "0             Paris      via HelloWork   \n",
       "1     Gennevilliers       via LinkedIn   \n",
       "2  Châtenay-Malabry  via Figaro Emploi   \n",
       "3            Nantes      via HelloWork   \n",
       "4          Bordeaux       via LinkedIn   \n",
       "\n",
       "                                         description  \\\n",
       "0  Fifty-Five recherche …\\n\\nDescription\\nData Sc...   \n",
       "1  Contexte : Dans le cadre de plusieurs projets ...   \n",
       "2  Quelles sont les missions ?\\n\\nVous\\navez beso...   \n",
       "3  Consept Informatique recherche …\\n\\nIntégré(e)...   \n",
       "4  As part of the Data Science team, you work clo...   \n",
       "\n",
       "                                      job_highlights  \\\n",
       "0  [{'items': [\"Fifty-Five recherche …\\n\\nDescrip...   \n",
       "1  [{'items': ['Contexte : Dans le cadre de plusi...   \n",
       "2  [{'items': [\"Quelles sont les missions ?\\n\\nVo...   \n",
       "3  [{'items': [\"Consept Informatique recherche …\\...   \n",
       "4  [{'items': ['As part of the Data Science team,...   \n",
       "\n",
       "                                       related_links  \\\n",
       "0  [{'link': 'https://www.google.fr/search?gl=fr&...   \n",
       "1  [{'link': 'https://www.google.fr/search?gl=fr&...   \n",
       "2  [{'link': 'https://www.google.fr/search?gl=fr&...   \n",
       "3  [{'link': 'https://www.google.fr/search?gl=fr&...   \n",
       "4  [{'link': 'https://www.google.fr/search?gl=fr&...   \n",
       "\n",
       "                                           thumbnail  \\\n",
       "0  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
       "1  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
       "2  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
       "3                                                NaN   \n",
       "4  https://encrypted-tbn0.gstatic.com/images?q=tb...   \n",
       "\n",
       "                                          extensions  \\\n",
       "0              ['il y a 16 heures', 'À plein temps']   \n",
       "1              ['il y a 17 heures', 'À plein temps']   \n",
       "2              ['il y a 11 heures', 'À plein temps']   \n",
       "3  ['il y a 11 heures', '35\\xa0k\\xa0€ à 40\\xa0k\\x...   \n",
       "4              ['il y a 19 heures', 'À plein temps']   \n",
       "\n",
       "                                              job_id         posted_at  \\\n",
       "0  eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCBMZWFkIE...  il y a 16 heures   \n",
       "1  eyJqb2JfdGl0bGUiOiJEQVRBIFNDSUVOVElTVCAoSVQpIC...  il y a 17 heures   \n",
       "2  eyJqb2JfdGl0bGUiOiJEYXRhIGFuYWx5c3QgLyBEYXRhIH...  il y a 11 heures   \n",
       "3  eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCBIL0YiLC...  il y a 11 heures   \n",
       "4  eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCAtIEluZH...  il y a 19 heures   \n",
       "\n",
       "   schedule_type                   date_time   search_query  Unnamed: 0.1  \n",
       "0  À plein temps  2023-02-17 11:50:44.355114  data engineer           NaN  \n",
       "1  À plein temps  2023-02-17 11:50:44.355114  data engineer           NaN  \n",
       "2  À plein temps  2023-02-17 11:50:44.355114  data engineer           NaN  \n",
       "3  À plein temps  2023-02-17 11:50:44.355114  data engineer           NaN  \n",
       "4  À plein temps  2023-02-17 11:50:44.355114  data engineer           NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/axel/ds_projects/projects/gg_job_search/data/gg_job_search_all_RAW.csv')\n",
    "data = df.copy()\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e1272",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "92e1a8ae-b74b-491d-a28f-6c806ee94933",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## General overview of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bcbba87",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "ac51a94d-0cb2-47dc-8c3e-51a254cb023d",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29354 entries, 0 to 29353\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      29354 non-null  int64  \n",
      " 1   title           29351 non-null  object \n",
      " 2   company_name    29351 non-null  object \n",
      " 3   location        29304 non-null  object \n",
      " 4   via             29354 non-null  object \n",
      " 5   description     29291 non-null  object \n",
      " 6   job_highlights  23018 non-null  object \n",
      " 7   related_links   29265 non-null  object \n",
      " 8   thumbnail       25258 non-null  object \n",
      " 9   extensions      29354 non-null  object \n",
      " 10  job_id          26181 non-null  object \n",
      " 11  posted_at       27214 non-null  object \n",
      " 12  schedule_type   29074 non-null  object \n",
      " 13  date_time       29354 non-null  object \n",
      " 14  search_query    29354 non-null  object \n",
      " 15  Unnamed: 0.1    6333 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(14)\n",
      "memory usage: 3.6+ MB\n",
      "None \n",
      "\n",
      "====================================================================== \n",
      "\n",
      " Number of unique values :  \n",
      "\n",
      " Unnamed: 0        6333\n",
      "title             3235\n",
      "company_name      2432\n",
      "location           583\n",
      "via                310\n",
      "description       6241\n",
      "job_highlights    4463\n",
      "related_links     9218\n",
      "thumbnail         1760\n",
      "extensions        2497\n",
      "job_id            7291\n",
      "posted_at           60\n",
      "schedule_type       33\n",
      "date_time         2741\n",
      "search_query         5\n",
      "Unnamed: 0.1        10\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "====================================================================== \n",
      "\n",
      " Search query results : \n",
      "\n",
      " data engineer                9872\n",
      "data analyst                 9444\n",
      "data scientist               9114\n",
      "machine learning engineer     804\n",
      "data scientist jobs           120\n",
      "Name: search_query, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.info(), '\\n')\n",
    "print('='*70, '\\n'*2, 'Number of unique values : ', '\\n'*2,data.nunique(), '\\n'*2)\n",
    "print('='*70, '\\n'*2,'Search query results :', '\\n'*2, data.search_query.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a01234",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "b90ed404-0bc1-4ffc-b117-df362aca9514",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "### Checking for null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e83723",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "0a0b0ab5-8866-4104-914a-465c5fefa0c1",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                 3\n",
       "company_name          3\n",
       "location             50\n",
       "description          63\n",
       "job_highlights     6336\n",
       "related_links        89\n",
       "thumbnail          4096\n",
       "job_id             3173\n",
       "posted_at          2140\n",
       "schedule_type       280\n",
       "Unnamed: 0.1      23021\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()[data.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a238ecd-65c7-47c4-b5dd-c840e0a4f182",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "1990cc9c-b788-426c-997e-af0275d9442e",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.fillna('unknown' , inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47929c2",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "46659ac6-66b8-4737-949b-f05ce626c590",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "### Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "583af771",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "3a4d97d4-486e-4a1d-886a-7adcc69bdb98",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates : 546\n",
      "Number of duplicates (based on identical job_id) : 22062 \n",
      " ======================================================================\n",
      "Search query results :\n",
      " data scientist               2462\n",
      "data analyst                 1324\n",
      "data engineer                1176\n",
      "machine learning engineer     398\n",
      "data scientist jobs            87\n",
      "Name: search_query, dtype: int64 \n",
      " ======================================================================\n",
      "Final number of rows :  5447\n",
      "Final number of columns :  17\n"
     ]
    }
   ],
   "source": [
    "print('Number of duplicates :',data[data.duplicated()].shape[0])\n",
    "print('Number of duplicates (based on identical job_id) :', data[data.duplicated(['job_id'])].shape[0],'\\n', '='*70) \n",
    "\n",
    "# removing duplicates based on job_id and description\n",
    "data.drop_duplicates(['description'], inplace=True)\n",
    "data.drop_duplicates(['job_id'], inplace=True)\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "print('Search query results :\\n', data.search_query.value_counts(), '\\n', '='*70)\n",
    "print('Final number of rows : ', data.shape[0])\n",
    "print('Final number of columns : ', data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c94e020",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "cf7c9502-c34d-4bcd-ad0f-5b3ca8819245",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "Purely based job id, we can skim off a lots of duplicates. Nonetheless i still found a few of identical / near-identical job descriptions, maybe because [sometimes recruiters or companies post the same advert for a job which results in duplicate data.](https://medium.com/analytics-vidhya/data-science-job-search-using-nlp-and-lda-in-python-12ecbfac79f9)\n",
    "\n",
    "To get rid off these ones, i will use cosine similatity between job descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfdfec2",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "98aa8195-2b74-4f5b-bfc9-c9494f55e881",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "### Removing remaining duplicates w/ Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c825e4e-8626-4298-8b29-ead56daa7a7a",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "dd85e257-4a31-4bfa-9b5c-5c36fe07bde9",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "source": [
    "There are several methods to consider to identify the remaining job postings not captured. We could group them in 3 :\n",
    "\n",
    "    * Fuzzy mathing methods\n",
    "    * Clustering methods\n",
    "    * Topic modeling methods\n",
    " \n",
    "Fuzzy matching methods can be a better choice for identifying job postings with minor variations because it can account for small spelling mistakes, typos and slight variations in the wording or phrasing of the job description. \n",
    "\n",
    "So i will go with cosine similarity which is a measure of the similarity between two non-zero vectors in a high-dimensional space, and is commonly used for comparing text documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145dad6-92f4-4373-95c5-3747bc311bf3",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "71fb7c30-867b-4a53-ba7e-d7f18ff26f5a",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### removing duplicates based on cosine similarity between \n",
    "## job descriptions (code from Thomas Caffrey, see link above)\n",
    "\n",
    "# Defining our collection of job description texts to tokenize\n",
    "data.description = data['description'].fillna('')\n",
    "corpus = data['description']\n",
    "\n",
    "# instantiate CountVectorizer object\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "# Fit_transform to vectorize each job description (map terms to feature indices)\n",
    "X_train_counts = count_vect.fit_transform(corpus)\n",
    "\n",
    "# Compute cosine similarities and put it in dataframe\n",
    "cos_df = pd.DataFrame(cosine_similarity(X_train_counts))\n",
    "\n",
    "\n",
    "## reshape dataframe for easier comparison\n",
    "\n",
    "# get arrays of rows indices and col indices from col_df.shape\n",
    "i, j = np.indices(cos_df.shape).reshape(2,-1)\n",
    "\n",
    "# reshape values to get a 1D array \n",
    "cos_values = cos_df.values.reshape(-1)\n",
    "\n",
    "cos_sim_df = pd.DataFrame({'i': i, 'j': j, 'sim':cos_values})\n",
    "\n",
    "# get cosine similarity values only above 0.98 \n",
    "cos_rem = cos_sim_df[(cos_sim_df['sim'] > 0.90) & (i!=j)]\n",
    "\n",
    "# Method to remove duplicates but keep first instance:\n",
    "# Trying to drop duplicates on i and j columns won't work as the row numbers of duplicates are either in i or j not both.\n",
    "# Setting another column that combines the i & j values ensures that duplicates can be dropped.\n",
    "\n",
    "cos_rem['i*j'] = cos_rem['i'] * cos_rem['j']\n",
    "drop_rows = np.unique(cos_rem.drop_duplicates('i*j')['i'].values)\n",
    "\n",
    "# keep only non-duplicated job postings\n",
    "data = data[~data.index.isin(drop_rows)] \n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "print('Search query results :\\n', data.search_query.value_counts(), '\\n', '='*70)\n",
    "print('Number of duplicates (based on cosine similarity) : ' ,drop_rows.shape[0])\n",
    "print('Final number of rows : ', data.shape[0])\n",
    "print('Final number of columns : ', data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85242f91",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "35cb596f-91fa-41f4-a157-463a8d814e0e",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "#### INSIGHTS :\n",
    "\n",
    "Based on this sample of job titles, we could create : \n",
    "    \n",
    "    * Contract_type (full-time, part-time ...) \n",
    "    * Contract_status (CDI, CDD, work-study, internship ...)\n",
    "    * Duration of Contract (Duration/Undetermined)\n",
    "    * Experience ( Senior, Junior ...)\n",
    "    * Data Specialization (Supply chain, Marketing, Clinical ...)\n",
    "    * Multiple titles (Analyst/Scientist, Scientist/ML Engineer, Manager/Analyst ...)\n",
    "    * Specific expertise asked for (Python, Power BI ...)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1679e1",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "c48c73be-79c0-4a27-9180-c81296120997",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## Explore company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3400f598",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "d3c32ed0-27e2-47fc-8a2e-d57367794e26",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique companies : 2249\n"
     ]
    }
   ],
   "source": [
    "print('number of unique companies :', data.company_name.nunique())\n",
    "#data.company_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1583ec6d",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "f0eb150b-3e79-4738-afd3-1273aff40b1b",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "#data.loc[data['company_name'] == 'Unspecified', ['description']].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05598b",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "2ca538cb-1fbc-4a61-9e38-699165d3d17f",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "#### INSIGHTS :\n",
    "\n",
    "When ***Unspecified***, companies name can be found in description column.\n",
    "\n",
    "Possible new columns :\n",
    "\n",
    "    * Group/Holding (Y/N/NC)\n",
    "    * Interim company (Y/N/NC)\n",
    "\n",
    "Based on the number of job posting per company we could potentially infer about : **size of company ? / Amount of data to work on** / \n",
    "\n",
    "Adding a time variable and much more data, the number of similar / identical job postings for the same company could maybe give insights on the **company's turnover rate / company's growth / magnitude of need-urgency to hire** ...  \n",
    "\n",
    "It seems like extracting additional informations without more context will be difficult. Having access to each company's structure information we could create :\n",
    "\n",
    "    * Size of company\n",
    "    * Industry\n",
    "    * Public / Private\n",
    "    \n",
    "We'll see if can extract more related informations in the following columns. Otherwise, we could try to scrap **Glassdoor databases** (or similar) to get those informations.remains to be seen ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0ce67",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "6e1ce413-3955-40bf-97f5-d460045ef60f",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## Explore location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f01afb6d",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "29b89ccc-8381-42b5-982d-9bc55a955193",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique locations :  494\n"
     ]
    }
   ],
   "source": [
    "print('number of unique locations : ', data.location.nunique())\n",
    "#data.location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29d39825",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "6591b71f-0bf3-4016-bcf9-3094a7b67f52",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "#data.location.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0cabad",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "6868c971-6ec6-4226-a78d-2c1d082494df",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "#### INSIGHTS :\n",
    "\n",
    "We could create a map of th repartition of job posting based on location provided.\n",
    "\n",
    "Some companies don't provide precise location *(ex : location = FRANCE)* and the information is not available in description column either. Further investigations will be needed for these companies, perhaps in conjunction with other databases *(GLASSDOOR / SIRENE databases for instance)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea2d818",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "bdd3aaa9-7ed4-4f21-accb-59ed18840435",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## Explore via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79a48ca8",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "c10426ed-a9f4-4776-8c8c-fa0fb5597387",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique job plateforms :  227\n"
     ]
    }
   ],
   "source": [
    "print('number of unique job plateforms : ', data.via.nunique())\n",
    "# data.via.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d3e6d-aecd-4c78-9b32-9e0a8d62625d",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "678827ed-12b1-401d-9a91-ae35c30d0ab2",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5b57edd",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "47825c1b-0277-4b20-be9d-5889f3af2ac3",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "source": [
    "## Explore description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acda0f5c",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "0dfac044-8ff1-4967-b8e6-35aa307c25ad",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     5447.000000\n",
      "mean      3046.172388\n",
      "std       1647.632778\n",
      "min          7.000000\n",
      "25%       1858.500000\n",
      "50%       2822.000000\n",
      "75%       3995.500000\n",
      "max      14172.000000\n",
      "Name: description, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data.description.str.len().describe())\n",
    "\n",
    "plt.hist(data.description.str.len(), bins=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391bf1f6",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "cffe4e39-6b95-434c-837d-2088f930f55b",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "#### INSIGHTS :\n",
    "\n",
    "\n",
    "We could create :\n",
    "\n",
    "    * Lenght of description (dunno what informations it could provide yet)\n",
    "    * Toold required (Excel, Google Tag Manager ...)\n",
    "    * Coding languages required (R, Python, SQL ...)\n",
    "    * Skills required (reporting, data visualization)\n",
    "    * Required experience\n",
    "    * Duration of contract\n",
    "    * Avantages (ticket resto)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b3d5e5-f1a9-4f1f-a1c9-a11ea8ce97dc",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "256a270e-0fad-4b36-b3cf-e69f98bd621d",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "data[\"all_bullets_string\"] = [' '.join(map(str, re.findall('•(.+)',data.description[i]))) for i, _ in enumerate(data.description)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4bcd7f-cf03-4f8f-b7ad-cbf74fa852a0",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "3cad0e9a-fb38-44ac-8adb-735758f1be15",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## Quick text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aac9330-d79c-4a6e-a1e0-b2e354147345",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "a6b154c4-2bc2-42a7-b194-eab6198f54e9",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "Before creating new features and extractings keywords i'm going to do some simple text normalization for easier parsing and processing : lower cases, remove accents and useless columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df76bedb-f2af-428a-800a-423002ac0a9c",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "f67dd88e-94e6-4683-96c1-6c7a62bc8323",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# removing useless columns\n",
    "def drop_useless_cols(df, cols):\n",
    "    df.drop(columns=cols, inplace=True)\n",
    "    return df\n",
    "\n",
    "cols_to_remove = ['index', 'Unnamed: 0', 'Unnamed: 0.1', 'related_links', 'job_id', 'posted_at', 'thumbnail', 'job_highlights']\n",
    "\n",
    "data = drop_useless_cols(data, cols_to_remove)\n",
    "\n",
    "# lowering cases\n",
    "data = data.applymap(lambda x: x.lower() if type(x) == str else x )\n",
    "\n",
    "# removing accents\n",
    "def remove_accents(text):\n",
    "    normalized = unicodedata.normalize('NFKD', text)\n",
    "    without_accents = [c for c in normalized if not unicodedata.combining(c)]\n",
    "    return ''.join(without_accents)\n",
    "\n",
    "# get columns to remove accents\n",
    "object_cols = set(data.select_dtypes(include='O').columns)\n",
    "accents_keeped_cols = {'extensions'} # i already worked on extensions before, don't wanna remake my code ...\n",
    "accents_removed_cols = list(object_cols - accents_keeped_cols)\n",
    "\n",
    "data[accents_removed_cols] = data[accents_removed_cols].applymap(lambda x: remove_accents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cf429b2-0ef1-4c55-b777-d8398d4b1dd2",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "876dcebc-5b8e-42ec-8a75-6f4454570635",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a propos d'alstef group ?\\n\\ngroupe international en pleine croissance, alstef group concoit, integre et maintient des solutions automatisees pour l'amelioration des performances des processus logistiques.\\n\\nnotre mission : creer des solutions intelligentes qui, au-dela de repondre aux besoins de nos clients, leur font beneficier durablement d’un systeme automatise sur-mesure performant, evolutif et innovant.\\n\\nnos activites\\n\\nnous proposons aux aeroports du monde entier des solutions completes et innovantes pour le traitement des bagages de soute.\\n\\nnous offrons egalement des solutions de manutention integrees completes qui s’etendent des chariots automatiques aux entrepots entierement automatises.\\n\\nen quelques chiffres alstef group, c’est\\n• 165 m€ de chiffre d’affaires\\n• 800 collaborateurs\\n• 13 filiales a l’etranger\\n• 26% des salaries actionnaires du groupe\\n\\net si vous commenciez une nouvelle aventure avec alstef group ?\\n\\nvos missions ?\\n\\nau cours de cette alternance, vous participerez aux... differentes phases des projets informatiques dans le cadre de la mise en place d'outils de data visualisation a la dimension d'alstef group (monde).\\n\\nsous la responsabilite d’un chef de projet, vous participerez aux projets de data analyse avec notamment la creation d’un bi groupe. vous aurez aussi la chance de prendre part a la mise en place des logiciels groupe satellites aux erp des entreprises du groupe (ged, crm, gmao, bi, ...) dans un environnement windows.\\n\\na ce titre, vous interviendrez sur les missions suivantes :\\n• identifier, collecter et qualifier les donnees pertinentes pour l’analyse,\\n• manipuler d’importants volumes de donnees en provenance des differents etablissements du groupe,\\n• developper et documenter un programme dans le cadre de votre projet,\\n• echanger avec des responsables metier pour vous assurer des cas d'usages,\\n• formaliser et documenter votre travail a travers un rapport detaille afin d’en assurer une utilisation perenne au sein de la direction.\\n\\ncompetences : manipulation de bdd, methodes de tests, programmation (legere), capacite d’analyse et de restitution.\\n\\net vous ?\\n\\nvous allez integrer une licence, un master ou une ecole d'ingenieur dans le domaine de l'informatique - data analyste / data science (dont la formation est orientee sur la gestion d'entreprise).\\n\\nau-dela de vos competences techniques ce sont aussi vos qualites personnelles qui nous interessent pour cette alternance.\\n\\nvous etes rigoureux(se), curieux(se) et vous etes reconnu(e) pour votre capacite d'analyse et de restitution, alors cette alternance est faite pour vous !\\n\\nce que nous vous proposons ?\\n• alternance (1 a 3 ans) a boigny-sur-bionne (proche d’orleans - 45),\\n• une aventure dans laquelle vous pourrez vous epanouir, apprendre et entreprendre, avec une grande variete de missions et beaucoup d’autonomie,\\n• une equipe ambitieuse, bienveillante et passionnee,\\n• cadre de travail privilegie (petit open space, espaces de reunion,...).\\n\\nattentifs a l’egalite professionnelle, nous nous engageons a favoriser la mixite dans tous les metiers de l’entreprise.\\n\\na competences egales, priorite aux personnes handicapees et autres beneficiaires de l’obligation d’emploi\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.description[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eb7016-0d6c-42ba-a288-6906e42d7db5",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "6d45708b-d872-45de-973d-f8bdd134122d",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## Extracting features from job titles & job descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4673551f-e3b3-44a4-bcb2-be79bfd3d7da",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "f45adcec-79de-4a30-b8db-a7eb65336ed6",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "As keywords meaning in job descriptions tends to vary a lot more depending on context, i will only extract employment-related kw from it (after investigations employment kws seem to be quite constant in their meaning even in job descriptions).\n",
    "\n",
    "For example, senerioty level keywords contained in job titles are pretty straightforward in term of meaning (employer looking for a specific seniority level) but in job descriptions the same keyword could explain that \"as a junior data analyst you will be supervised by several senior data analyst\". \n",
    "\n",
    "To avoid extracting meaningless keywords i will leave aside job descriptions for now. It'll require fancier extracting methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19a7620b-f19e-4e53-9678-aba9b09f6e1f",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "0eaaec6d-4bcb-4839-aa9e-6fd9ec344c93",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_employment_type(row):\n",
    "    employment_type_dict = {\n",
    "        'CDI': {'cdi'},\n",
    "        'internship': {'stage', 'internship', 'stagiaire'},\n",
    "        'apprenticeship': {'alternant', \"contrat d'apprentissage\", 'contrat de professionnalisation', 'alternance',\n",
    "                           \"(apprenti)\", \"en apprentissage\"},\n",
    "        'CDD': {'cdd'},\n",
    "        'freelance': {'freelance', 'prestataire', 'freelancer'},\n",
    "        'interim': {'poste en Intérim'}\n",
    "}\n",
    "    for employment_type, keywords in employment_type_dict.items():\n",
    "        regex = re.compile(r'\\b(?:%s)\\b' % '|'.join(keywords), re.I)\n",
    "        if regex.search(row['title']) or regex.search(row['description']):\n",
    "            return employment_type\n",
    "    return np.nan\n",
    "\n",
    "def create_seniority_level(row):\n",
    "    seniority_level_dict = {\n",
    "        'senior': {'senior', 'advanced', 'avance', 'sr', 'experimente'},\n",
    "        'mid-level': {'confirme'},\n",
    "        'junior': {'junior', 'debutant', 'jr', 'entry-level'},\n",
    "}\n",
    "    \n",
    "    for seniority_level, keywords in seniority_level_dict.items():\n",
    "        regex = re.compile(r'\\b(?:%s)\\b' % '|'.join(keywords), re.I)\n",
    "        if regex.search(row['title']):\n",
    "                return seniority_level\n",
    "    return np.nan\n",
    "\n",
    "def create_executive_title(row):\n",
    "    executive_title_dict = {\n",
    "        'lead': {'lead'},\n",
    "        'Director': {'director', 'directeur'},\n",
    "        'Manager': {'manager', 'project manager', 'chef de projet'},\n",
    "        'Assistant': {'assistant'},\n",
    "        'Chief': {'chief'},\n",
    "        'Head': {'head'},\n",
    "        'Supervisor': {'supervisor'},\n",
    "}\n",
    "    for executive_title, keywords in executive_title_dict.items():\n",
    "        regex = re.compile(r'\\b(?:%s)\\b' % '|'.join(keywords), re.I)\n",
    "        if regex.search(row['title']):\n",
    "            return executive_title\n",
    "    return np.nan\n",
    "\n",
    "def create_remote_availability(row):\n",
    "    remote_availability_dict = {\n",
    "        'full': {'100 % teletravail', 'remote role', 'full remote', 'teletravail complet', 'fully remote', \n",
    "                 'full-time remote', \"l'entreprise fonctionne en remote\", 'full tt' },\n",
    "        'partial_remote': {'teletravail/semaine', 'teletravail possible', 'jours / mois', '(2j / semaine)', \n",
    "                           'teletravail de','teletravail hybride', 'jours de teletravail','teletravail\\n\\npartiel',\n",
    "                           'teletravail partiel', 'jour de teletravail', 'teletravail par semaine', 'format hybride',\n",
    "                          'jour par semaine', 'jours par semaine', 'j de TT', 'j TT', 'j par semaine', 'jours de tt', 'jours de remote',\n",
    "                          'jour de remote'}\n",
    "}\n",
    "    for remote, keywords in remote_availability_dict.items():\n",
    "        regex = re.compile(r'(?:%s)' % '|'.join(keywords), re.I)\n",
    "        if regex.search(row['title']) or regex.search(row['description']):\n",
    "              return remote\n",
    "    return np.NaN\n",
    "\n",
    "data['employment_type'] = data.apply(create_employment_type, axis=1) \n",
    "data['seniority_level'] = data.apply(create_seniority_level, axis=1)\n",
    "data['executive_title'] = data.apply(create_executive_title, axis=1)\n",
    "data['remote_availability'] = data.apply(create_remote_availability, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23211e26-02b6-4492-b6ef-62be99d543da",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "34df29d6-e4a9-46f7-a74e-ea7883287b5e",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "source": [
    "## Extracting and preprocessing salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b576ae3-5f4d-4387-85c9-20e2e71df59a",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "ea9b7f10-b16a-41b5-bef9-3a14aa7897f1",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_salary_col(df):\n",
    "    \n",
    "    # Extract salary from extensions col\n",
    "    df['extracted_salary'] = pd.Series(df.extensions.str.split(', ', expand=True)[1])\n",
    "       \n",
    "    # Replace non-salary values to np.NaN\n",
    "    df['extracted_salary'].replace([\"'à plein temps']\", \"'à temps partiel']\", \"'stage']\", \"'prestataire']\"], np.NaN, inplace=True)\n",
    "    \n",
    "    # Convert null values to Nothing_found to make parsing easier\n",
    "    df.at[df.extracted_salary.isnull(), 'extracted_salary'] = \"nothing_found\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_og_salary_currency(df):\n",
    "    df['og_salary_currency'] = df.extracted_salary.str.extract(r'(\\€|\\$us)', flags=re.IGNORECASE)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_og_salary_period(df):\n",
    "    df['og_salary_period'] = df.extracted_salary.str.extract(r'(\\ban\\b|\\bmois\\b|\\bjour\\b)', flags=re.IGNORECASE)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def clean_salary(df):\n",
    "    \n",
    "    \n",
    "        ####### targeted clean for easier parsing #######\n",
    "\n",
    "        for index, salary_str in enumerate(df.extracted_salary):\n",
    "                \n",
    "                if 'nothing_found' not in salary_str:\n",
    "                    \n",
    "                    # split salary period from rest of string\n",
    "                    salary_str =  salary_str.split(' par')[0]\n",
    "                    \n",
    "                    # remove single quote\n",
    "                    salary_str = salary_str.split(\"'\")[1]\n",
    "\n",
    "                    # remove unicode chars\n",
    "                    salary_str = salary_str.replace(\"\\\\xa0\", \"\")\n",
    "                    salary_str = salary_str.replace(\"\\\\u202f\", \"\")\n",
    "\n",
    "                    #remove currency\n",
    "                    salary_str = salary_str.replace(\"€\", \"\")\n",
    "                    salary_str = salary_str.replace(\"$us\", \"\")\n",
    "                    salary_str = salary_str.replace(\"$US\", \"\")\n",
    "\n",
    "                    df.at[index, 'extracted_salary'] = salary_str\n",
    "                    \n",
    "        return df\n",
    "\n",
    "def get_salary_range_and_mean(df):                    \n",
    "                 \n",
    "                                        \n",
    "        for index, row in df.iterrows():\n",
    "    \n",
    "            # extract boundaries of YEAR salaries given as a range + calculate mean salary\n",
    "            if (row['og_salary_period'] == 'an') and 'à' in row['extracted_salary']:\n",
    "\n",
    "                # remove k \n",
    "                row['extracted_salary'] = row['extracted_salary'].replace('k', '000')\n",
    "\n",
    "                # get upper and lower bounds\n",
    "                lower_bound = float(row.extracted_salary.split(' à ')[0].split(',')[0])\n",
    "                upper_bound = float(row.extracted_salary.split(' à ')[1].split(',')[0])\n",
    "\n",
    "                # re-establish a consistent value regarding to common year salaries\n",
    "                if lower_bound < 200:\n",
    "                    lower_bound = lower_bound * 1000\n",
    "                    \n",
    "                elif lower_bound > 200 and lower_bound < 1000 :\n",
    "                    lower_bound = lower_bound * 100\n",
    "                    \n",
    "                if upper_bound < 200:\n",
    "                    upper_bound = upper_bound * 1000\n",
    "                    \n",
    "                if upper_bound < 200 and upper_bound < 1000:\n",
    "                    upper_bound = upper_bound * 100\n",
    "                \n",
    "                # get upper / lower bound and discrete_salary columns\n",
    "                df.at[index, 'lower_bound'] = lower_bound\n",
    "                df.at[index, 'upper_bound'] = upper_bound\n",
    "                df.at[index, 'discrete_salary'] = np.mean([lower_bound, upper_bound])\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "            # extract discrete YEAR salaries        \n",
    "            elif (row['og_salary_period'] == 'an') and 'à' not in row['extracted_salary']:\n",
    "\n",
    "                # remove k\n",
    "                row['extracted_salary'] = row['extracted_salary'].replace('k', '000')\n",
    "                row['extracted_salary'] = row['extracted_salary'].replace(',', '.')\n",
    "\n",
    "                # convert value to float\n",
    "                row['extracted_salary'] = float(row['extracted_salary'])\n",
    "\n",
    "                # re-establish a consistent value regarding to common year salaries\n",
    "                if row['extracted_salary'] < 1000:\n",
    "                    row['extracted_salary'] = row['extracted_salary'] * 1000\n",
    "\n",
    "                # assign result to discrete salary column\n",
    "                df.at[index, 'discrete_salary'] = row['extracted_salary']\n",
    "\n",
    "                \n",
    "\n",
    "            \n",
    "            # extract boundaries of MONTH salaries given as a range + calculate mean salary   \n",
    "            elif (row['og_salary_period'] == 'mois') and 'à' in row['extracted_salary']:\n",
    "\n",
    "                # remove k and replace commas\n",
    "                row['extracted_salary'] = row['extracted_salary'].replace('k', '00')\n",
    "                row['extracted_salary'] = row['extracted_salary'].replace(',', '.')\n",
    "\n",
    "                # get upper and lower bounds\n",
    "                lower_bound = float(row.extracted_salary.split(' à ')[0])\n",
    "                upper_bound = float(row.extracted_salary.split(' à ')[1])\n",
    "\n",
    "                # re-establish a consistent value regarding to common month salaries\n",
    "                if lower_bound < 10:\n",
    "                    lower_bound = lower_bound * 100\n",
    "\n",
    "                if lower_bound < 1000:\n",
    "                    lower_bound = lower_bound * 10\n",
    "\n",
    "                if upper_bound < 10:\n",
    "                    upper_bound = upper_bound * 100\n",
    "\n",
    "                if upper_bound < 1000:\n",
    "                    upper_bound = upper_bound * 10\n",
    "\n",
    "                # get upper / lower bound and discrete_salary columns\n",
    "                df.at[index, 'lower_bound'] = lower_bound\n",
    "                df.at[index, 'upper_bound'] = upper_bound\n",
    "                df.at[index, 'discrete_salary'] = np.mean([lower_bound, upper_bound])\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "            # extract discrete MONTH salaries        \n",
    "            elif (row['og_salary_period'] == 'mois') and 'à' not in row['extracted_salary']:\n",
    "\n",
    "                # remove k and replace commas\n",
    "                row['extracted_salary'] = row['extracted_salary'].replace('k', '00')\n",
    "                row['extracted_salary'] = row['extracted_salary'].replace(',', '.')\n",
    "\n",
    "                # convert value to float\n",
    "                row['extracted_salary'] = float(row['extracted_salary'])\n",
    "\n",
    "\n",
    "                # re-establish a consistent value regarding to common year salaries \n",
    "                if row['extracted_salary'] < 1000 and type(row['employment_type']) == str and row['employment_type'] not in ['internship', 'apprenticeship']:\n",
    "                    row['extracted_salary'] = row['extracted_salary'] * 1000\n",
    "                 \n",
    "                elif row['extracted_salary'] < 100:\n",
    "                    row['extracted_salary'] = row['extracted_salary'] * 1000\n",
    "            \n",
    "                elif row['extracted_salary'] < 1000 and type(row['employment_type']) == str and row['employment_type'] in ['internship', 'apprenticeship']:\n",
    "                    row['extracted_salary'] = row['extracted_salary']\n",
    "                \n",
    "                # assign result to discrete salary column\n",
    "                df.at[index, 'discrete_salary'] = row['extracted_salary']\n",
    "            \n",
    "            # extract boundaries of DAY salaries given as a range + calculate mean salary   \n",
    "            elif (row['og_salary_period'] == 'jour') and 'à' in row['extracted_salary']:\n",
    "                \n",
    "                # get upper and lower bounds\n",
    "                lower_bound = float(row.extracted_salary.split(' à ')[0])\n",
    "                upper_bound = float(row.extracted_salary.split(' à ')[1])\n",
    "\n",
    "                # get upper / lower bound and discrete_salary columns\n",
    "                df.at[index, 'lower_bound'] = lower_bound\n",
    "                df.at[index, 'upper_bound'] = upper_bound\n",
    "                df.at[index, 'discrete_salary'] = np.mean([lower_bound, upper_bound])\n",
    "                    \n",
    "                    \n",
    "        return df\n",
    "    \n",
    "            \n",
    " # Define a global variable to cache the exchange rate value\n",
    "cached_exchange_rate = None\n",
    "\n",
    "# Define a function to get the exchange rate value\n",
    "def get_exchange_rate():\n",
    "    # Declare the variable as global to modify its value in the function\n",
    "    global cached_exchange_rate\n",
    "    \n",
    "    try:\n",
    "        # Send a network request to get the exchange rate\n",
    "        response = requests.get('https://openexchangerates.org/api/latest.json?app_id=4820391575d04bdd8d07b7e15fb0a463')\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse the response and calculate the exchange rate\n",
    "        data = response.json()\n",
    "        exchange_rate = data['rates']['EUR'] / data['rates']['USD']\n",
    "        \n",
    "        # Cache the exchange rate value\n",
    "        cached_exchange_rate = exchange_rate\n",
    "        \n",
    "    except (requests.exceptions.RequestException, json.decoder.JSONDecodeError) as e:\n",
    "        # Handle any exceptions that occur during the API request\n",
    "        # If the API request fails, use the cached exchange rate value if it exists\n",
    "        if cached_exchange_rate is not None:\n",
    "            exchange_rate = cached_exchange_rate\n",
    "        else:\n",
    "            # If there is no cached exchange rate value, raise the original exception\n",
    "            raise e\n",
    "    \n",
    "    return exchange_rate           \n",
    "            \n",
    "# This function converts salary values in US dollars to euro currency\n",
    "def convert_salary_currency(df):\n",
    "    \n",
    "    # Create a boolean mask to select rows where salary is in US dollars\n",
    "    mask = df['og_salary_currency'] == '$us'   \n",
    "    \n",
    "    # Multiply the 'discrete_salary' column by the exchange rate\n",
    "    df.loc[mask,'discrete_salary'] *= get_exchange_rate()\n",
    "    \n",
    "    # Return the modified dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "# This function converts salary values from their original period to yearly, monthly, and daily rates\n",
    "def convert_salary_period(df):\n",
    "    \n",
    "    # Define constants used in the conversion calculations\n",
    "    n_days_per_year = 250\n",
    "    n_days_per_month = 20\n",
    "        \n",
    "    # Create a boolean mask to select rows where salary is reported annually\n",
    "    mask = df['og_salary_period'] == 'an'\n",
    "\n",
    "    # Convert the 'discrete_salary' values in the selected rows to yearly, monthly, and daily rates\n",
    "    df.loc[mask, 'year_salary'] = df.loc[mask,'discrete_salary']\n",
    "    df.loc[mask, 'month_salary'] = df.loc[mask,'discrete_salary'] / 12\n",
    "    df.loc[mask, 'day_salary'] = df.loc[mask,'discrete_salary'] / n_days_per_year\n",
    "\n",
    "    # Create a boolean mask to select rows where salary is reported monthly\n",
    "    mask = df['og_salary_period'] == 'mois'\n",
    "\n",
    "    # Convert the 'discrete_salary' values in the selected rows to yearly, monthly, and daily rates\n",
    "    df.loc[mask, 'year_salary'] = df.loc[mask,'discrete_salary'] * 12\n",
    "    df.loc[mask, 'month_salary'] = df.loc[mask,'discrete_salary'] \n",
    "    df.loc[mask, 'day_salary'] = df.loc[mask,'discrete_salary'] / n_days_per_month\n",
    "\n",
    "    # Create a boolean mask to select rows where salary is reported daily\n",
    "    mask = df['og_salary_period'] == 'jour'\n",
    "\n",
    "    # Convert the 'discrete_salary' values in the selected rows to yearly, monthly, and daily rates\n",
    "    df.loc[mask, 'year_salary'] = df.loc[mask,'discrete_salary'] * n_days_per_year\n",
    "    df.loc[mask, 'month_salary'] = df.loc[mask,'discrete_salary'] * n_days_per_month\n",
    "    df.loc[mask, 'day_salary'] = df.loc[mask,'discrete_salary'] \n",
    "\n",
    "    # Return the modified dataframe\n",
    "    return df\n",
    "    \n",
    "def salary_prepro(df):\n",
    "    \n",
    "    df = get_salary_col(df)\n",
    "    df = get_og_salary_period(df)\n",
    "    df = get_og_salary_currency(df)\n",
    "    df = clean_salary(df)\n",
    "    df = get_salary_range_and_mean(df)\n",
    "    df = convert_salary_period(df)\n",
    "    df = convert_salary_currency(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = salary_prepro(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bacc47cc-4ee7-4c7b-9999-973c5faf2cc4",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "fdd67a66-7be5-4b89-bd1b-edfb72a916ce",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       209.000000\n",
       "mean      58045.369378\n",
       "std       31399.376220\n",
       "min        7200.000000\n",
       "25%       40000.000000\n",
       "50%       50000.000000\n",
       "75%       66000.000000\n",
       "max      157500.000000\n",
       "Name: year_salary, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = data.year_salary.notnull()\n",
    "data.loc[mask, ['extracted_salary', 'og_salary_period', 'discrete_salary', 'lower_bound', 'upper_bound', 'year_salary']]['year_salary'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61b1b1df-5d31-47f7-b216-4eb70faf2d56",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "4ac35c2d-05d7-4f7b-a76a-278fc461613c",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fzg\u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "fzg= f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f893224",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "702f5f80-e124-43ad-88e0-033db4c04edc",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "source": [
    "## Finding remaining salaries hidden in job descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ab559-9163-43f9-a586-3cef570b6a5b",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "38d67a85-250a-4317-bf6f-bf64219f2405",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "After thorough research, some salaries are not mentionned in extensions column but in the job descriptions one. Problem is that the salary information comes in many forms, hence the difficulty to extract it. To get a better sense of the many forms it can take i will extract n number of characters before and after a proxy keyword ('salaire').\n",
    "\n",
    "As per i hope to get the full sentence in which the salary information is for each description containing the proxy keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e62d8ca1",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "a072efa0-66de-4606-856d-d1a8bd4bf85d",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining constants\n",
    "keywords = ['salaire', 'remuneration']#, 'durée', 'stage', 'contrat', 'localisation|lieu|location', 'statut', 'formation', 'profil', \n",
    "            #'mission', 'avantage', 'experience', 'soft', 'langue']\n",
    "n_chars_after = 200\n",
    "m_chars_before = 150\n",
    "#col_name = f'charsss_around_{kw}'\n",
    "\n",
    "# loop over keywords list\n",
    "for kw in keywords:\n",
    "    \n",
    "    # define our new columns\n",
    "    data[f'chars_around_{kw}'] = 'NC '\n",
    "\n",
    "    # loop over each string in data.description\n",
    "    for i, text in zip(data.index, data['description']):\n",
    "        \n",
    "        # get iterator over all keywords matches in each string\n",
    "        search_obj = re.finditer(kw, text, re.I)\n",
    "\n",
    "        if search_obj: # ... is true, then ...\n",
    "\n",
    "            # get each keyword match in string\n",
    "            for match in search_obj:\n",
    "\n",
    "                # Find the start index of the keyword\n",
    "                start = match.span()[0]\n",
    "\n",
    "                # Find the end index of the keyword\n",
    "                end = match.span()[1]\n",
    "\n",
    "                # Truncate line to get only 'n' characters before and after the keyword\n",
    "                line = text[start-m_chars_before:end+n_chars_after]\n",
    "                \n",
    "                # add up ever line containing keyword match (if several) in corresponding cells\n",
    "                data.loc[i, f'chars_around_{kw}'] += line\n",
    "                \n",
    "                # get rid of by default 'NC' string\n",
    "                data.loc[i, f'chars_around_{kw}'] = data.loc[i, f'chars_around_{kw}'].replace('NC ', '')\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            # if no keyword match then keep by default value\n",
    "            data.loc[i, f'chars_around_{kw}'] = data.loc[i, f'chars_around_{kw}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6dc52a2-ae00-4c08-90b7-b5413ebeca47",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "2a4ce602-4638-4a9e-8d66-af90c08ecca2",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of salaire word found in descriptions :  396\n",
      "Number of remuneration word found in descriptions :  608\n",
      "NUmber of processed discrete salaries :  209\n",
      "Unexploited salary info w/ \"salaire\" :  363\n",
      "Unexploited salary info w/ \"rémunération\" :  495\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 4500\n",
    "pd.options.display.max_rows = 144\n",
    "\n",
    "mask1 = data.discrete_salary.isnull()\n",
    "mask2 = ~data.discrete_salary.isnull()\n",
    "\n",
    "mask3 = data.description.str.contains(r'remuneration')\n",
    "\n",
    "mask4 = ~data.description.str.contains(r'salaire')\n",
    "mask5 = data.description.str.contains(r'salaire')\n",
    "\n",
    "mask6 = data.chars_around_salaire != 'NC '\n",
    "mask7 = data.chars_around_salaire == 'NC '\n",
    "\n",
    "mask8 = data.chars_around_remuneration != 'NC '\n",
    "mask9 = data.chars_around_remuneration == 'NC '\n",
    "\n",
    "\n",
    "print('Number of salaire word found in descriptions : ', mask5.sum())\n",
    "print('Number of remuneration word found in descriptions : ', mask3.sum())\n",
    "\n",
    "print('NUmber of processed discrete salaries : ', mask2.sum())\n",
    "print('Unexploited salary info w/ \"salaire\" : ',data[ mask1 & mask6]['chars_around_salaire'].shape[0])\n",
    "print('Unexploited salary info w/ \"rémunération\" : ', data[ mask1 & mask7 & mask3].shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3550d5b1-9aeb-4508-a68c-dba9181f26d0",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "d2c63639-1526-4538-b6c3-ecb30e7cfae0",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chars_around_salaire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>bution des campagnes marketing\\n• evaluation de l'impact incremental de tel ou tel canal\\n✨ quelques avantages a travailler chez shine :\\n\\nune grille de salaire transparente qui prend en compte ton experience et ton organisation personnelle (colonne data)\\n\\n‍ 1 jour de freelancing par mois : l'occasion de se mettre dans la peau de nos client·es (avec un compt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>ciee.\\n\\nfourchette de remuneration annuelle versee en 2018 pour ce poste apres au moins une annee de presence (remuneration brute globale, incluant le salaire et la part variable : primes, participation, interessement) : 50.000 a 100.000+ € selon experience.\\n\\nvotre profil :\\nvous etes un passionne de developpement . vous aimez developper.\\nvous etes rigoureu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>ns l’objectif de developper vos competences et de construire votre avenir professionnel,\\n\\n- vous serez responsable, autonome et force de proposition\\n\\nsalaire :\\n\\nen tant que stagiaire, vous percevez une remuneration comprise entre 950€ et 1400€ par mois en fonction de votre niveau d’etude et de la duree de votre stage.\\n\\nensemble, nous vous proposons d’inno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>muneration attractive\\n• remboursement du titre de transport (50%)\\n• tickets restaurant\\n\\ntype d'emploi : temps plein, stage\\nduree du contrat : 6 mois\\n\\nsalaire : 1 500,00€ a 2 500,00€ par mois\\n\\navantages :\\n• participation au transport\\n• titre-restaurant\\n\\nprogrammation :\\n• travail en journee\\n\\ntypes de primes et de gratifications :\\n• prime annuelle\\n• primes\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>fixe + variable (10%)\\n• prime de participation\\n• 30j de conges\\n• ≈* 3j de teletravail *par semaine\\n\\ntype d'emploi : temps plein, cdi\\nstatut : cadre\\n\\nsalaire : a partir de 37 000,00€ par mois\\n\\nprogrammation :\\n• travail en journee\\n\\nlieu du poste : teletravail hybride (94000 creteil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>entre presence chez nos clients, dans nos bureaux ou en teletravail, en fonction des sujets a mener.\\n• pour ce poste de data engineer experimente le salaire indicatif que nous vous proposons a niort est compris entre 45 k€ et 60 k€ brut annuel, beneficiez de rtt et de titres restaurant. cette remuneration s'etudie en fonction de vos annees d'experiences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>vous maitrisez a un niveau avance (notions de js appreciees)\\n\\ncontrat et remuneration :\\n• type de contrat : cdi.\\n• temps de travail : 35h/ semaine.\\n• salaire entre 75,000 € et 90,000 € brut/an + 18% de variable ; negociable.\\n• teletravail.\\n\\nnotre client est un grand groupe francais leader specialise dans la distribution de biens d'equipements de la maison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>s et en anglais\\n\\n# data science\\n\\n# data scientist\\n\\n# ai artificial intelligence\\n\\n# machine learning\\n\\ntype d'emploi : temps plein, cdi\\nstatut : cadre\\n\\nsalaire : a partir de 50 000,00€ par an\\n\\navantages :\\n• horaires flexibles\\n• participation au transport\\n• rtt\\n• titre-restaurant\\n• travail a domicile\\n\\nprogrammation :\\n• du lundi au vendredi\\n• horaires flexibl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>vous maitrisez a un niveau avance (notions de js appreciees)\\n\\ncontrat et remuneration :\\n- type de contrat : cdi.\\n- temps de travail : 35h/ semaine.\\n- salaire entre 75, 000 € et 90, 000 € brut/an + 18% de variable ; negociable.\\n- teletravail.\\nen resume ...\\n• creteil - 94\\n• cdi - teletravail partiel\\n• services aux entreprises\\n• bac +5\\npubliee le 20/02/2023.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>s atouts pour reussir dans ce poste.\\n• vous voulez rejoindre notre equipe de data enthusiasts ?\\n• contactez-nous !\\n\\ntype d'emploi : temps plein, cdi\\n\\nsalaire : a partir de 36 000,00€ par an\\n\\navantages :\\n• epargne salariale\\n• participation au transport\\n• rtt\\n• titre-restaurant\\n\\nprogrammation :\\n• periodes de travail de 8 heures\\n• travail en journee\\n\\nlieu du</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>s et en anglais\\n\\n# data science\\n\\n# data scientist\\n\\n# ai artificial intelligence\\n\\n# machine learning\\n\\ntype d'emploi : temps plein, cdi\\nstatut : cadre\\n\\nsalaire : a partir de 50 000,00€ par an\\n\\navantages :\\n• horaires flexibles\\n• participation au transport\\n• rtt\\n• titre-restaurant\\n• travail a domicile\\n\\nprogrammation :\\n• du lundi au vendredi\\n• horaires flexibl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>t le monde souhaite avancer, une serie d’entretiens en visio avec les personnes cles.\\n\\nduree du contrat : 6 mois\\n\\ntype d'emploi : temps plein, stage\\n\\nsalaire : a partir de 800,00€ par mois\\n\\navantages :\\n\\n- titre-restaurant\\n\\nhoraires :\\n\\n... horaires amenageables\\n\\n- periodes de travail de 8 heures\\n\\n- travail en journee\\n\\nteletravail:\\n\\n- oui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>iens\\n\\ncv + reponse a la question suivante : how do you see data play a role in digital marketing ?\\n\\nstatut : cadre\\n\\ntype d'emploi : temps plein, cdi\\n\\nsalaire : 2 289,00€ a 3 750,00€ par mois\\n\\navantages :\\n\\n- epargne salariale\\n\\n- horaires flexibles\\n\\n- participation au transport\\n\\n- rtt\\n\\n- titre-restaurant\\n\\n- travail a distance\\n\\nhoraires :\\n\\n- du lundi au vend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>sir dans ce poste.\\n\\n- vous voulez rejoindre notre equipe de data enthusiasts ?\\n\\n- contactez-nous !\\n\\nstatut : cadre\\n\\ntype d'emploi : temps plein, cdi\\n\\nsalaire : a partir de 45 000,00€ par an\\n\\navantages :\\n\\n- epargne salariale\\n\\n- participation au transport\\n\\n- rtt\\n\\n- titre-restaurant\\n\\n- travail a distance\\n\\nhoraires :\\n\\n- du lundi au vendredi\\n\\n- periodes de tra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>vous maitrisez a un niveau avance (notions de js appreciees)\\n\\ncontrat et remuneration :\\n• type de contrat : cdi.\\n• temps de travail : 35h/ semaine.\\n• salaire entre 75,000 € et 90,000 € brut/an + 18% de variable ; negociable.\\n• teletravail.\\n\\nnotre client est un grand groupe francais leader specialise dans la distribution de biens d’equipements de la maison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>nce integration au sein d'une equipe pluridisciplinaire large eventail de mission (connaissance client, fraude etc...)type d'emploi : temps plein, cdisalaire: 55000,00€a65000,00€par anavantages: horaires flexibles titre-restaurantprogrammation: du lundi au vendredi horaires flexiblestypes de primes et de gratifications: prime annuelle* primeslieu du poste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>ion en francais et en anglais data science data scientist ai artificial intelligence machine learning type d'emploi : temps plein, cdi statut : cadre salaire : a partir de 50 000,00€ par an avantages : horaires flexibles participation au transport rtt titre-restaurant travail a domicile programmation : du lundi au vendredi horaires flexibles travail en jo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>ion. date de prise de poste : des que possible localisation du poste : merignac (33)remuneration : a definir selon profil type d'emploi : temps plein salaire : 27 000,00€ a 32 000,00€ par an avantages: epargne salariale participation au transport rtt titre-restaurant programmation: travail en journee formation: bac +3 (licence / bachelor) (optionnel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>te, innovation, performance et responsabilite), basee dans le 92 (rueil-malmaison, au pied du rer a). type d'emploi : temps plein, cdi statut : cadre salaire : 34 000,00€ par an avantages: epargne salariale participation au transport rtt titre-restaurant travail a domicile programmation: travail en journee types de primes et de gratifications: prime annue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>entre presence chez nos clients, dans nos bureaux ou en teletravail, en fonction des sujets a mener.\\n• pour ce poste de data engineer experimente le salaire indicatif que nous vous proposons a nantes est compris entre 45 k€ et 60 k€ brut annuel,beneficiez de rttet de titres restaurant.cette remuneration s'etudie en fonction de vos annees d'experiences et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3457</th>\n",
       "      <td>ipe experimentee. nombreux avantages et super ce. perspectives d’evolution et reevaluation salariale. type d'emploi : temps plein, cdi statut : cadre salaire : 50 000,00€ a 60 000,00€ par an avantages: participation au transport rtt titre-restaurant horaires: du lundi au vendredi repos le week-end travail en journee remuneration supplementaire: 13eme mois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>fs, vous disposez de bonnes capacites organisationnelles et de gestion du temps - anglais obligatoire type d'emploi : temps plein, cdi statut : cadre salaire : 40 000,00€ a 70 000,00€ par an horaires: - du lundi au vendredi - travail en journee remuneration supplementaire: - primes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>*variable *(10%)\\n• prime de *participation*\\n• *30j* de conges\\n• *≈* 3j de *teletravail *par semaine\\n\\ntype d'emploi : temps plein, cdi\\nstatut : cadre\\n\\nsalaire : a partir de 37 000,00€ par mois\\n\\nprogrammation :\\n• travail en journee\\n\\nlieu du poste : teletravail hybride (94000 creteil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>idee, la remuneration moyenne au sein de sfeir lille pour un(e) data engineer experimente(e) avec ton experience demarre a 48 000€ brut par an.\\n\\nton salaire sera ensuite revalorise chaque annee.\\n\\ntes competences, rien que tes competences !\\n\\n💻 presentiel ou tele-travail ?\\n\\nles deux, capitaine !\\n\\nla plupart de nos clients sont en mode hybride. le classique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>une idee, la remuneration moyenne au sein de sfeir lille pour un(e) data engineer confirme(e) avec ton experience demarre a 44 000€ brut par an.\\n\\nton salaire sera ensuite revalorise chaque annee.\\n\\ntes competences, rien que tes competences !\\n\\n💻 presentiel ou tele-travail ?\\n\\nles deux, capitaine !\\n\\nla plupart de nos clients sont en mode hybride. le classique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>idee, la remuneration moyenne au sein de sfeir lille pour un(e) data engineer experimente(e) avec ton experience demarre a 48 000€ brut par an.\\n\\nton salaire sera ensuite revalorise chaque annee.\\n\\ntes competences, rien que tes competences !\\n\\npresentiel ou tele-travail ?\\n\\nles deux, capitaine !\\n\\nla plupart de nos clients sont en mode hybride. le classique,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4825</th>\n",
       "      <td>5% abonnement transport processus de recrutement interne : entretien rh (1h) + test technique + debriefing &amp; discussion tech + rencontre co-fondateur salaire et avantages salaire : salaire selon profil reference : 28324320 voir toutes les offresrt processus de recrutement interne : entretien rh (1h) + test technique + debriefing &amp; discussion tech + rencontre co-fondateur salaire et avantages salaire : salaire selon profil reference : 28324320 voir toutes les offresus de recrutement interne : entretien rh (1h) + test technique + debriefing &amp; discussion tech + rencontre co-fondateur salaire et avantages salaire : salaire selon profil reference : 28324320 voir toutes les offres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5085</th>\n",
       "      <td>allenge et des perspectives motivantes ? contactez-nous autres offres de l'entreprise personne en charge du recrutement\\nsebastien podetti - president\\nsalaire\\na partir de 52 k€ brut annuel\\nprise de poste\\ndes que possible\\nexperience\\ntous niveaux d'experience acceptes\\nmetier\\ndata scientist\\nstatut du poste\\ncadre du secteur prive\\nzone de deplacement\\npas de dep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             chars_around_salaire\n",
       "91                                                                                                                                                                                                                                                                                                                                    bution des campagnes marketing\\n• evaluation de l'impact incremental de tel ou tel canal\\n✨ quelques avantages a travailler chez shine :\\n\\nune grille de salaire transparente qui prend en compte ton experience et ton organisation personnelle (colonne data)\\n\\n‍ 1 jour de freelancing par mois : l'occasion de se mettre dans la peau de nos client·es (avec un compt\n",
       "502                                                                                                                                                                                                                                                                                                                                   ciee.\\n\\nfourchette de remuneration annuelle versee en 2018 pour ce poste apres au moins une annee de presence (remuneration brute globale, incluant le salaire et la part variable : primes, participation, interessement) : 50.000 a 100.000+ € selon experience.\\n\\nvotre profil :\\nvous etes un passionne de developpement . vous aimez developper.\\nvous etes rigoureu\n",
       "682                                                                                                                                                                                                                                                                                                                                 ns l’objectif de developper vos competences et de construire votre avenir professionnel,\\n\\n- vous serez responsable, autonome et force de proposition\\n\\nsalaire :\\n\\nen tant que stagiaire, vous percevez une remuneration comprise entre 950€ et 1400€ par mois en fonction de votre niveau d’etude et de la duree de votre stage.\\n\\nensemble, nous vous proposons d’inno\n",
       "698                                                                                                                                                                                                                                                                                                                     muneration attractive\\n• remboursement du titre de transport (50%)\\n• tickets restaurant\\n\\ntype d'emploi : temps plein, stage\\nduree du contrat : 6 mois\\n\\nsalaire : 1 500,00€ a 2 500,00€ par mois\\n\\navantages :\\n• participation au transport\\n• titre-restaurant\\n\\nprogrammation :\\n• travail en journee\\n\\ntypes de primes et de gratifications :\\n• prime annuelle\\n• primes\\n\\n\n",
       "1132                                                                                                                                                                                                                                                                                                                                                                                                        fixe + variable (10%)\\n• prime de participation\\n• 30j de conges\\n• ≈* 3j de teletravail *par semaine\\n\\ntype d'emploi : temps plein, cdi\\nstatut : cadre\\n\\nsalaire : a partir de 37 000,00€ par mois\\n\\nprogrammation :\\n• travail en journee\\n\\nlieu du poste : teletravail hybride (94000 creteil\n",
       "1331                                                                                                                                                                                                                                                                                                                                        entre presence chez nos clients, dans nos bureaux ou en teletravail, en fonction des sujets a mener.\\n• pour ce poste de data engineer experimente le salaire indicatif que nous vous proposons a niort est compris entre 45 k€ et 60 k€ brut annuel, beneficiez de rtt et de titres restaurant. cette remuneration s'etudie en fonction de vos annees d'experiences \n",
       "1415                                                                                                                                                                                                                                                                                                                                vous maitrisez a un niveau avance (notions de js appreciees)\\n\\ncontrat et remuneration :\\n• type de contrat : cdi.\\n• temps de travail : 35h/ semaine.\\n• salaire entre 75,000 € et 90,000 € brut/an + 18% de variable ; negociable.\\n• teletravail.\\n\\nnotre client est un grand groupe francais leader specialise dans la distribution de biens d'equipements de la maison\n",
       "1536                                                                                                                                                                                                                                                                                                                s et en anglais\\n\\n# data science\\n\\n# data scientist\\n\\n# ai artificial intelligence\\n\\n# machine learning\\n\\ntype d'emploi : temps plein, cdi\\nstatut : cadre\\n\\nsalaire : a partir de 50 000,00€ par an\\n\\navantages :\\n• horaires flexibles\\n• participation au transport\\n• rtt\\n• titre-restaurant\\n• travail a domicile\\n\\nprogrammation :\\n• du lundi au vendredi\\n• horaires flexibl\n",
       "2030                                                                                                                                                                                                                                                                                                                            vous maitrisez a un niveau avance (notions de js appreciees)\\n\\ncontrat et remuneration :\\n- type de contrat : cdi.\\n- temps de travail : 35h/ semaine.\\n- salaire entre 75, 000 € et 90, 000 € brut/an + 18% de variable ; negociable.\\n- teletravail.\\nen resume ...\\n• creteil - 94\\n• cdi - teletravail partiel\\n• services aux entreprises\\n• bac +5\\npubliee le 20/02/2023.\n",
       "2360                                                                                                                                                                                                                                                                                                                      s atouts pour reussir dans ce poste.\\n• vous voulez rejoindre notre equipe de data enthusiasts ?\\n• contactez-nous !\\n\\ntype d'emploi : temps plein, cdi\\n\\nsalaire : a partir de 36 000,00€ par an\\n\\navantages :\\n• epargne salariale\\n• participation au transport\\n• rtt\\n• titre-restaurant\\n\\nprogrammation :\\n• periodes de travail de 8 heures\\n• travail en journee\\n\\nlieu du\n",
       "2432                                                                                                                                                                                                                                                                                                                s et en anglais\\n\\n# data science\\n\\n# data scientist\\n\\n# ai artificial intelligence\\n\\n# machine learning\\n\\ntype d'emploi : temps plein, cdi\\nstatut : cadre\\n\\nsalaire : a partir de 50 000,00€ par an\\n\\navantages :\\n• horaires flexibles\\n• participation au transport\\n• rtt\\n• titre-restaurant\\n• travail a domicile\\n\\nprogrammation :\\n• du lundi au vendredi\\n• horaires flexibl\n",
       "2465                                                                                                                                                                                                                                                                                                                                     t le monde souhaite avancer, une serie d’entretiens en visio avec les personnes cles.\\n\\nduree du contrat : 6 mois\\n\\ntype d'emploi : temps plein, stage\\n\\nsalaire : a partir de 800,00€ par mois\\n\\navantages :\\n\\n- titre-restaurant\\n\\nhoraires :\\n\\n... horaires amenageables\\n\\n- periodes de travail de 8 heures\\n\\n- travail en journee\\n\\nteletravail:\\n\\n- oui\n",
       "2508                                                                                                                                                                                                                                                                                                              iens\\n\\ncv + reponse a la question suivante : how do you see data play a role in digital marketing ?\\n\\nstatut : cadre\\n\\ntype d'emploi : temps plein, cdi\\n\\nsalaire : 2 289,00€ a 3 750,00€ par mois\\n\\navantages :\\n\\n- epargne salariale\\n\\n- horaires flexibles\\n\\n- participation au transport\\n\\n- rtt\\n\\n- titre-restaurant\\n\\n- travail a distance\\n\\nhoraires :\\n\\n- du lundi au vend\n",
       "2514                                                                                                                                                                                                                                                                                                            sir dans ce poste.\\n\\n- vous voulez rejoindre notre equipe de data enthusiasts ?\\n\\n- contactez-nous !\\n\\nstatut : cadre\\n\\ntype d'emploi : temps plein, cdi\\n\\nsalaire : a partir de 45 000,00€ par an\\n\\navantages :\\n\\n- epargne salariale\\n\\n- participation au transport\\n\\n- rtt\\n\\n- titre-restaurant\\n\\n- travail a distance\\n\\nhoraires :\\n\\n- du lundi au vendredi\\n\\n- periodes de tra\n",
       "2719                                                                                                                                                                                                                                                                                                                                vous maitrisez a un niveau avance (notions de js appreciees)\\n\\ncontrat et remuneration :\\n• type de contrat : cdi.\\n• temps de travail : 35h/ semaine.\\n• salaire entre 75,000 € et 90,000 € brut/an + 18% de variable ; negociable.\\n• teletravail.\\n\\nnotre client est un grand groupe francais leader specialise dans la distribution de biens d’equipements de la maison\n",
       "2802                                                                                                                                                                                                                                                                                                                                        nce integration au sein d'une equipe pluridisciplinaire large eventail de mission (connaissance client, fraude etc...)type d'emploi : temps plein, cdisalaire: 55000,00€a65000,00€par anavantages: horaires flexibles titre-restaurantprogrammation: du lundi au vendredi horaires flexiblestypes de primes et de gratifications: prime annuelle* primeslieu du poste\n",
       "2809                                                                                                                                                                                                                                                                                                                                        ion en francais et en anglais data science data scientist ai artificial intelligence machine learning type d'emploi : temps plein, cdi statut : cadre salaire : a partir de 50 000,00€ par an avantages : horaires flexibles participation au transport rtt titre-restaurant travail a domicile programmation : du lundi au vendredi horaires flexibles travail en jo\n",
       "3309                                                                                                                                                                                                                                                                                                                                              ion. date de prise de poste : des que possible localisation du poste : merignac (33)remuneration : a definir selon profil type d'emploi : temps plein salaire : 27 000,00€ a 32 000,00€ par an avantages: epargne salariale participation au transport rtt titre-restaurant programmation: travail en journee formation: bac +3 (licence / bachelor) (optionnel\n",
       "3331                                                                                                                                                                                                                                                                                                                                        te, innovation, performance et responsabilite), basee dans le 92 (rueil-malmaison, au pied du rer a). type d'emploi : temps plein, cdi statut : cadre salaire : 34 000,00€ par an avantages: epargne salariale participation au transport rtt titre-restaurant travail a domicile programmation: travail en journee types de primes et de gratifications: prime annue\n",
       "3339                                                                                                                                                                                                                                                                                                                                        entre presence chez nos clients, dans nos bureaux ou en teletravail, en fonction des sujets a mener.\\n• pour ce poste de data engineer experimente le salaire indicatif que nous vous proposons a nantes est compris entre 45 k€ et 60 k€ brut annuel,beneficiez de rttet de titres restaurant.cette remuneration s'etudie en fonction de vos annees d'experiences et\n",
       "3457                                                                                                                                                                                                                                                                                                                                        ipe experimentee. nombreux avantages et super ce. perspectives d’evolution et reevaluation salariale. type d'emploi : temps plein, cdi statut : cadre salaire : 50 000,00€ a 60 000,00€ par an avantages: participation au transport rtt titre-restaurant horaires: du lundi au vendredi repos le week-end travail en journee remuneration supplementaire: 13eme mois\n",
       "3597                                                                                                                                                                                                                                                                                                                                                                                                                   fs, vous disposez de bonnes capacites organisationnelles et de gestion du temps - anglais obligatoire type d'emploi : temps plein, cdi statut : cadre salaire : 40 000,00€ a 70 000,00€ par an horaires: - du lundi au vendredi - travail en journee remuneration supplementaire: - primes\n",
       "4198                                                                                                                                                                                                                                                                                                                                                                                                       *variable *(10%)\\n• prime de *participation*\\n• *30j* de conges\\n• *≈* 3j de *teletravail *par semaine\\n\\ntype d'emploi : temps plein, cdi\\nstatut : cadre\\n\\nsalaire : a partir de 37 000,00€ par mois\\n\\nprogrammation :\\n• travail en journee\\n\\nlieu du poste : teletravail hybride (94000 creteil\n",
       "4388                                                                                                                                                                                                                                                                                                                               idee, la remuneration moyenne au sein de sfeir lille pour un(e) data engineer experimente(e) avec ton experience demarre a 48 000€ brut par an.\\n\\nton salaire sera ensuite revalorise chaque annee.\\n\\ntes competences, rien que tes competences !\\n\\n💻 presentiel ou tele-travail ?\\n\\nles deux, capitaine !\\n\\nla plupart de nos clients sont en mode hybride. le classique\n",
       "4429                                                                                                                                                                                                                                                                                                                              une idee, la remuneration moyenne au sein de sfeir lille pour un(e) data engineer confirme(e) avec ton experience demarre a 44 000€ brut par an.\\n\\nton salaire sera ensuite revalorise chaque annee.\\n\\ntes competences, rien que tes competences !\\n\\n💻 presentiel ou tele-travail ?\\n\\nles deux, capitaine !\\n\\nla plupart de nos clients sont en mode hybride. le classique\n",
       "4624                                                                                                                                                                                                                                                                                                                               idee, la remuneration moyenne au sein de sfeir lille pour un(e) data engineer experimente(e) avec ton experience demarre a 48 000€ brut par an.\\n\\nton salaire sera ensuite revalorise chaque annee.\\n\\ntes competences, rien que tes competences !\\n\\npresentiel ou tele-travail ?\\n\\nles deux, capitaine !\\n\\nla plupart de nos clients sont en mode hybride. le classique, \n",
       "4825  5% abonnement transport processus de recrutement interne : entretien rh (1h) + test technique + debriefing & discussion tech + rencontre co-fondateur salaire et avantages salaire : salaire selon profil reference : 28324320 voir toutes les offresrt processus de recrutement interne : entretien rh (1h) + test technique + debriefing & discussion tech + rencontre co-fondateur salaire et avantages salaire : salaire selon profil reference : 28324320 voir toutes les offresus de recrutement interne : entretien rh (1h) + test technique + debriefing & discussion tech + rencontre co-fondateur salaire et avantages salaire : salaire selon profil reference : 28324320 voir toutes les offres\n",
       "5085                                                                                                                                                                                                                                                                                                                           allenge et des perspectives motivantes ? contactez-nous autres offres de l'entreprise personne en charge du recrutement\\nsebastien podetti - president\\nsalaire\\na partir de 52 k€ brut annuel\\nprise de poste\\ndes que possible\\nexperience\\ntous niveaux d'experience acceptes\\nmetier\\ndata scientist\\nstatut du poste\\ncadre du secteur prive\\nzone de deplacement\\npas de dep"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask9 = data.description.str.contains(r'€')\n",
    "\n",
    "data.loc[ mask1 & mask6 & mask3 & mask9, ['chars_around_salaire']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e38e611-45a2-47af-86b5-d27be66c8a22",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "a9caf84b-3510-47ea-9941-a19133a977f9",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "The already formated data in discrete_salary being scarce, it is crucial to extract the most of salary information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "946b3015-c84f-4515-a0d4-92f56fdc796f",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "f724111b-07a7-4472-9f8c-106a85be2fdf",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                                                                                                                                                                                                                                                          igieuse.\\n\\nrencontrez l'equipe fifty-five ! https://bit.ly/2t8hlhx\\n\\nlocalisation : 5 rue d'athenes, 75009 paris\\n\\ndate de demarrage : des que possible\\n\\nsalaire : selon experience\\nen resume ...\\n• paris 1er - 75\\n• cdi\\n• secteur informatique • esn\\n• bac +5\\npubliee le 16/02/2023. ref : eb5f25ecbbf136f294e497b6a1b6d894\n",
       "8                                                                                                                                                                                                                                                                                                                                                                      r recrute un data scientist - sql / python (h/f) en contrat pro / alternance a massy (91377). le profil ideal ? formation et experience de 1 - 2 ans. salaire : selon profil\\n\\ndescription de l'offre :\\n\\na propos de nous:\\n\\ncreateur de l'hypermarche et pionnier de la consommation de masse, carrefour reste fidele a ses racines tout en se reinventant chaque jour\n",
       "25                                                                                                                                                                                                                                                                                                                                                                                                                                        patients et de la recherche. vous etes a l'aise avec des langages comme r ou python, avec le deep learning, et l'ecosysteme big data (hadoop, spark).\\nsalaire 45/55k€\\nposte en cdi a pourvoir sur rennes\\nsiege social\\nles jardins de la duranne\\n510 rue rene descartes bat d\\n13290 aix-en-provence\n",
       "58                                                                                                                                                                                                                                                                                                                                                                           commerciale. anglais courant ecrit et oral car il y a des echanges reguliers avec le siege europe base en belgique. remuneration : entre 55ke et 65ke salaire fixe variable paye sur 13 mois selon le profil de la personne recrutee. mutuelle, tr. un parking est a disposition des salaries, le site est accessible par le rer c et le tramway 7 egalement. jusqu'a\n",
       "79                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       vos debuts.\\n\\ndetails pratiques\\n\\ntype d'emploi : temps plein, cdi\\n\\nlieu de travail : boulogne-billancourt\\n\\nteletravail : plusieurs jours par semaine\\n\\nsalaire : 42 000,00€ par an - selon profil\n",
       "                                                                                                                                                                                                                                                                                                                                                                           ...                                                                                                                                                                                                                                                                                                                                                                    \n",
       "5420                                                                                                                                                                                                                                                                                                                                                                                                 alend\\n\\nssas\\n\\npower bi\\n\\nms sql server\\n\\nminio\\n\\nkafka\\n\\ntrino\\n\\nelk\\n\\nazure data factory\\n\\nssis\\n\\nbigquery (future)\\n\\ntype d'emploi : independant / freelance\\n\\nsalaire : 150,00€ a 1 500,00€ par jour\\n\\nprogrammation :\\n• travail en journee\\n\\nlieu du poste : un seul lieu de travail\\n\\ndate de debut prevue : 20/03/2023\n",
       "5427                                                                                                                                                                                                                                                                                                                                                      aux certifications.\\n\\nvous souhaitez progresser et booster votre carriere ? venez nous rencontrer.\\n\\ntype d'emploi : temps plein, cdi\\n\\nstatut : cadre\\n\\nsalaire : 45 000,00€ a 60 000,00€ par an\\n\\navantages\\n• horaires flexibles\\n• participation au transport\\n• rtt\\n• titre-restaurant\\n• travail a domicile\\n\\nprogrammation\\n• du lundi au vendredi\\n• horaires flexibles\\n\n",
       "5431                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "5439                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "5442    pe rh pour parler de tes attentes, ton projet, ton futur puis les managers pour parler concret : missions, projets, parcours de carriere, et bien sur salaire et avantages j et tu discutes avec un de nos tech leads, pour evaluer tes competences/ te challenger. les infos en plus teletravail un salaire attractif en fonction de ton experience differents avanten sur salaire et avantages j et tu discutes avec un de nos tech leads, pour evaluer tes competences/ te challenger. les infos en plus teletravail un salaire attractif en fonction de ton experience differents avantages un groupe en pleine croissance avec un management bienveillant et une evolution technique personnalisee avec nos tech lead avec la possibi\n",
       "Name: chars_around_salaire, Length: 363, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get null rows in discrete_salary AND not null rows in chars_around_salary\n",
    "pd.options.display.max_rows = 268\n",
    "data[(data.discrete_salary.isnull()) & (data.chars_around_salaire != 'NC ')]['chars_around_salaire']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a0af31-d021-4ed8-ae17-2f90860b5c58",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "6f0435fd-762e-48f9-9ae7-6a3ca5b3057b",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "After investigation, salaries informations do come from in several differents forms. To that high variablity in salary information we need to add typing errors, incomplete salary ranges or inconsistant salary periods.\n",
    "\n",
    "And to make matters even worse, in several job descriptions we can find a lots of similar informations to salaries (bonus, incentives, profit sharing ...) which add another difficulty to discriminate and extract salaries only.\n",
    "\n",
    "Using rule-based approaches (for loops) to extract and clean up salary data would to be tideous and error-prone as new data is collected, while using regex expressions would quickly become a hassle and readability nightmare.\n",
    "\n",
    "To solve these problems, i will rely on pre-trained QA model languages, which can retrieve informations using question asked about the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6160d158-ee80-4b3f-87c1-370da3e310be",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": "576395f6-16c5-452e-a34e-97b560a66e48",
     "diskcache": false,
     "headerColor": "inherit",
     "id": "142e7042-4768-49ca-850a-704011cbf96e",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "question = \"What is the pay or salary range for the role?\"\n",
    "texts = [\"etes a l'aise sur du cloud (azure, aws ou gcp)\\n• une curiosite technique a toute epreuve et l’envie de prendre part a un projet data from scratch\\n\\nle salaire & avantages\\n• 60-65 k€ selon experience\\n• carte lunchr & mutuelle\\n• 2-3 jours de teletravail par semaine\\n• incentives organises par la direction\\n\\net plus encore...\\n\\nce qu’on prefere\\n• etre implique a\", \n",
    "         \"lle et bordeaux, nous poursuivons notre maillage local en ouvrant 3 agences a lyon, aix et nantes.\\n\\nstatut : cadre\\n\\ntype d'emploi : temps plein, cdi\\n\\nsalaire : 25 000,00€ a 45 000,00€ /an\",\n",
    "        \"ics recherche pour son site de satolas (38) un data analyst h/f. autres offres de l'entreprise personne en charge du recrutement marc low - dirigeant salaire a negocier prise de poste des que possible experience minimum 3 ans metier data analyst statut du poste cadre du secteur prive zone de deplacement pas de deplacement secteur d’activite du poste entre\",\n",
    "        \"tachement : ​​​​​​equipe analyseniveau hierarchique : operationnelremuneration : de 50k a 60k annuel brut + 8% de variable + interessement (1 mois de salaire)teletravail : 2 jours possible par semaine​​​​​​​demarrage : 1 a 90 jours cette opportunite vous correspond ?adressez-nous votre candidature et un consultant vous contactera dans les plus brefs delai\",\n",
    "        \"ale (8 personnes).- des evolutions possibles au sein du groupe.- des avantages : statut cadre, 24 jours de rtt/an, interessement entre 2 et 4 mois de salaire, mutuelle prise en charge a 90%, avantages salaries sur certains produits bancaires et d’assurance, un accord de teletravail, une restauration d’entreprise sur place, une prime variable de 973€/an et produits et un 13eme mois.salaire fixe sur 13 mois en fonction de votre experience\",\n",
    "        \"l’entreprise et son processus de recrutement n’hesitez pas a consulter notre site internet : decilia.fr type d'emploi : temps plein, cdistatut : cadresalaire: 38000,00€a45000,00€par anavantages: horaires flexibles rttprogrammation: du lundi au vendredi horaires flexibles travail en journeetypes de primes et de gratifications:* primeslieu du poste : teletr\"]\n",
    "ranges = [qa_model(question = question, context = x)['answer'] for x in texts if qa_model(question = question, context = x)['score'] > 0.0005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72982e-454a-4ea6-b88f-c19f48fbdb4e",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": "dc4f4f14-96d6-480a-8910-dcc0eda49eef",
     "diskcache": false,
     "headerColor": "inherit",
     "id": "495da39d-0cd8-4a02-8116-413bab079a9f",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20a043-4559-4041-b4c6-6197e739b887",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "95e4d4db-50c1-4541-8a44-9c83d7aed84d",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# capturing salary information using regex\n",
    "pattern1 = r'salaire\\s*\\s*((?:.|\\n)*?)\\n'\n",
    "for index, text in enumerate(data.description):\n",
    "    data.at[index, 'salary_in_description'] = \"\".join(re.findall(pattern1, text))\n",
    "\n",
    "data.salary_in_description.replace('', np.nan, inplace=True)\n",
    "\n",
    "print('number of captured salaries info from description :', data.salary_in_description.notnull().sum(), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf11837-9d65-4440-8588-05231ba26dfb",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "11b4ac7a-e8db-4b09-a647-a80dcd3fb4b5",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "source": [
    "mask = data.salary_in_description.notnull()\n",
    "\n",
    "data.salary_in_description.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd58f2a4-9c51-4ca3-9c90-48b851a2c9b7",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "71580805-4fc5-48bc-b231-5949c5018cc3",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "Using a regex pattern we can extract a substantial amount of salaries. Let's proceed with cleaning and assigning values to each corresponding columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ea8ae-13b0-47c6-bba2-4fc81d4d37c7",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "3ab9dbae-1dd8-4188-ab54-d0c008942318",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "# FIRST CLEAN using vectorized operations \n",
    "data.salary_in_description = data.salary_in_description.astype(str) #cast column type for easier iteration\n",
    "data.salary_in_description = data.salary_in_description.replace(['nan', 'None'], 'NC', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace(r'[a|à] partir de ', '', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace(r'^.*?entre\\s*', '', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace('/an', 'par an', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace('brut annuel', 'par an', regex=True)\n",
    "\n",
    "# get salary period information and assign it to og_salary_period column, it'll serve for later conversion\n",
    "data.og_salary_period.fillna(data.salary_in_description.str.extract(r'(\\ban\\b|\\bmois\\b|\\bjour\\b)', expand=False), axis=0, inplace=True)\n",
    "data.og_salary_currency.fillna(data.salary_in_description.str.extract(r'(\\€|\\$us)', expand=False), axis=0, inplace=True)\n",
    "\n",
    "data.salary_in_description = data.salary_in_description.str.replace('brut', '', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace(r'selon.*', '', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace(r'^.*?:\\s*', '', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace(r'^.*?:\\s*', '', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace(' par an.*', '', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace(' par mois.*', '', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace('eur', '€', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace(' k', '000', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace('et', 'à', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace('/', ' à ', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace('-', ' à ', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace('+', '', regex=True) \n",
    "data.salary_in_description = data.salary_in_description.str.replace('•', '', regex=True) \n",
    "\n",
    "\n",
    "data.salary_in_description = data.salary_in_description.str.replace('€', '', regex=True)\n",
    "\n",
    "# formating string like '3035k' to '30 à 35k' \n",
    "pattern = r'\\b(\\d{2})(\\d{2})[kK]\\b'\n",
    "add_a = r'\\1 à \\2k'\n",
    "\n",
    "data['salary_in_description'] = data['salary_in_description'].apply(lambda x: re.sub(pattern, add_a, x))\n",
    "\n",
    "# replace 'k' by '000' in strings like '45 à 55k' \n",
    "def add_zeros(match):\n",
    "    num1 = match.group(1)\n",
    "    num2 = match.group(2)\n",
    "    return str(int(num1) * 1000) + \" à \" + num2 + \"k\"\n",
    "data['salary_in_description'] = data['salary_in_description'].apply(lambda x: re.sub(r'(\\d+) à (\\d+)k', add_zeros, x))\n",
    "\n",
    "# remove space between thousands and hundreds units in strings like '2 292,00 à 4 774,00'\n",
    "data.salary_in_description = data.salary_in_description.str.replace(r'(?<=\\d) (?=\\d{3})', '', regex=True)\n",
    "\n",
    "# remove commas from salaries\n",
    "data.salary_in_description = data.salary_in_description.str.replace(',00', '', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace(r',..', '', regex=True) \n",
    "\n",
    "\n",
    "# remove points from salaries\n",
    "data.salary_in_description = data.salary_in_description.str.replace('.', '', regex=True)\n",
    "\n",
    "# replace '  à  ' by ' à '\n",
    "data.salary_in_description = data.salary_in_description.str.replace('  à  ', ' à ', regex=True)\n",
    "data.salary_in_description = data.salary_in_description.str.replace('  à ', ' à ', regex=True)\n",
    "\n",
    "# replace every character after k included by '000'\n",
    "data.salary_in_description = data.salary_in_description.str.replace('k.*', '000', regex=True)\n",
    "\n",
    "# remove remaining whitespace from the beginning of strings\n",
    "data.salary_in_description = data.salary_in_description.str.lstrip(' ')\n",
    "\n",
    "# add '000' to strings like '30 à 35' \n",
    "def add_zeros(match):\n",
    "    return match.group(1) + '000'\n",
    "data['salary_in_description'] = data['salary_in_description'].apply(lambda x: re.sub(r'\\b(\\d{2})\\b', add_zeros, x))\n",
    "\n",
    "# SECOND CLEAN using iterations : loop over remaining salaries for final clean \n",
    "# + assigning cleaned values to discrete_salary, lower_bound and upper_bound columns\n",
    "for index, row in data.iterrows():\n",
    "    \n",
    "    # assign 'NC' to string not containing any digits (can't contain salary infos)\n",
    "    if not any(char.isdigit() for char in row['salary_in_description']):\n",
    "        data.at[index,'salary_in_description'] = 'NC'\n",
    "    \n",
    "    # assign 'NC' to string containing a whitespace between thousands and hundreds units (probably typing error - unexplotable infos)\n",
    "    elif re.search(r'(?<=\\d) (?=\\d{3})', row['salary_in_description']):\n",
    "        data.at[index,'salary_in_description'] = 'NC'\n",
    "    \n",
    "    # remove lenghty string (irrelevant information) and short strings (probably typing errors- unexplotable infos) == keep only properly formated salary info\n",
    "    elif len(row['salary_in_description']) > 20 or len(row['salary_in_description']) <= 1:\n",
    "            data.at[index,'salary_in_description'] = 'NC'                    \n",
    "    \n",
    "    # get rows containing ' à ' >>> extract salary range\n",
    "    elif ' à ' in row['salary_in_description'] and row['salary_in_description'] != 'NC':\n",
    "        #print(row.salary_in_description)\n",
    "        # get salary boundaries\n",
    "        data.at[index,'lower_bound'] = int(row['salary_in_description'].split(' à ')[0])\n",
    "        data.at[index,'upper_bound'] = int(row['salary_in_description'].split(' à ')[1])\n",
    "        \n",
    "        # get mean of lower and upper bound\n",
    "        data.at[index, 'discrete_salary'] = (data.loc[index, 'lower_bound'] + data.loc[index, 'upper_bound']) / 2\n",
    "        \n",
    "        # deduce salary period from wage value for strings who didn't contain any mention about period\n",
    "        if int(row['salary_in_description'].split('à')[0]) > 20000:\n",
    "            data.at[index, 'og_salary_period'] = 'an'\n",
    "        else:\n",
    "            data.at[index, 'og_salary_period'] = 'mois'\n",
    "            \n",
    "    # get rows already containing a discrete value (so w/o ' à ' in strings) + assign to discrete_salary column \n",
    "    elif ' à 'not in row['salary_in_description'] and row['salary_in_description'] != 'NC':\n",
    "        print(index, row.salary_in_description)\n",
    "\n",
    "        data.at[index, 'discrete_salary'] = int(row['salary_in_description'])\n",
    "        \n",
    "        # deduce salary period from wage value for strings who didn't contain any mention about period \n",
    "        if int(row['salary_in_description']) > 20000:\n",
    "            data.at[index, 'og_salary_period'] = 'an'\n",
    "        else:\n",
    "            data.at[index, 'og_salary_period'] = 'mois' \n",
    "            \n",
    "\n",
    "    \n",
    "           \n",
    "#convert new salaries period to year / month / day\n",
    "data = pp.convert_salary_period(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7c1305-c0fd-4492-95b5-35dd85a3bdfc",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "759bf536-4e9c-4ea0-90a4-c525262393b3",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df s= feszd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18dbcc7-bd56-44af-bcaf-5374795aec44",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "ae79c671-a708-4b6d-8840-4f7f6c2f16c3",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e1f3b-7045-41d4-821c-22cf3fad07f5",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "16eef583-4705-4bb8-8a8b-f584c8dc7101",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.remote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ac783-3f66-4328-aea7-b3d1ffcd107d",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "b8762f95-c927-4eb3-9436-ce5c93ad1a8e",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = data.title.str.contains('remote')\n",
    "\n",
    "data.title.loc[mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dcaa5a-47a1-4d0f-aa01-06bd42c76673",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "85c56eeb-2352-433a-a382-1ec9d4d8bd9a",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 2000\n",
    "pd.options.display.max_rows = 561\n",
    "\n",
    "mask = data['chars_around_(TT)'] != 'NC '\n",
    "\n",
    "data.loc[:, ['chars_around_(TT)']].loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35a0d2",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "175fe7e4-059f-48a3-9f6d-90598ff33ccc",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## Text normalization of job descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee22857-aeb9-4ccb-9c77-2bbf9aaa3cbe",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "ebfd1d28-011d-427f-998d-bfb4278076d6",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "There are several reasons to text normalization, one is to reduce noise in data. Job descriptions contains a lot of irrelevant information such as punctuation, numbers, special characters, and stop words. By normalizing the data, it'll be easier for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d743542",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "82a96f08-911f-42a9-9661-d3414d6c7056",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get common stopwords from nltk library in both french and english\n",
    "stop_words = list(set(stopwords.words('french')).union(set(stopwords.words('english'))))\n",
    "\n",
    "punct_mark = [\"•\"]\n",
    "\n",
    "apostrophes_stop_words = [\"d'\", \"c'\", \"j'\", \"m'\", \"n'\", \"s'\", \"t'\", \"l'\" ,\"qu'\", \n",
    "                          \"jusqu'\", \"lorsqu'\", \"puisqu'\", \"quoiqu'\", \"qu'il\", \n",
    "                          \"qu'on\", \"qu'un\", \"qu'une\", \"sans qu'\", \"étant qu'\",\n",
    "                         \"qu’\", \"jusqu’\", \"lorsqu’\", \"puisqu’\", \"quoiqu’\", \n",
    "                          \"qu’il\", \"qu’on\", \"qu’un\", \"qu’une\", \"sans qu’\", \"étant qu’\",\n",
    "                         \"d’\", \"c’\", \"j’\", \"m’\", \"n’\", \"s’\", \"t’\", \"d’un\", \"d’une\", \"c’est\"]\n",
    "additional_fr_stop_words = [\n",
    "    \"au\", \"aux\", \"avec\", \"ce\", \"ces\", \"dans\", \"de\", \"des\", \"du\", \"elle\",\n",
    "    \"en\", \"et\", \"eux\", \"il\", \"je\", \"la\", \"le\", \"leur\", \"lui\", \"ma\",\n",
    "    \"mais\", \"me\", \"même\", \"mes\", \"moi\", \"mon\", \"ne\", \"nos\", \"notre\",\n",
    "    \"nous\", \"on\", \"ou\", \"par\", \"pas\", \"pour\", \"qu\", \"que\", \"qui\", \"sa\",\n",
    "    \"se\", \"ses\", \"son\", \"sur\", \"ta\", \"te\", \"tes\", \"toi\", \"ton\", \"tu\",\n",
    "    \"un\", \"une\", \"vos\", \"votre\", \"vous\", \"c’\", \"d’\", \"j’\", \"l’\", \"à\", \"m’\",\n",
    "    \"n’\", \"s’\", \"t’\", \"y’\", \"été\", \"étée\", \"étées\", \"étés\", \"étant\", \"suis\",\n",
    "    \"es\", \"est\", \"sommes\", \"êtes\", \"sont\", \"serai\", \"seras\", \"sera\",\n",
    "    \"serons\", \"serez\", \"seront\", \"serais\", \"serait\", \"serions\", \"seriez\",\n",
    "    \"seraient\", \"étais\", \"était\", \"étions\", \"étiez\", \"étaient\", \"fus\",\n",
    "    \"fut\", \"fûmes\", \"fûtes\", \"furent\", \"sois\", \"soit\", \"soyons\", \"soyez\",\n",
    "    \"soient\", \"fusse\", \"fusses\", \"fût\", \"fussions\", \"fussiez\", \"fussent\",\n",
    "    \"ayant\", \"eu\", \"eue\", \"eues\", \"eus\", \"ai\", \"as\", \"avons\", \"avez\",\n",
    "    \"ont\", \"aurai\", \"auras\", \"aura\", \"aurons\", \"aurez\", \"auront\", \"aurais\",\n",
    "    \"aurait\", \"aurions\", \"auriez\", \"auraient\", \"avais\", \"avait\", \"avions\",\n",
    "    \"aviez\", \"avaient\", \"eut\", \"eûmes\", \"eûtes\", \"eurent\", \"aie\", \"aies\",\n",
    "    \"ait\", \"ayons\"]\n",
    "\n",
    "all_stop_words = set(stop_words + apostrophes_stop_words + additional_fr_stop_words + punct_mark)\n",
    "all_stop_words = list(all_stop_words)\n",
    "\n",
    "\n",
    "# Copy the original description column to a new column\n",
    "data['description_normalized'] = data['description'].copy().str.lower()\n",
    "\n",
    "pattern = r\"(\\b\\w+)[`'’](\\w+)?\\b\"\n",
    "replacement = r\"\\2\"\n",
    "\n",
    "data['description_normalized'] = data['description_normalized'].str.replace(pattern, replacement, regex=True)\n",
    "\n",
    "\n",
    "# remove stop words in data.description_normalized\n",
    "data['description_normalized'] = data['description_normalized'].apply(lambda text: ' '.join([word for word in text.split() if word not in all_stop_words]))\n",
    "    \n",
    "# remove tabulation and punctuation\n",
    "data['description_normalized'] = data['description_normalized'].str.replace('[^\\w\\s]',' ', regex=True)\n",
    "    \n",
    "# Remove punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "data['description_normalized'] = data['description_normalized'].apply(lambda text: text.translate(translator))\n",
    "    \n",
    "# lemmatization\n",
    "\n",
    "# Load the French language model\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "\n",
    "# Define a custom tokenizer rule for \"data\"\n",
    "#special_cases = [{ORTH: \"data\", 'LEMMA': \"data\"}]\n",
    "#nlp.tokenizer.add_special_case(\"data\", special_cases)\n",
    "\n",
    "def lemmatize_description_normalized(text):\n",
    "    # Apply Spacy's tokenizer to the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Lemmatize each token in the document, taking into account context\n",
    "    lemmas = [token.lemma_ if token.pos_ != 'VERB' and token.text != 'data' else token.text for token in doc]\n",
    "    \n",
    "    # Join the lemmas back into a string\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "data['description_normalized'] = data['description_normalized'].apply(lambda text: lemmatize_description_normalized(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b696e0ed-b7b5-473c-b74e-c99cf4d7675a",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "da5328f3-417d-4aac-959c-dd8c79327e39",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "Now, that our job descriptions are normalized, we can analyze them more precisely. In order to that, i'll use : N-grams tokenization and Word cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e5836e",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "539e7bac-cd6d-42b7-a663-7e1176ca0f45",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## Performing N-grams tokenization on normalized job descripions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9481ba-6f40-4254-8504-abb894e98084",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "1824c996-3836-434e-baee-3804b3ceadf5",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "By using N-grams tokenization, we can create tokens that represent not just individual words, but also sequences of words that appear together frequently. This is important because the context in which words are used can greatly affect their meaning.\n",
    "\n",
    "These tokens might capture more complex and nuanced information about the job description and may provide more accurate insights into the skills, qualifications, and requirements of the job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513098b8",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "420a604e-288a-4dfa-a7f5-18d7ff6b8938",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "trigrams = []\n",
    "bigrams = []\n",
    "monograms = []\n",
    "\n",
    "def get_most_common_ngrams(data, n, k):\n",
    "    \"\"\"\n",
    "    This function takes a list of strings, an integer n (for the n-gram size), \n",
    "    and an integer k (for the number of most common n-grams to return). \n",
    "    It returns a list of the k most common n-grams in the input data.\n",
    "    \"\"\"\n",
    "    ngrams_list = []  # Create an empty list to store the n-grams\n",
    "    \n",
    "    for text in data:\n",
    "        \n",
    "        # Tokenize the text into words\n",
    "        words = nltk.word_tokenize(text)\n",
    "        # Generate the n-grams and add them to the list\n",
    "        ngrams_list.extend(list(ngrams(words, n)))\n",
    "        \n",
    "    # Count the occurrences of each n-gram using FreqDist\n",
    "    freq_dist = FreqDist(ngrams_list)\n",
    "    \n",
    "    # Get the k most common n-grams and return them\n",
    "    return freq_dist.most_common(k)\n",
    "\n",
    "trigrams = get_most_common_ngrams(data.description_normalized, 3, 1000)\n",
    "bigrams = get_most_common_ngrams(data.description_normalized, 2, 1000)\n",
    "monograms = get_most_common_ngrams(data.description_normalized, 1, 1000)\n",
    "\n",
    "    \n",
    "# Print the most common trigrams and bigrams\n",
    "print(\"The 5 most common trigrams are:\\n\")\n",
    "for trigram, count in trigrams[:5]:\n",
    "    print(' '.join(trigram), count)\n",
    "\n",
    "print(\"\\nThe 5 most common bigrams are:\\n\")\n",
    "for bigram, count in bigrams[:5]:\n",
    "    print(' '.join(bigram), count)\n",
    "    \n",
    "print(\"\\nThe 5 most common monograms are:\\n\")\n",
    "for monogram, count in monograms[:5]:\n",
    "    print(' '.join(monogram), count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e3d02c",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "1172d996-06c7-4bc9-861f-9d9e9d8c8e9c",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## Visualizing aggregated job descriptions w/ WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f87f2-444b-4423-87d3-42086b8e557c",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "0d0a67b0-c07c-4f17-af2a-1ce4ba1487e9",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "WordCloud provide a quick and visually appealing way to identify the most common terms and phrases used in job descriptions.\n",
    "\n",
    "Below i divided my dataframe by search query to get query-related wordclouds. Grouping data by job titles might have be more precise but as there are over 1300 unique job titles, the quick & easy wordcloud solution would have become less interesting. So i used search_query as a proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50cbc73",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "7fb63ac1-5051-494c-9b07-46a94ca2cc4a",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# groupby data by search query and aggregate descriptions\n",
    "agg_descriptions_by_query = data.groupby('search_query')['description_normalized'].sum().reset_index()\n",
    "\n",
    "\n",
    "for job in agg_descriptions_by_query.search_query.values:\n",
    "\n",
    "    # get aggregated description for each query\n",
    "    agg_text = agg_descriptions_by_query.loc[agg_descriptions_by_query.search_query == job, 'description_normalized'].values[0]\n",
    "\n",
    "    # Create a word cloud object and generate the word cloud\n",
    "    wordcloud = WordCloud(width=800, height=800, background_color=\"white\").generate(agg_text)\n",
    "    print(\"\\n***\",job,\"***\\n\")\n",
    "\n",
    "    # Display the word cloud\n",
    "    plt.figure(figsize=(8, 8), facecolor=None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f526509",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "d9f06708-4e76-4d66-9e0b-2db385d28300",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "additionnal_stop_words = [\"client\", \"solution\", \"service\", \"donnée\", \"plus\", \"busines\", \"entreprise\", \"développement\", \"produit, \"team\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905215b1",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "d91f67f2-17c2-4ad0-9b5b-e316dc404755",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "source": [
    "## Keywords extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dcef97",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "0d45ce8b-f016-4e2c-be1b-ce434036c4c6",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## replace keywords for easier keyword extraction\n",
    "\n",
    "data.description_prepro.replace(['(?i)(Google Tag Manager)|\\b(GTM)\\b', \"(?i)\\b(GA4)\\b|\\b(GA)\\b\", '(?i)\\b(Google Colab)\\b', '\\b(GCP)\\b|(google cloud plateform)\\b'], value=['Google Tag Manager', 'Google Analytics', 'Google Colaboratory', 'Google Cloud Plateform'] ,regex=True, inplace=True)\n",
    "data.description_prepro.replace(['(?i)\\b(AWS)\\b|Amazon Web Services'], value=['Amazon Web Services'] ,regex=True, inplace=True)\n",
    "data.description_prepro.replace(['(?i)SKlearn|Scikit'], value=['ScikitLearn'] ,regex=True, inplace=True)\n",
    "data.description_prepro.replace(['(?i)data viz'], value=['data visualisation'] ,regex=True, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b649a",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "5ffe5888-cf8a-45a5-ac66-514acf5393af",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_visualization_tools = ['d3.js', 'ggplot2', 'tableau', 'matplotlib', 'seaborn', 'lumira',\n",
    "                            'spotfire', 'grafana', 'google data studio', 'looker', 'mode', 'metabase', 'kibana']\n",
    "\n",
    "\n",
    "\n",
    "tools = [\n",
    "'sas', 'Spark', 'BigML', 'D3.js', 'MATLAB', 'Excel', 'ggplot2', 'Tableau', 'Jupyter', \n",
    "'Matplotlib', 'NLTK', 'TensorFlow', 'Weka', 'Google Analytics', 'KNIME', \n",
    "'Flink', 'MongoDB', 'Minitab', 'Rapidminer', 'DataRobot', 'NLTK', 'Hadoop', 'Power BI', \n",
    "'QlikView', 'MySQL', 'Neo4j', 'HANA', 'Spotfire', 'SPSS', 'STATA', 'RiverLogic', \n",
    "'Lumira', 'Pig', 'Keras', 'NumPy', 'PyTorch', 'Seaborn', 'Wolfram Mathematica', \n",
    "'WebSockets', 'Algorithms.io', 'ForecastThis', 'BigQuery', 'GitHub', \n",
    "'Pycharm', 'Visual Studio Code', 'Linux', 'Windows', 'macOS', 'Google Colaboratory', \n",
    "'Google Cloud Plateform', 'Watson Studio', 'Amazon Web Services', \n",
    "'EC2', 'Amazon Elastic Compute Cloud', 'Microsoft Azure', \n",
    "'Nvidia Jetson Nano', 'Arduino', 'beam', 'semantria', 'trackur', 'cassandra', 'octoparse', \n",
    "'Content Grabber', 'OpenRefine', 'Google Fusion Table', 'scipy', 'pandas', 'NPM', 'Redshift', \n",
    "'Snowflake', 'Alteryx', 'Domino Data Lab', 'Kafka', 'Hbase', 'Elasticsearch', 'Maven', \n",
    "'Ansible', 'Gitlab', 'Jenkins', 'Bash', 'IntelliJ', 'MySQL', 'PostreSQL', 'Sonar', \n",
    "'Jira', 'OpenCV', 'TimescaleDB', 'Grafana', 'Google Sheet', 'Pig', 'Talend', 'MSBI',\n",
    "'SAP BO', 'Abode Campaign', 'Google Data Studio', 'Dataform', 'Looker',\n",
    "'Mode', 'Metabase', 'Power Query', 'Power Pivot', 'DataIku', 'MLFlow', 'DVC', 'Kibana', 'SageMaker',\n",
    "'Minio', 'S3', 'MQTT'\n",
    "]\n",
    "\n",
    "keywords_programming = [\n",
    "'sql', 'python', 'r', 'c', 'c#', 'javascript', 'js',  'java', 'scala', 'sas', 'matlab', \n",
    "'c++', 'c/c++', 'perl', 'go', 'typescript', 'bash', 'html', 'css', 'php', 'powershell', 'rust', \n",
    "'kotlin', 'ruby',  'dart', 'assembly', 'swift', 'vba', 'lua', 'groovy', 'delphi', 'objective-c', \n",
    "'haskell', 'elixir', 'julia', 'clojure', 'solidity', 'lisp', 'f#', 'fortran', 'erlang', 'apl', \n",
    "'cobol', 'ocaml', 'crystal', 'javascript/typescript', 'golang', 'nosql', 'mongodb', 't-sql', 'no-sql',\n",
    "'visual_basic', 'pascal', 'mongo', 'pl/sql',  'sass', 'vb.net', 'mssql', \n",
    "]\n",
    "\n",
    "keywords_libraries = [\n",
    "'scikit-learn', 'jupyter', 'theano', 'openCV', 'spark', 'nltk', 'mlpack', 'chainer', 'fann', 'shogun', \n",
    "'dlib', 'mxnet', 'node.js', 'vue', 'vue.js', 'keras', 'ember.js', 'jse/jee',\n",
    "]\n",
    "\n",
    "keywords_analyst_tools = [\n",
    "'excel', 'tableau',  'word', 'powerpoint', 'looker', 'powerbi', 'outlook', 'azure', 'jira', 'twilio',  'snowflake', \n",
    "'shell', 'linux', 'sas', 'sharepoint', 'mysql', 'visio', 'git', 'mssql', 'powerpoints', 'postgresql', 'spreadsheets',\n",
    "'seaborn', 'pandas', 'gdpr', 'spreadsheet', 'alteryx', 'github', 'postgres', 'ssis', 'numpy', 'power_bi', 'spss', 'ssrs', \n",
    "'microstrategy',  'cognos', 'dax', 'matplotlib', 'dplyr', 'tidyr', 'ggplot2', 'plotly', 'esquisse', 'rshiny', 'mlr',\n",
    "'docker', 'linux', 'jira',  'hadoop', 'airflow', 'redis', 'graphql', 'sap', 'tensorflow', 'node', 'asp.net', 'unix',\n",
    "'jquery', 'pyspark', 'pytorch', 'gitlab', 'selenium', 'splunk', 'bitbucket', 'qlik', 'terminal', 'atlassian', 'unix/linux',\n",
    "'linux/unix', 'ubuntu', 'nuix', 'datarobot',\n",
    "]\n",
    "\n",
    "keywords_cloud_tools = [\n",
    "'aws', 'azure', 'gcp', 'snowflake', 'redshift', 'bigquery', 'aurora',\n",
    "]\n",
    "\n",
    "keywords_general_tools = [\n",
    "'microsoft', 'slack', 'apache', 'ibm', 'html5', 'datadog', 'bloomberg',  'ajax', 'persicope', 'oracle', \n",
    "]\n",
    "\n",
    "keywords_general = [\n",
    "'coding', 'server', 'database', 'cloud', 'warehousing', 'scrum', 'devops', 'programming', 'saas', 'ci/cd', 'cicd', \n",
    "'ml', 'data_lake', 'frontend','front-end', 'back-end', 'backend', 'json', 'xml', 'ios', 'kanban', 'nlp',\n",
    "'iot', 'codebase', 'agile/scrum', 'agile', 'ai/ml', 'ai', 'paas', 'machine_learning', 'macros', 'iaas',\n",
    "'fullstack', 'dataops', 'scrum/agile', 'ssas', 'mlops', 'debug', 'etl', 'a/b', 'slack', 'erp', 'oop', \n",
    "'object-oriented', 'etl/elt', 'elt', 'dashboarding', 'big-data', 'twilio', 'ui/ux', 'ux/ui', 'vlookup', \n",
    "'crossover',  'data_lake', 'data_lakes', 'bi', 'pack office'\n",
    "]\n",
    "\n",
    "ml_tools = [\n",
    "'Tensorflow', 'Keras', 'PyTorch', 'ScikitLearn', 'sklearn', 'scikit'\n",
    "]\n",
    "\n",
    "big_data_tools = [\n",
    "'Hadoop', 'HDFS', 'YARN', 'Hive', 'Map', 'Reduce', 'Tez', 'Spark'\n",
    "]\n",
    "\n",
    "general_skills = [\n",
    "'informatique décisionnelle', 'Extraction', 'Nettoyage', 'transformation', 'ingestion', \n",
    "'data visualisation', 'modélisation', 'reporting', 'veille technologique', 'data mining',\n",
    "'kpi', 'computer vision'\n",
    "]\n",
    "\n",
    "soft_skills = [\n",
    "\"Esprit d'analyse\", \"Sens du service\", \"Rigueur\", \"communication\", 'positif', 'créatif', \n",
    "'pragmatique', 'souple', 'agile', \"Autonome\", 'Polyvalent', 'travailler en équipe', \"esprit d'équipe\"\n",
    "'esprit de synthèse', 'aisance relationnelle', 'force de proposition', \"capacité d'analyse\",\n",
    "\"anglais\", \"espagnol\", \"francais\"\n",
    "]\n",
    "\n",
    "coding_languages = [\n",
    "'SQL', 'Python', 'R', 'Julia', 'Scala', 'C++', 'Java', 'Javascript', 'Go'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Add up all keyword lists\n",
    "all_kw = tools + keywords_programming + keywords_libraries + keywords_analyst_tools + keywords_cloud_tools + keywords_general_tools + keywords_general + ml_tools + big_data_tools + general_skills + soft_skills + coding_languages\n",
    "\n",
    "# Lower case & remove duplicates\n",
    "all_kw = list(set([word.lower() for word in all_kw]))\n",
    "\n",
    "# keyword extraction\n",
    "data['extracted_kw'] = data['description'].apply(lambda x: [])\n",
    "\n",
    "for text in enumerate(data.description):\n",
    "\n",
    "    kw_list = [word for word in all_kw if word in text[1]]\n",
    "    data.loc[text[0], \"extracted_kw\"].extend(kw_list)\n",
    "\n",
    "# number of keywords extracted\n",
    "data['extracted_kw_len'] = data['extracted_kw'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f79ba-8d64-4bd1-9d0e-4b011b5b7390",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "05ad6b2c-5882-4068-beda-39c4fcad0d5d",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_useless_col(data):\n",
    "    \n",
    "    data.drop(['Unnamed: 0', 'extensions','level_0', 'index', 'Unnamed: 0.1', 'job_highlights', 'related_links', 'thumbnail',\n",
    "       'extensions', 'job_id', 'Unnamed: 0', 'chars_around_salaire', 'salary_in_description'], axis=1, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = drop_useless_col(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d8890d-2ea6-4b07-8d07-04c78d53820c",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "010e526e-9ea5-4c89-8493-e362838b0949",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "## Encoding"
   ]
  }
 ],
 "metadata": {
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": [],
   "version": "1.0"
  },
  "kernelspec": {
   "display_name": "gg_jobs_env",
   "language": "python",
   "name": "gg_jobs_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
