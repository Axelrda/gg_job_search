{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8CIZfyaSFqLN","executionInfo":{"status":"ok","timestamp":1684447599339,"user_tz":-120,"elapsed":17724,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"}},"outputId":"aec2a80e-730b-445d-a558-cf7f38f71429"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install transformers\n","!pip install torch"]},{"cell_type":"markdown","metadata":{"id":"6cdNWq2sbbn-"},"source":["## Load libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"QI2v6Qd0FsvT","executionInfo":{"status":"ok","timestamp":1684447605260,"user_tz":-120,"elapsed":5927,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"}}},"outputs":[],"source":["import pandas as pd\n","import unicodedata\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"F0yD2Xg_beLB"},"source":["## Mount Drive"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"YR_EBvxuD_cG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684447634166,"user_tz":-120,"elapsed":28910,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"}},"outputId":"e5d1d3a9-ae14-4e05-ece2-4e7df5f32444"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","import sys\n","from google.colab import drive\n","drive.mount('/content/drive')\n","package_path = ['/content/drive/MyDrive/Packages', '/content/drive/MyDrive/github/gg_job_search', '/content/drive/MyDrive/github/gg_job_search/src/']\n","sys.path.extend(package_path)\n","#!pip install --target=$package_path cupy-cuda102"]},{"cell_type":"code","source":["# custom functions\n","import preprocessing.preprocess  as pp"],"metadata":{"id":"i0f9WwslH_Rj","executionInfo":{"status":"ok","timestamp":1684447636990,"user_tz":-120,"elapsed":2837,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qv9Mqog9bhn-"},"source":["## Load data"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"N5YrI-5ZEAHq","executionInfo":{"status":"ok","timestamp":1684448951814,"user_tz":-120,"elapsed":2726,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"}}},"outputs":[],"source":["# Get data\n","data = pd.read_csv('/content/drive/MyDrive/github/gg_job_search/data/gg_job_search_all_RAW.csv')\n","df = data.copy()"]},{"cell_type":"markdown","metadata":{"id":"E3Ge2zPpbko-"},"source":["## Preparing data"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"XgkvoxBEU9qv","executionInfo":{"status":"ok","timestamp":1684448987501,"user_tz":-120,"elapsed":18650,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"}}},"outputs":[],"source":["df = pp.lowercase_and_remove_accents(df)\n","df = pp.basic_cleaning(df)\n","df = pp.matching_cols(df)"]},{"cell_type":"markdown","metadata":{"id":"OANH1XvvEX5-"},"source":["## Get last scraped data"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"MYFR_HkVEXGd","executionInfo":{"status":"ok","timestamp":1684448987501,"user_tz":-120,"elapsed":6,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"}}},"outputs":[],"source":["df = pp.get_last_records(df)"]},{"cell_type":"markdown","metadata":{"id":"9j555LhHZjK-"},"source":["## Encoding data"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"tBEat7SEuM0a","executionInfo":{"status":"ok","timestamp":1684448988137,"user_tz":-120,"elapsed":641,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"}}},"outputs":[],"source":["descriptions = df.description.to_list()\n","\n","model_checkpoint = 'papluca/xlm-roberta-base-language-detection'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","\n","inputs = tokenizer(descriptions, \n","                   truncation=True, \n","                   padding=True,\n","                   max_length=512, \n","                   return_tensors=\"pt\")"]},{"cell_type":"markdown","metadata":{"id":"tmp0tMy2L3yQ"},"source":["## Encogings to torch dataset"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"6zI0-LVav4U8","executionInfo":{"status":"ok","timestamp":1684448988140,"user_tz":-120,"elapsed":14,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"}}},"outputs":[],"source":["class PyTorchEncodedDataset(torch.utils.data.Dataset):\n","    \n","    \"\"\"\n","    A custom PyTorch dataset that takes a dictionary of encodings as input and returns a dictionary of PyTorch tensors \n","    when indexed.\n","    \"\"\"\n","    \n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx): \n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask']}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)\n","\n","torch_descriptions = PyTorchEncodedDataset(inputs)"]},{"cell_type":"markdown","metadata":{"id":"DV-zS6zPcW9v"},"source":["## Dataloader"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"Ddh1WhmecYRe","executionInfo":{"status":"ok","timestamp":1684448988483,"user_tz":-120,"elapsed":353,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"}}},"outputs":[],"source":["# create a data loader with batch size 32\n","batch_size = 50\n","dataloader = DataLoader(torch_descriptions, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"of_VGfmqMtHo"},"source":["## Load model to device"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"gACDIgNEwZwn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684448992293,"user_tz":-120,"elapsed":3819,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"}},"outputId":"91ac84c1-77f2-4ad1-9da6-9dfd9d62a734"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): XLMRobertaModel(\n","    (embeddings): XLMRobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): XLMRobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): XLMRobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=20, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":21}],"source":["# set up device\n","device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n","\n","# set up model and move it to device\n","lg_classifier = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n","lg_classifier.to(device)"]},{"cell_type":"markdown","metadata":{"id":"2G3SD6bfMyPp"},"source":["## Inference"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"jFLjUXL8muGB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684448996660,"user_tz":-120,"elapsed":4397,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"}},"outputId":"59191aa2-236f-42f8-f6db-0bd4628c76b7"},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/4 [00:00<?, ?it/s]<ipython-input-19-d9847ad612b6>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key in ['input_ids', 'attention_mask']}\n","100%|██████████| 4/4 [00:04<00:00,  1.13s/it]\n"]}],"source":["logit_list = []\n","\n","with torch.no_grad():\n","\n","  # iterate over dataloader\n","  for batch in tqdm(dataloader):\n","    # Move batch to device\n","    batch = {k: v.to(device) for k, v in batch.items()}\n","\n","    # get logits\n","    logits = lg_classifier(**batch).logits\n","\n","    # append list \n","    logit_list.append(logits)"]},{"cell_type":"markdown","metadata":{"id":"Okqr1JNOLEQN"},"source":["## Post-processing"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Ky4WYLtS0qa-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684448996661,"user_tz":-120,"elapsed":23,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"}},"outputId":"040b9be1-2e63-4706-a171-cc2afca42d49"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["fr    139\n","en     30\n","it      1\n","Name: lang_labels, dtype: int64"]},"metadata":{},"execution_count":23}],"source":["# get best predicted ids (language)\n","id_list = []\n","for batch in logit_list:\n","  for line in batch:\n","    id_list.append(line.argmax().item())\n","\n","# assign ids to pd.Series \n","id_col = pd.Series(id_list)\n","\n","# map ids to corresponding labels for easier readability\n","lang_labels = id_col.map(lg_classifier.config.id2label)\n","\n","# rename \n","lang_labels.rename('lang_labels', inplace=True)\n","\n","lang_labels.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"5ugjMXRuch0B"},"source":["## Export"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"q1gACVDdciPd","executionInfo":{"status":"ok","timestamp":1684448996662,"user_tz":-120,"elapsed":13,"user":{"displayName":"Camarade Axel","userId":"05508807808245626778"}}},"outputs":[],"source":["# export\n","lang_labels.to_csv('/content/drive/MyDrive/github/gg_job_search/data/lang_labels', mode='a', index=False, header=False)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNndtzgyGSHce0yVzNK5J2M"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}