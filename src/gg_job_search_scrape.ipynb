{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e29d6f6e",
   "metadata": {},
   "source": [
    "google job search scraping tuto : https://serpapi.com/blog/scrape-google-jobs-organic-results-with-python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca0a82",
   "metadata": {},
   "source": [
    "## IMPORT NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f79509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv \n",
    "\n",
    "# Libraries for using google jobs API from SERPAPI\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "# library for using SERPSTACK\n",
    "#import requests\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import json, os\n",
    "import datetime\n",
    "\n",
    "# Library to generate UULE code on the fly\n",
    "import uule_grabber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91fae41",
   "metadata": {},
   "source": [
    "## GET GEOTARGETS INTO UULE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2df9107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign all google geo location to dataset\n",
    "geotargets = pd.read_csv('data_science_stuff/P1/geotargets-2022-12-21.csv') \n",
    "# get canonical name for our cities of interest >>> PARIS for instance\n",
    "\n",
    "canonical_name = geotargets.loc[(geotargets['Target Type'] == 'Country') &( geotargets['Country Code'] == 'FR'), ['Canonical Name']]\n",
    "\n",
    "#canonical_name = geotargets.loc[(geotargets.Name == 'Nantes') & (geotargets['Country Code'] == 'FR') & (geotargets['Target Type'] == 'City'), ['Canonical Name']]\n",
    "#canonical_name = canonical_name.iloc[0,0]\n",
    "canonical_name = canonical_name.iloc[0,0]\n",
    "\n",
    "# get corresponding uule code to cities of interest\n",
    "cities = canonical_name\n",
    "uule_codes = uule_grabber.uule(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f803d72",
   "metadata": {},
   "source": [
    "## COLLECT DATA W\\ SERPAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff60a7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 0 of 'data scientist' results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14387/876356761.py:43: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  jobs = pd.concat([pd.DataFrame(jobs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 10 of 'data scientist' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 20 of 'data scientist' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 30 of 'data scientist' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 40 of 'data scientist' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 50 of 'data scientist' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 60 of 'data scientist' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 70 of 'data scientist' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 80 of 'data scientist' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 90 of 'data scientist' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 100 of 'data scientist' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 110 of 'data scientist' results\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 0 of 'data analyst' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 10 of 'data analyst' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 20 of 'data analyst' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 30 of 'data analyst' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 40 of 'data analyst' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 50 of 'data analyst' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 60 of 'data analyst' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 70 of 'data analyst' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 80 of 'data analyst' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 90 of 'data analyst' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 100 of 'data analyst' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 110 of 'data analyst' results\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 0 of 'data engineer' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 10 of 'data engineer' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 20 of 'data engineer' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 30 of 'data engineer' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 40 of 'data engineer' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 50 of 'data engineer' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 60 of 'data engineer' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 70 of 'data engineer' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 80 of 'data engineer' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 90 of 'data engineer' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 100 of 'data engineer' results\n",
      "https://serpapi.com/search\n",
      "Getting SerpAPI data for page: 110 of 'data engineer' results\n",
      "https://serpapi.com/search\n"
     ]
    }
   ],
   "source": [
    "# Defining our search query + necessary parameters for GoogleSearch object\n",
    "\n",
    "search_queries = [\"data scientist\", \"data analyst\", \"data engineer\"]\n",
    "\n",
    "for query in search_queries:\n",
    "\n",
    "    # serpapi will iterate up to n number of iterations\n",
    "    for num  in range(45):\n",
    "\n",
    "        start = num * 10\n",
    "\n",
    "\n",
    "    # define parameters\n",
    "        params = {\n",
    "            'api_key': '4b799b64af09be918f6d66d6e908184cba836c46596e58bfa8bf1fb9280e7f09',                              \n",
    "            'device':'desktop',\n",
    "            'uule': uule_codes,                         # encoded location \n",
    "            'q': search_queries,                          # search query\n",
    "            'google_domain': 'google.fr',              \n",
    "            'hl': 'fr',                                 # language of the search\n",
    "            'gl': 'fr',                                 # country of the search\n",
    "            'engine': 'google_jobs',                    # SerpApi search engine\n",
    "            'start': start,                             # pagination\n",
    "            'chips':'date_posted:today'                 \n",
    "        }\n",
    "\n",
    "        # get results \n",
    "        search = GoogleSearch(params)\n",
    "        results = search.get_dict()  # JSON file to python dict \n",
    "\n",
    "        # check if last search page, exceptions handling   \n",
    "        try:\n",
    "            if results['error'] == \"Google hasn't returned any results for this query.\":\n",
    "                    break\n",
    "        except KeyError:\n",
    "                print(f\"Getting SerpAPI data for page: {start} of '{query}' results\")\n",
    "        else:\n",
    "                continue\n",
    "\n",
    "        # create dataframe of 10 pulled results\n",
    "        jobs = results['jobs_results']\n",
    "        jobs = pd.DataFrame(jobs)\n",
    "        jobs = pd.concat([pd.DataFrame(jobs), \n",
    "                        pd.json_normalize(jobs['detected_extensions'])], #convert detected extension key in json files into pandas df\n",
    "                        axis=1).drop('detected_extensions', 1) # drop json object\n",
    "        jobs['date_time'] = datetime.datetime.now() # add extraction date column for job results\n",
    "\n",
    "        # concat dataframe\n",
    "        if start == 0:\n",
    "                jobs_all = jobs\n",
    "        else:\n",
    "                jobs_all = pd.concat([jobs_all, jobs])\n",
    "\n",
    "\n",
    "        jobs_all['search_query'] = query\n",
    "        \n",
    "        \n",
    "    # exporting results to csv file\n",
    "    jobs_all.to_csv('gg_job_search_all_RAW.csv', mode='a', header=False, index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c839ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa753b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f31f66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9363cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe57c4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca125e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f58e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23e766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ad73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7069cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
